<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[BeanDefinition的资源定位过程]]></title>
    <url>%2Fpost%2FSpring-IOC-BeanDefinition%2F</url>
    <content type="text"><![CDATA[前言之前一直想系统的拜读一下 spring 的源码，看看它到底是如何吸引身边的大神们对它的设计赞不绝口，虽然每天工作很忙，每天下班后总感觉脑子内存溢出，想去放松一下，但总是以此为借口，恐怕会一直拖下去。所以每天下班虽然有些疲惫，但还是按住自己啃下这块硬骨头。 spring 源码这种东西真的是一回生二回熟，第一遍会被各种设计模式和繁杂的方法调用搞得晕头转向，不知道看到的这些方法调用的是哪个父类的实现（IoC 相关的类图实在太复杂咯，继承体系又深又广），但当你耐下心来多走几遍，会发现越看越熟练，每次都能 get 到新的点。 另外，对于第一次看 spring 源码的同学，建议先在 B 站上搜索相关视频看一下，然后再结合计文柯老师的《spring 技术内幕》深入理解，最后再输出自己的理解（写博文或部门内部授课）加强印象。 首先对于我们新手来说，还是从我们最常用的两个 IoC 容器开始分析，这次我们先分析 FileSystemXmlApplicationContext 这个 IoC 容器的具体实现，ClassPathXmlApplicationContext 留着下次讲解。 （PS：可以结合我 GitHub 上对 Spring 框架源码的翻译注释一起看，会更有助于各位同学的理解。地址：spring-beans https://github.com/AmyliaY/spring-beans-readingspring-context https://github.com/AmyliaY/spring-context-reading） 正文当我们传入一个 Spring 配置文件去实例化 FileSystemXmlApplicationContext 时，可以看一下它的构造方法都做了什么。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 下面这 4 个构造方法都调用了第 5 个构造方法 * @param configLocation * @throws BeansException */// configLocation 包含了 BeanDefinition 所在的文件路径public FileSystemXmlApplicationContext(String configLocation) throws BeansException &#123; this(new String[] &#123;configLocation&#125;, true, null);&#125;// 可以定义多个 BeanDefinition 所在的文件路径public FileSystemXmlApplicationContext(String... configLocations) throws BeansException &#123; this(configLocations, true, null);&#125;// 在定义多个 BeanDefinition 所在的文件路径 的同时，还能指定自己的双亲 IoC 容器public FileSystemXmlApplicationContext(String[] configLocations, ApplicationContext parent) throws BeansException &#123; this(configLocations, true, parent);&#125;public FileSystemXmlApplicationContext(String[] configLocations, boolean refresh) throws BeansException &#123; this(configLocations, refresh, null);&#125;/** * 如果应用直接使用 FileSystemXmlApplicationContext 进行实例化，则都会进到这个构造方法中来 */public FileSystemXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; // 动态地确定用哪个加载器去加载我们的配置文件 super(parent); // 告诉读取器 配置文件放在哪里，该方法继承于爷类 AbstractRefreshableApplicationContext setConfigLocations(configLocations); if (refresh) &#123; // 容器初始化 refresh(); &#125;&#125;/** * 实例化一个 FileSystemResource 并返回，以便后续对资源的 IO 操作 * 本方法是在其父类 DefaultResourceLoader 的 getResource 方法中被调用的， */@Overrideprotected Resource getResourceByPath(String path) &#123; if (path != null &amp;&amp; path.startsWith(&quot;/&quot;)) &#123; path = path.substring(1); &#125; return new FileSystemResource(path);&#125; 看看其父类 AbstractApplicationContext 实现的 refresh() 方法，该方法就是 IoC 容器初始化的入口类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 容器初始化的过程：BeanDefinition 的 Resource 定位、BeanDefinition 的载入、BeanDefinition 的注册。 * BeanDefinition 的载入和 bean 的依赖注入是两个独立的过程，依赖注入一般发生在 应用第一次通过 * getBean() 方法从容器获取 bean 时。 * * 另外需要注意的是，IoC 容器有一个预实例化的配置（即，将 AbstractBeanDefinition 中的 lazyInit 属性 * 设为 true），使用户可以对容器的初始化过程做一个微小的调控，lazyInit 设为 false 的 bean * 将在容器初始化时进行依赖注入，而不会等到 getBean() 方法调用时才进行 */public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 调用容器准备刷新，获取容器的当前时间，同时给容器设置同步标识 prepareRefresh(); // 告诉子类启动 refreshBeanFactory() 方法，BeanDefinition 资源文件的载入从子类的 refreshBeanFactory() 方法启动开始 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 为 BeanFactory 配置容器特性，例如类加载器、事件处理器等 prepareBeanFactory(beanFactory); try &#123; // 为容器的某些子类指定特殊的 BeanPost 事件处理器 postProcessBeanFactory(beanFactory); // 调用所有注册的 BeanFactoryPostProcessor 的 Bean invokeBeanFactoryPostProcessors(beanFactory); // 为 BeanFactory 注册 BeanPost 事件处理器. // BeanPostProcessor 是 Bean 后置处理器，用于监听容器触发的事件 registerBeanPostProcessors(beanFactory); // 初始化信息源，和国际化相关. initMessageSource(); // 初始化容器事件传播器 initApplicationEventMulticaster(); // 调用子类的某些特殊 Bean 初始化方法 onRefresh(); // 为事件传播器注册事件监听器. registerListeners(); // 初始化 Bean，并对 lazy-init 属性进行处理 finishBeanFactoryInitialization(beanFactory); // 初始化容器的生命周期事件处理器，并发布容器的生命周期事件 finishRefresh(); &#125; catch (BeansException ex) &#123; // 销毁以创建的单态 Bean destroyBeans(); // 取消 refresh 操作，重置容器的同步标识. cancelRefresh(ex); throw ex; &#125; &#125;&#125; 看看 obtainFreshBeanFactory() 方法，该方法告诉了子类去刷新内部的 beanFactory 12345678910111213141516/** * Tell the subclass to refresh the internal bean factory. * 告诉子类去刷新内部的 beanFactory */protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; // 自己定义了抽象的 refreshBeanFactory() 方法，具体实现交给了自己的子类 refreshBeanFactory(); // getBeanFactory() 也是一个抽象方法，交由子类实现 // 看到这里是不是很容易想起 “模板方法模式”，父类在模板方法中定义好流程，定义好抽象方法 // 具体实现交由子类完成 ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); &#125; return beanFactory;&#125; 下面看一下 AbstractRefreshableApplicationContext 中对 refreshBeanFactory() 方法的实现。FileSystemXmlApplicationContext 从上层体系的各抽象类中继承了大量的方法实现，抽象类中抽取大量公共行为进行具体实现，留下 abstract 的个性化方法交给具体的子类实现，这是一个很好的 OOP 编程设计，我们在自己编码时也可以尝试这样设计自己的类图。理清 FileSystemXmlApplicationContext 的上层体系设计，就不易被各种设计模式搞晕咯。 12345678910111213141516171819202122232425262728/** * 在这里完成了容器的初始化，并赋值给自己私有的 beanFactory 属性，为下一步调用做准备 * 从父类 AbstractApplicationContext 继承的抽象方法，自己做了实现 */@Overrideprotected final void refreshBeanFactory() throws BeansException &#123; // 如果已经建立了 IoC 容器，则销毁并关闭容器 if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; // 创建 IoC 容器，DefaultListableBeanFactory 类实现了 ConfigurableListableBeanFactory 接口 DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); // 对 IoC 容器进行定制化，如设置启动参数，开启注解的自动装配等 customizeBeanFactory(beanFactory); // 载入 BeanDefinition，在当前类中只定义了抽象的 loadBeanDefinitions() 方法，具体实现 调用子类容器 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; // 给自己的属性赋值 this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125;&#125; AbstractXmlApplicationContext 中对 loadBeanDefinitions(DefaultListableBeanFactory beanFactory) 的实现。 123456789101112131415161718192021222324/* * 实现了基类 AbstractRefreshableApplicationContext 的抽象方法 */@Overrideprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // DefaultListableBeanFactory 实现了 BeanDefinitionRegistry 接口，在初始化 XmlBeanDefinitionReader 时 // 将 BeanDefinition 注册器注入该 BeanDefinition 读取器 // 创建用于从 Xml 中读取 BeanDefinition 的读取器，并通过回调设置到 IoC 容器中去，容器使用该读取器读取 BeanDefinition 资源 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); beanDefinitionReader.setEnvironment(this.getEnvironment()); // 为 beanDefinition 读取器设置 资源加载器，由于本类的基类 AbstractApplicationContext // 继承了 DefaultResourceLoader，因此，本容器自身也是一个资源加载器 beanDefinitionReader.setResourceLoader(this); // 设置 SAX 解析器，SAX（simple API for XML）是另一种 XML 解析方法。相比于 DOM，SAX 速度更快，占用内存更小。 // 它逐行扫描文档，一边扫描一边解析。相比于先将整个 XML 文件扫描近内存，再进行解析的 DOM，SAX 可以在解析文档的 // 任意时刻停止解析，但操作也比 DOM 复杂。 beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // 初始化 beanDefinition 读取器，该方法同时启用了 Xml 的校验机制 initBeanDefinitionReader(beanDefinitionReader); // Bean 读取器真正实现加载的方法 loadBeanDefinitions(beanDefinitionReader);&#125; 继续看 AbstractXmlApplicationContext 中 loadBeanDefinitions() 的重载方法。 1234567891011121314151617181920212223242526/** * 用传进来的 XmlBeanDefinitionReader 读取器加载 Xml 文件中的 BeanDefinition */protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; /** * ClassPathXmlApplicationContext 与 FileSystemXmlApplicationContext 在这里的调用出现分歧， * 各自按不同的方式加载解析 Resource 资源，最后在具体的解析和 BeanDefinition 定位上又会殊途同归。 */ // 获取存放了 BeanDefinition 的所有 Resource，FileSystemXmlApplicationContext 类未对 // getConfigResources() 进行重写，所以调用父类的，return null。 // 而 ClassPathXmlApplicationContext 对该方法进行了重写，返回设置的值 Resource[] configResources = getConfigResources(); if (configResources != null) &#123; // XmlBeanDefinitionReader 调用其父类 AbstractBeanDefinitionReader 的方法加载 BeanDefinition reader.loadBeanDefinitions(configResources); &#125; // 调用父类 AbstractRefreshableConfigApplicationContext 的实现， // 优先返回 FileSystemXmlApplicationContext 构造方法中调用 setConfigLocations() 方法设置的资源 String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; // XmlBeanDefinitionReader 调用其父类 AbstractBeanDefinitionReader 的方法从配置位置加载 BeanDefinition reader.loadBeanDefinitions(configLocations); &#125;&#125; AbstractBeanDefinitionReader 中对 loadBeanDefinitions 方法的各种重载及调用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * loadBeanDefinitions() 方法的重载方法之一，调用了另一个重载方法 loadBeanDefinitions(String) */public int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException &#123; Assert.notNull(locations, &quot;Location array must not be null&quot;); // 计数器，统计加载了多少个配置文件 int counter = 0; for (String location : locations) &#123; counter += loadBeanDefinitions(location); &#125; return counter;&#125;/** * 重载方法之一，调用了下面的 loadBeanDefinitions(String, Set&lt;Resource&gt;) 方法 */public int loadBeanDefinitions(String location) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(location, null);&#125;/** * 获取在 IoC 容器初始化过程中设置的资源加载器 */public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; // 在实例化 XmlBeanDefinitionReader 后 IoC 容器将自己注入进该读取器作为 resourceLoader 属性 ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException( &quot;Cannot import bean definitions from location [&quot; + location + &quot;]: no ResourceLoader available&quot;); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; try &#123; // 将指定位置的 BeanDefinition 资源文件解析为 IoC 容器封装的资源 // 加载多个指定位置的 BeanDefinition 资源文件 Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); // 委派调用其子类 XmlBeanDefinitionReader 的方法，实现加载功能 int loadCount = loadBeanDefinitions(resources); if (actualResources != null) &#123; for (Resource resource : resources) &#123; actualResources.add(resource); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Loaded &quot; + loadCount + &quot; bean definitions from location pattern [&quot; + location + &quot;]&quot;); &#125; return loadCount; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( &quot;Could not resolve bean definition resource pattern [&quot; + location + &quot;]&quot;, ex); &#125; &#125; else &#123; /** * ！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！ * AbstractApplicationContext 继承了 DefaultResourceLoader，所以 AbstractApplicationContext * 及其子类都会调用 DefaultResourceLoader 中的实现，将指定位置的资源文件解析为 Resource， * 至此完成了对 BeanDefinition 的资源定位 * ！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！ */ Resource resource = resourceLoader.getResource(location); // 从 resource 中加载 BeanDefinition，loadCount 为加载的 BeanDefinition 个数 // 该 loadBeanDefinitions() 方法来自其实现的 BeanDefinitionReader 接口， // 且本类是一个抽象类，并未对该方法进行实现。而是交由子类进行实现，如果是用 xml 文件进行 // IoC 容器的初始化，则调用 XmlBeanDefinitionReader 中的实现 int loadCount = loadBeanDefinitions(resource); if (actualResources != null) &#123; actualResources.add(resource); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Loaded &quot; + loadCount + &quot; bean definitions from location [&quot; + location + &quot;]&quot;); &#125; return loadCount; &#125;&#125; resourceLoader 的 getResource() 方法有多种实现，看清 FileSystemXmlApplicationContext 的继承体系就可以明确，其走的是 DefaultResourceLoader 中的实现。 123456789101112131415161718192021222324/** * 获取 Resource 的具体实现方法 */public Resource getResource(String location) &#123; Assert.notNull(location, &quot;Location must not be null&quot;); // 如果 location 是类路径的方式，返回 ClassPathResource 类型的文件资源对象 if (location.startsWith(CLASSPATH_URL_PREFIX)) &#123; return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader()); &#125; else &#123; try &#123; // 如果是 URL 方式，返回 UrlResource 类型的文件资源对象， // 否则将抛出的异常进入 catch 代码块，返回另一种资源对象 URL url = new URL(location); return new UrlResource(url); &#125; catch (MalformedURLException ex) &#123; // 如果既不是 classpath 标识，又不是 URL 标识的 Resource 定位，则调用容器本身的 // getResourceByPath() 方法获取 Resource。根据实例化的子类对象，调用其子类对象中 // 重写的此方法，如 FileSystemXmlApplicationContext 子类中对此方法的重写 return getResourceByPath(location); &#125; &#125;&#125; 其中的 getResourceByPath(location) 方法的实现则是在 FileSystemXmlApplicationContext 中完成的。 1234567891011/** * 实例化一个 FileSystemResource 并返回，以便后续对资源的 IO 操作 * 本方法是在 DefaultResourceLoader 的 getResource() 方法中被调用的， */@Overrideprotected Resource getResourceByPath(String path) &#123; if (path != null &amp;&amp; path.startsWith(&quot;/&quot;)) &#123; path = path.substring(1); &#125; return new FileSystemResource(path);&#125; 至此，我们可以看到，FileSystemXmlApplicationContext 的 getResourceByPath() 方法返回了一个 FileSystemResource 对象，接下来 spring 就可以对这个对象进行相关的 I/O 操作，进行 BeanDefinition 的读取和载入了。 原文)]]></content>
      <categories>
        <category>JavaNotes</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一篇关于我的真实回忆录]]></title>
    <url>%2Fpost%2FAbout-me%2F</url>
    <content type="text"><![CDATA[一篇关于我的真实回忆录 我出生在一个极其普通传统的家庭，从小被父母带到省会读书。 父母都是普通的农民，零几年在省会中做着餐饮小生意，那个时候餐饮行业还是很挣钱的，竞争相对小，所以我觉得我小学过得还是比较好的，我虽然不是一个很爱花钱的孩子，但是吃穿都不会少。 后来，小学快毕业，由于家中出了些变故，对于还没上中学的我来说这是一场灾难，我将从此面临各种挫折，困难，当时我便已经认定，我这一生，将会很坎坷，我只能靠自己的双手慢慢爬起来。 初中，我便开始自力更生，只要放假，就去找兼职，找寒暑假工，做过很多类型的工作。 发传单 打字员 硬件主板流水工作 饺子工 餐厅服务员 物业保安 工地（鬼门关走一回） 还有一些记不得了，暂时能想起这些，大概说下这些工作吧，记忆还是挺深刻的。 发传单发传单这种兼职相信很多学生都做过，是最直接的一种兼职。 初中不上课的周末，学校附近的开发商总会招兼职去发传单，所以会挤满了人，这是在红绿灯口给马路车辆发，还是很危险的，当然也没那意识，还因为这个，被警察叔叔带回去教育了一番，哈哈。 打字员这个工作是学校校医老师给我介绍的，我们经常有工作来往，所以有什么帮忙也都会找我。 这项工作是给一所中学的所有学生的体检数据录入到系统，高中部+初中部大概有几千人吧，当然还看到好多老同学在那所学校，哈哈。记得拿到体检表的时候也是惊了，十几打厚厚的文档袋装满了全校的学生体检数据，在我的笔记本上装上体检的系统，录完后导出备份。 这所学校的校医老师怀孕了，不能长期对着电脑，所以就把这项工作通过我们学校的校医外包给了我，正好，我很需要钱，所以就接下了，给了我七天的时间，我晚上熬夜打，只用了三天，三天500快。 硬件主板流水工作其实就是类似大厂里的流水工作，不过现在都机械化了，我去的也是老师给我介绍的，自己老公的公司，小公司，做硬件的，组装配件需要人工，有些主板焊锡有问题的需要处理一下，还有就是纯手工，拿镊子将那些元件点在主板上，工作类似流水线的工作，一天70，一般都是周末有空去。 饺子工这是我初中第一份暑假工，在一个小店里包饺子，老板和老板娘是五六十岁儿孙满堂的夫妇，人很好，虽然店小，但是还签了个字据（迷你版劳动合同）哈哈，大概意思就是我中途不能跑吧，不然就没工钱了，还摁了手印，现在想想真是有意思呢。我主要负责包饺子，擀皮，还有刷碗和收拾桌子吧，因为店小，杂活都是我干吧，后来也来了一个大学生姐姐，我稍微轻松些，感觉那时候干什么都有力气，能挣钱就行，这是我第一份暑假工（一个月600元）。 餐厅服务员这次是和同学一起去的打工的地方，也是围着周边一家一家找的，最终找到这家要暑假工的，做服务生有很多细节需要注意，有时候也挺无奈的，客人如果没有用完餐，作为服务生的你是不能下班的，要等所有客人都走了，你才能收拾残局再走，一般如果今天是自己加班，基本上都是凌晨才能走的，回家差不多一点了，做服务生还是挺辛苦的，有时候站一天腿都酸的。 物业保安保安这个工作让我觉得一个物业的服务能达到这种程度我是服了，虽然以我的体格根本驾驭不了这份工作吧，哈哈，这份工作是我上大学前的最后一份暑假工，一天工作十二小时。 开始这份工作是我自己在58上找的，去面试的时候，保安队长看了之后，直接说好一个月多少钱，换上衣服直接就开始干了，没错，到那面试谈妥换上衣服就开始先干，比较缺人手吧，虽然这么唐突，但是还是比较正规的，后来又办了银行卡，该走的流程都走了，其实原则是不招学生暑假工的，但是保安队长人还挺好，说别人问别说我是暑假工，于是就这样做了下去。 这份工作离我有些远，我每天骑自行车都要快一个小时，干十二个小时，后来我陆陆续续介绍了三个同学过来，但是都干几天就走了，确实很累，站岗要站一天，我同学脚穿着那不合脚的皮鞋都磨出水泡了，最后我坚持了下来吧。 开始我本来是站岗，后来，被调到了隔壁一期的院里，这个院子里的人要像上帝一样供着，这也是我为什么开头为什么说服务程度令我佩服。 这个院子小，岗位比较有限，保安加起来就五六个吧，地下停车场两个（东西各一个），地上监控室两个（一般是一个人巡逻一个在监控室），西门两个，一人一个对讲机，我是在监控室的，负责给业主开门，拿快递，拿报纸，每天还要给院子洒洒水（因为在马路在修高架，很多尘土）。 有一次停水，监控室也就我一个人，我要管着门口，还要去提水上楼给业主，院子里有部分老人，主管要求我们帮忙给提上楼，说时候当时真的觉得我一个人，分身几个角色。 有意思的是，我们上班管控其实很严格的，虽然我是在监控室里，但是平时是不让坐在里面的，让在门口站岗，我们主管很严格，每次看到我们坐在里面就回呵斥我们一下，我们队长也是一个脾气不好的老头，但是人心很好，有一次上夜班不小心睡着了，被拍照了，可能会罚款，我罚50，队长就是100，主管200，后来我队长和监管人员比较熟，也就没事儿了，一般不熟的人，都直接发微信群了，太难了。 后来我白班实在太忙受不了，就改上夜班了，凌晨十二点到第二天中午十二点，夜里只要不睡觉，看着监控，就好，还可以坐在那里，于是就拿出了我的《C Primer Plus 》 看了起来，哈哈，这也是我自学C语言的第一本书，视频看过郝斌C语言和Java系列吧，现在来看，郝斌的视频就太老了，不过很经典，郝斌老师讲课很有趣。这也让我觉得《C Primer Plus》不愧是一门经典畅销的专业书籍，讲的很细。 夜里的时间基本上都是这样消磨的，有时候在监控看到有人睡觉，就拿对讲机把对方喊醒：“检查的来了，检查的来了”，哈哈，我们相互传输信号，谁先遇到谁先喊，现在想想还真是有意思啊。 工地（鬼门关走一回）可能这份工作是我所有做的工作里最累，最委屈、最危险的工作了、这辈子都不想再去工地打工了。 工作环境是在三十几层的楼顶做钢结构，我属于零工的角色，帮着师傅抬个钢筋，给焊工搭把手，第一次通过那个吊梯上三十几层的楼顶，简直是吓尿了，一晃一晃的，我本身也恐高，后来慢慢才适应。 因为吃饭都是大锅饭，有一次食物中毒了，整个身体没有力气，发烧，然后就躺在那里，后来被包工头看见了，我就去看病了，输液花了五十吧，输完液，整个人都好多了，第二天接着上工了。 还有一次就是我给焊工搭把手，把眼睛给闪了，夜里那是真叫痛苦啊，整个眼睛都是涩痛的，闭不了，夜里拿湿毛巾垫在眼上缓解疼痛，那一夜我是在痛苦中度过的。 不过以上还不是最惨的，有一天，工头让所有人去另一个工地干活，说是要装玻璃，玻璃厂那边安排运输工把玻璃送到了目的地，那么后面，事故就来了。 运输玻璃的车子本身停的位置就很偏，玻璃是树立捆绑在车上的架子上的，一面各有三块玻璃，长有2米左右，宽一米5左右，后来工人要求再往后停一停，司机没有理会，说可以了。 结果，司机上车开始解绳，刚解开一遍的绳子，还没来得及反应，玻璃就开始往下倒了，一眨眼的功夫，五六十的那位老大爷被压在了玻璃下，司机的眼睛被划血流不止，另一位工友，压到了胯骨，骨折严重，而我则是从鬼门关走了一波，我腿上都溅上了他们的血，只差一点，我也被压在下面，可能就不会有这篇文章了吧。 被完全压在玻璃下的老大爷，第一时间，我和另一位有点小伤的工友一起把玻璃迅速搬开，拿开的时候，大爷的四肢都是朝前的，整个人像被压扁了一样，随后120来了之后，抢救已经无效，一个活生生的生命就这样从我眼前消失了，当时我吓傻了，随后就陪着工友去医院了。 因为这件事情，也不知道是怎么回事工头就跑了，我联系好多人，都无果，我的工钱就这样打了水漂，两个月白干，还差点丢了性命，从那刻起，我发誓，我再也不会来工地做任何工作。 以上就是我大学前，能想起的做过的工作，总结就是服务类的行业相对是需要用心还要用力的工作，挺辛苦的，工地这种纯卖力气的工作，只能向所有社会上的工人朋友致敬，希望少出现一些黑心不负责的老板，出卖的都是别人的血汗钱，良心怎能过的去。 通过这些兼职也差不多攒够了大学的学费以及花销，所以大学就没有太注重兼职了。 正是因为从小这样的生活环境，让我的性格也有些转变，其实有时也挺自卑的，毕业前从没有出过远门，没有出去玩过，没有坐过火车，让我对外界社会的一切都不是很了解，主要还是因为穷吧。 不过现在看来，对于我生活的唯一的目标就是能尝试没有尝试过的事物，做没有做过的事情，忠于自己的想法，做一个有原则的人，追寻自己认为对的生活。 不忘初心。]]></content>
      <categories>
        <category>生活记载</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人生一大极限挑战———我竟然走完了一百公里]]></title>
    <url>%2Fpost%2F100KM%2F</url>
    <content type="text"><![CDATA[K4426故事（续）———赴约 就那么随口的一个约定，我们四人便不约而同的在三月份就在微信群里开始讨论参加百公里徒步的事情，走 1 0 0 km 想想都那么有（花）趣（钱）刺（找）激（虐 :unamused:）。 百公里培训讲座园园 在群里发了百公里讲座的培训，我和 东东、君君 接着都报了名（结果只有我和 园园 去了 :sleeping:）。 哦，对了，这里我再介绍一下 园园 东东 君君 三人。 园园：电商行业，女 东东：电商行业，男 君君：IT行业（退伍兵） 男 以上三位都是我火车上结识的老乡，上篇文章有说到，这里就不多介绍了，回到正题。 那次培训报名，下了雨，一大早群里没动静，我以为都去了，就PDPD得起来去了公交站，到培训点那里要一个半小时。上了公交结果群里是这样的 园园 比较近，会比我先到，后来我们就在培训大厅会和了，这是火车上离别后的首次见面，这次讲座的内容，主要就是徒步的一些注意事项，对于我这种徒步小驴，收获还是挺大的。 培训比预定的时间快一些，下午4点半就结束了，出来后，我把今天的讲座内容发到了群里，艾特了下 东东、君君 。因为具体的报名时间还没有确定，我们约定好在活动开始报名前两周确定自己时间情况觉得是否能够组队参加（ps：往年都是组队才可以报名，人数齐了才可以报，貌似至少4人，后来得知几年改了报名规则，可以单人报名了，所以这种突发情况不能完成组队的顾虑就可以消除了）。 报名（名额 2 万人，报名费 150）磨坊百公里是深圳的一项全民公益性的大型徒步活动，2001年开始创办，第一届只有52人参与，今年是第十九届。在16年因为参与人数过多，起点是深圳湾，参与人达到6万人，据说这次的活动对当地市民造成了严重的影响，被一位市民举报，差点磨坊百公里这个活动就终结于16届，不过还好，经过与政府的协调，17年出发起点改在了大运体育中心并控制了报名人数。 不知不觉就到了报名的时间，在那一段时间里，掩盖不住心中的激动，上班的时候总是心不在焉的，哈哈，网上看装备，看注意事项，看官网论坛，看官方微信公众号，关注一切关于百公里的动态，终于盼来了报名。官方先放出了1000名赞助名额，通过好友助力的形式来提高中签率（类似买火车票那种加油），结果通过各种转发，完成了助力，坐等结果，官方剩下的1万9名额仍然报了名，会提升中签率，取两个渠道的其中一个，哪个先中给哪个。 就这样，我们老乡四人在群里聊的不亦乐乎，等待报名结果的日子也是很漫长的，可能也是这么多年报名被吐槽最多的一回（理解万岁）。 最后，终于迎来的报名结果，成功中签（编号：84227），我的是微时光的1000名额，这一千名都是8开头。 相继 园园、君君 也中签了，君君 最终也没有中，不过没中签也能空降，哈哈。 装备说到装备，也是纠结了好久，按照网上、培训讲座、微信群里的各种途径的建议综合下，我买了以下装备： 1、水袋背包（15升的，遵循尽量轻量化的原则） 2、护膝（不要长时间戴，影响血液循环，主要在后半程间歇性的戴）3、冰袖（这个我感觉要戴，不然真的会被晒死的）4、头巾（防晒）5、帽子（防晒）6、徒步鞋（推荐亚瑟士，切记不要穿登山鞋，太硬，还磨脚，穿软底的鞋子）7、5双五指袜（每十几公里换一双，最终我的脚都每起一个泡）8、登山杖（我觉得非大神，登山杖是必须的，它是支撑你后半程的助力，我后半程就靠这个拖着腿走完的，记得一定要直柄双杖）9、一件防晒衣（很薄的那种，夜里会比较凉，防止着凉）10、裤子（可以穿长运动裤，也可以运动短裤，我是那种篮球运动装，里面穿个紧身裤，外面再传一条短裤）11、充电宝（不多说了）12、垃圾袋（一路上垃圾桶很少，注意环保，我是拿了一个很大的绑在自己的背包上）13、运动饮料 (我出发前自己带了一升半的水，两升的水袋，起点有赞助商的饮料补给，可以少带些)14、士力架（这个很多人推荐，但是我真的真的不推荐，走到半路都化了，吃起来太腻了，真的是后悔带了，巧克力类的尽量都不要带，你根本吃不下，个人建议）15、牛肉干或牛肉丁（超市都有，包括能补充能量和盐分的鸭腿什么的也可以带，我主要包太小，不用带太多吃的，可能走都半路你就想把包扔了）16、榨菜（补充盐分）17、凡士林润肤霜（出发前涂脚趾间，大腿内侧，总之能摩擦的地方你都涂点，防止摩擦起水泡）18、云南白药创可贴（意外擦伤或起水泡）19、云南白药气雾剂（这个没买，买的双氯芬酸钠气雾剂，药店员推荐的）20、姨妈巾（夜用无翼卫生巾，很多人推荐，这个主要是垫脚的，比较软吧，我没有带，女队友带的有，我用了一次，感觉只要鞋子够软，这个其实作用不大） 我能想起来的装备，只有这些了，如果有漏的我再补充吧，基本上这些就够了。 行程安排因为起点在龙岗大运体育中心，大多数人都离这里比较远，早上6点钟就要出发了，所以要在6点之前赶到，要么就是在附近提前预定房间，要么就是驴友们一起拼车，早上早起过去。我是和附近的群友一起搭车过来的，有一个小伙伴自己开车过去，于是我就搭个顺风车过去，最终我们是四个人组成了拼车团（也成为了一起前行的队友）。 拉练拉练很重要，拉链很重要，拉链很重要，重要的事说三遍。但是很遗憾，作为一个苦逼的程序猿，并没有太多的拉练时间，也就平时公司每一周一次的羽毛球和篮球运动，可以忽略。 线路（全程101.4公里） 启程（2019-05-11）这一刻等了好久，大家都非常的兴奋，群里又开始活跃了起来，终于在出发的前一天晚上（周五），我早早的下了班，怀着激动的心情回去好好准备了下装备，群里我们约定好4点钟起床（真的是拼啊），我还专门早早的睡，晚上九点多就开始躺下，翻来覆去就是睡不着，可能真的是太激动了，不知我翻滚了多久，再次睁开眼睛就是被闹钟叫醒了，一想到该起床出发了，丝毫没有感到困意，赶紧看群里有没有消息，顺便发了条消息：“起床了，该出发了”，结果打脸了，我以为我是第一个起来的，别人早已经起来了，都太兴奋了，于是赶忙洗漱，背上装备，按照约定的地点，一分不差一分不多，成功启程。 一签本计划在起点与老乡们会和，看到下图我觉得我方了 人山人海，我们四人也只能先打卡过去，再联系，打卡点人真的是太多了。 当然，我们在起点留了张纪念照。 从左到右：亮亮（载我们来的车主），涛涛，丽丽，ME 随后我与园园进行微信位置共享，园园比我先到达，君君此时还在来的路上，园园穿着比较好认，我们很快就会和了，园园带了一个朋友（敏敏）过来，本应还有两个朋友一起的，结果走丢了，哈哈，感觉太正常不过，真的是一不留神就会走丢的，然后我们就先出发了，与君君联系后，一会再让他来赶上我们，此时我们的队伍很壮大（6人队），很容易走丢的，哈哈哈。 这一路上边说边走，阵势尤为强大，渐渐烈日升起，今天的天气是如此的热，开始打开包囊把防晒装备都戴上，不过园园和他的朋友背的吃的东西实在是太多了。下面比较搞笑的一幕就出现了，哈哈 我们才走了几公里，队伍便停下换姨妈巾了（园园提供的），我的脚涂了凡士林，就先没有换，真是一道美丽的风景线。 接着边走边聊，联系到了君君，他在我们后面前行，于是我们约定好在二签的时候集合。 这一路上，边走边看着队友们，生怕走丢了。到了梧桐山脚下的时候，我们停下歇息了会，开始调整，涂抹凡士林，换新的袜子，开始吃些东西，都来分享自己带的食物，就是在这个时候，我发现我买的士力架全部都软了，吃起来贼腻，真的后悔买这个了，所以我建议不要买士力架，周边的垃圾桶是比较少的，所以我就把带来的垃圾袋绑在了身上，供大家使用。 调整了大概十几分钟，我们开始起身继续行走，此时我也开始取下登山杖来助力行走，此时我的右腿其实是有些不舒服了，一可能就是因为我没有拉练，二就是我走路姿势的问题，我的左腿没有一点感觉，但是右腿已经有点累了，腿弯处有些酸，到了开始爬行梧桐山的时候，我的腿的疼痛感反应就有了，然后我就开始使用了护膝，护膝确实能够起到一定的作用，但是最后还是感觉腿胀胀的，坐下来休息时发现脚腕出现了血丝，然后我就把护膝给取了下来，莫非是血液不流通？总是护膝不能长时间戴着。 怎么说呢，那天的天气是特别热的，走梧桐山的时候，已经是正午，阳光爆裂的时刻，也是最缺水的一个阶段，好在28.3公里处有补给点，把水袋装满了水。 我从小到大都没有中暑过，就在这段起起伏伏的山坡中，连续中暑两次，身体出冷汗，胸口还有些刺痛感，全身无力，头晕目眩，说话喘不过气来，开始我以为只有我这样，敏敏也和我一样的症状，我觉得我一个男生好丢脸啊，女生还背着那么大的包都走到了这里，真的是挺佩服的，园园的脚已经起了很大的水泡，涛涛和亮亮都还没有事，莉莉在之前与我们走丢了，她已经在我们前面了，很佩服。 后来，山上有卖水的，我们都没有水了，买了五瓶（五元一瓶的农夫），接着我们继续前行，不知翻过了多少个坡，这段真的好痛苦，这期间我们补充了两次的食物，补充完能量的那瞬间是真的像脱胎换骨一样，豁然开朗了，起身继续前行，这之前我们有尝试使用小跑的方式行进，其实有时候小跑确实比走路痛苦少一些。经过这一段的行走，我们五人的速度已经开始拉开了，先是园园和亮亮在前面，然后又变我和园园在前面，然后我又和敏敏在最后面，中途分分合合了好几次，最后亮亮单独走在了最前面，我和园园在其后跟着，后来我和园园的距离也拉开了，此时离签到时间越来越近，总是被路上的志愿者调侃，走不完的两公里，也是哭笑不得啊。最后我赶上了亮亮，我撑着登山杖，支持着我的双腿，坚毅的往前行，心中默默念着：”快到了，快到了，坚持走下去”。 二签看到二签的那一刻，只有一座桥的间隔，这也是在痛苦中走的最舒心的一段，走在桥间，阵阵风出来，简直别提多舒服了，我和亮亮边走边聊，终于抵达了二签（小三洲）。于是开始给园园他们打电话，一直打不通，然后我们俩就在签到口等着，不一会儿，园园也赶了上来，表情也是很苦逼啊，随后涛涛，敏敏都赶了上来，就这样我们都到达了二签，很不容易，感觉这对于一个不经常运动人的，真的是太酸爽了，我们找了个角落大歇了一会，调整一下，涂一些凡士林，换换袜子，喷些药，我是累的瘫在了地上，此时感觉自己还不如女生，好惭愧，哈哈。 调整之后，我们起身准备出发，此时也联系到了我们K4426的老乡君君，他比我们后出发，还比我们先到二签，我们见到的时候，他整个人跟没事儿的人一样，不愧是当过兵的人。 此时敏敏、亮亮都决定退出了，因为后面的路更难走，时间也比较紧，当然，有时也要量力而行，如果身体传出了信号，就是否要考虑继续往前行了。 于是我们还合了影进行留念，就此与两位队友告别。 当然，我可能就比较倔了，我是从始至终都怀着要走完的决心，不竭尽全力，会很不甘心，园园也一样，涛涛在人群中走失了，目前就剩我们三人组了，我们三人火车上相识，作为同乡的三人，达成一致的目标，向终点继续前行。 在三签到达前的这一路上（40km-73km），我们的体力是不断下降的，路程也比较远，这期间只有君君的体力是最好的，君君来看着地形为我们调整配速，不过从二签离开总体感觉是比前40km舒服很多，因为没有了烈日，唯一就是园园前脚掌起水泡，走起来就很痛苦，但是她仍然坚持着，很是佩服。我的右腿又很不争气，两个脚也开始酸胀感增强。 走到天黑时，有一段很长的土坡路，很难走，有时候累的不行了，就一起停下来歇歇，手机都没有心思看，只想闭上眼睡一觉，看见地就想躺。 大概晚上10点钟时候，朋友圈是这样的 经过一次大歇，我们起身后，真的感觉就无法行走了一样，腿特别的胀痛，真的不要休息太久，包括抬腿回血的时候，不要超过三分钟，不然，起身后，真的是好难走，一路上的拉练也是很重要的，所以会常常看到这个画面。 这一路上，夜里仍然有很多人，我感觉这些人都好强，大多都是运动达人，身体素质很棒，有些边走边唱的，很悠哉，更牛的人，可能跑着就早已到了终点，剩下的就是我们这些来找虐的小驴了。 我们边走边听歌，靠着音乐来鼓舞着自己，园园喜欢听许巍，我喜欢听beyond，然后就是相互鼓舞着，不断的靠着那双手臂与毅力来拖着看似半身不遂的躯体。 也不知道走了多久，看到了有发盒饭吃的，自己打菜，可惜没有筷子，菜也基本剩残渣了，此时已经差不多快十一点了，还有几公里到达三签，然后我们继续前行了，这个时候也饿的不行了，只能再坚持坚持了，到了三签就有泡面了。 不知道拖着躯体前行了多久，终于走出了山，进入城区，此时看到有些人已经走不下去，开始打车到终点了，当然，我认为这样就不是真正意义上的百公里了，大部分人还是会遵守这个规则的，毕竟这是对个人一个挑战。 三签差不多走了1.5km，我们终于抵达三签（坪山体育馆），此时差不多凌晨十二点中，走路的速度像丧尸一样，晃晃悠悠地走进了签到点，我两眼到处寻找着泡面，已经饿的不行了，我们先找了个墙角落地休息，然后去拿了泡面，吃泡面的时候，别提有多爽了，真想吃饱喝足再睡上一大觉。 没有办法，时间不允许我们太多的停留，我们吃完，调整后，差不多快一点钟了，然后叫醒睡得正香的君君，我们算了下时间，我们这一路可能就没有太多时间停留了，要在上午9点半之前抵达，9点半就会关闭签到点了，所以以我们的行进速度，就很可能赶不上，于是备好水，继续前行。 那么三签到终点，有28km左右，有18km左右的路程是城区的马路，刚补充完能量的我们走这18km算是感觉比较舒坦的了，但是后10km简直就是炼狱一样。 在前18km这段路程中，相对我们走的速度并不是很快，中途我们商讨，在这比较好走的18km里，尽量使用小跑的速度，把速度提升上去，为后面的山路节省一些时间，后面可能就特别的难走。然后我们三人的速度也开始拉开，于是就分开先行，一段是走走又相遇，后来我一直使用小跑的方式，在前面行走，也不知道为什么，可能是能量补充的问题吧，此时收起登山杖，小跑起来其实比走路要舒服一点，园园和君君和我的距离在1-2km的距离，我们通过微信来联系着，我在前面打探着，中途路过了一个补给点，我看了下水带，差不多够用，就没有再装，然后联系了园园他们两个，记得补水，我此时稍作停歇后，继续前行。 中途，看到一个女孩有些眼熟，猛地一想，哦，原来是在三签吃泡面的时候坐在对面的那个姑娘，看起来很清新的软妹子，但是让我自愧不如，刮目相看的是她竟然没有用登山杖，这也太强了，我觉得要不是登山杖，我根本就走不到现在。她似乎也认出了我，只是各看了一眼，她的体力看起来还很好，我小跑一段后，稍慢一会，就被追上，然后我落后之后，就又追上了，就这样，像比赛一样，交叉追赶了几次后，我最终走在了前面，时间上来看，并不是很乐观，只能要更快些。 18km的这段，快到山脚入口的时候，遇到一位大姐，她也是组队过来，体力也不够了，于是落下了，然后这段我们结伴走了一段，刚到山口，就听到了喇叭里喊着：”还有最后10km”。感觉充满了希望，这10km感觉就像100km里，山路太痛苦。 刚入山口，没走多久，和那位大姐，我们就拉开了距离，我在前面继续前行，我也不知翻过了多少个山坡，累的已经真的要绝望了，然后突然后面跑着过来一位，我一看，原来是那位大姐，真的是深藏不露啊，她直接就开启了小跑模式，越走越远。此时的我已经没有力量开启小跑模式了，当然，我在城区小跑就是为了把时间节省在这段山路上，这段真的是痛不欲生，中途我好几次累的摊在地上歇息，在这一段里，天亮之后，烈日又升起，能做的只有前行，一路上被多少位志愿者大哥，说还有5km，然后走了一段又遇到一位志愿者同志，还说有5km（真的5km），我要哭了。 我不知道怎么表达，这种绝望感，我可以说这10km真的是在用毅力前行，我边走边估摸时间，要尽早赶到，所以基本上是不敢停留，这期间也联系了君君她们，她们两个在一起走着，距离应该还是在1-2km左右吧。 这10km里是把整座山绕了个圈，感觉翻不完的破，但是坡度还能接受，就是太漫长，此时的很多人的体力都已经不堪了，简直就是炼狱，最考验毅力的一段路程。 就这样，我靠着毅力终于走出了这座山，到达马路的那一刻，感觉胜利就在眼前，我看了下时间，还算充足，我开始坐在马路边调整，打开手机联系他们两个，没有打通，可能信号不好，路程还剩最后的2km，看到这个心理舒服多了。 就这样，越走越近，又到了最后的500m 终点没错，我成功了，我成功的走完了全程，到达终点的时候，我的内心是激动，但是我不得不像一个丧尸一样走进终点，我拿到了这块我认为我目前人生最大的一次挑战所获得的奖牌，很是欣慰。 此时，感觉身体已经感觉不是自己的了，找到一个角度坐下，开始联系园园他们，得知他们两个也刚刚下山，从时间上来看，还来得及，然后我就摊在那里，等待着队友的抵达。 期间，我又看到了在途中遇到的那个女孩，她也成功抵达了终点，在那段小跑阶段，她整体的状态还是不错的，看到她进入签到点时，腿已经有些瘸了，脸色有些泛白，但是这种体能已经甩我几条街了，看到她拿到奖牌的那刻，她欣然的笑了，这是一张胜利者的笑容，她成功了。 大概等了园园他们半个小时左右，成功抵达签到点，就这样，我们三人，来自K4426列车的同乡，因一句约定，共同走完了这100km，我们成功了。 没错，这就是来自K4426的故事。变态认证，哈哈，我这只能算初级变态]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>足迹</tag>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[来自《K4426》的故事]]></title>
    <url>%2Fpost%2FK4426%2F</url>
    <content type="text"><![CDATA[看到标题，可能会有些诧异！”K4426”?，这是什么标志呢？可能有人也能联想到。。。没错，就是一趟我认为最慢最慢最慢的绿皮火车。 春节，我很幸运的抢到了这张K4426的硬座？？没错，硬座，像这么便宜的车，硬卧完全抢不到好吗？高铁我完全没有抢的欲望（因为坐不起啊o(╥﹏╥)o），最崩溃的是这趟车是凌晨1点半的(＃￣～￣＃)。不知不觉就到了回村的日子，当天拎着箱子就到了公司，晚上加会班就直接去火车站了，和预想的一样，我是18年最后一个走的，叫好外卖，下好了火车上消磨时间的电视剧，那段比较火的《大江大河》，帅气的走出了写字楼。 按照掐好的时间，果然还是提前到了火车站，人真的是多的可怕，其实一个人出行，也挺不方便的，上个厕所，也没有人帮看下行李，不，上大号可以说基本排不上，果断放弃了。 凌晨一点钟，所有人都起身拥往进站口排队，看着这形形色色的人，可都是自己的老乡啊，大家看起来还都很精神，武警都上阵了，接着开门一个一个放行，很快，我也过了关卡，随着大部队朝着站内跑去。 这段路是如此的漫长，K4426在最后一段，跑了好久终于到了，验票上车，找到自己的位置，我是靠过道的位置（别人眼中最不好的位置），一共六个人，我静静的等待着。。。等了好久，终于来了一位女士，位置正对我，六个人，才来了一位，心中暗喜：最好都不来了，我可以躺着睡一晚了，哈哈！结果人越来越多，陆续又来了一对情侣，到了火车要快开动的前十分钟，剩下的那两个人都还没有到场（可能真的是把时间记成了下午一点半了吧！！），果真，火车开动了，那两个人也没有到来，不过还好，四个人共用六个位置，宽松了许多，可能最让我落差较大的就是人并没有我想象的那么多，难道是因为凌晨出发？ 就这样，这一晚我们邻座间都没有说什么话，倒是火车上各种推销嚷嚷个不停，夜里火车音乐声还不断，真不知道怎么想的，夜里真的及其痛苦，坐着很难入睡，下好的电视剧，完全没有精神看啊，所以，以后买长途火车票能躺着就别坐着。 就这样，不知不觉随着火车的汽笛声，天渐渐的亮了，抬头看到的仍是推销不断的推销员走来走去，邻座们也都醒来，当然，火车上少不了的就是泡面，走过看起来并不是很拥挤的过道，洗漱一番，清爽了许多，望着窗外的风景，吃起了我那碗香辣牛肉面。 时间不知道过了多久，也不知道是什么话题，邻座们之间也渐渐聊起了话题，很巧的是，我们这排，大家都是年轻人，有聊不完的话题，我暂且将旁边的情侣就简称男X，女Y吧，聊天得知对面的女士是我的老乡，简称A吧。 A是电商行业，我对此行业了解并不是很多，如果细说整个行业，分支可能就多了去了。XY年龄不大但也都结婚了，还没我大，但相貌看起来比我成熟许多，与我同行，我们聊了些关于行业的一些看法吧（瞎聊），还聊得不亦乐乎，头头是道，哈哈。边聊边吃，再加睡觉，不知不觉就快到了傍晚，二十多小时的行程，过去了一大半，于是乎，过道右手边的四人座中的两位B、C也加入了我们的聊天。很巧，B和A都是做电商的，A刚做不久，B已经做了很多年了吧，同行聊起来就是很投机啊，什么B2B,B2C,O2O关于电商营销，外贸什么的聊的也是我一脸懵，不过还好，大学学过一些电商的知识，有些还算明白。对了，还有C是退伍兵，和XYA一样刚来S不久，接着我们就聊起电影，户外，爱好之类的，贼搞笑，聊着聊着XY也到了站，剩下两站的车程，我们接着聊啊，聊着聊着，A便喊道：”我们建个群组吧！”，约定年后一起户外运动，大家相互留了微信。”那群组的名字就叫K4426吧!”,我提议道。哈哈，大家一并赞同。 就这样，K4426群组就这样成立了，到站后， 我们一并下了车，下车才凌晨两点，我离得比较近，打的士十几分钟便到了，到家中，与家人在被窝中聊着在外的故事，慢慢进入了梦乡。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>足迹</tag>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo 支持的通信协议]]></title>
    <url>%2Fpost%2FDubbo-Supported-Communication-Protocol%2F</url>
    <content type="text"><![CDATA[dubbo 支持的通信协议 dubbo 协议 dubbo://192.168.0.1:20188 默认就是走 dubbo 协议的，单一长连接，NIO 异步通信，基于 hessian 作为序列化协议 适用的场景就是：传输数据量很小（每次请求在 100kb 以内），但是并发量很高 为了要支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次！此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接就可以，可能总共就 100 个连接。然后后面直接基于长连接 NIO 异步通信，可以支撑高并发请求。 否则如果上亿次请求每次都是短连接的话，服务提供者会扛不住。 而且因为走的是单一长连接，所以传输数据量太大的话，会导致并发能力降低。所以一般建议是传输数据量很小，支撑高并发访问。 rmi 协议 走 java 二进制序列化，多个短连接，适合消费者和提供者数量差不多，适用于文件的传输，一般较少用 hessian 协议 走 hessian 序列化协议，多个短连接，适用于提供者数量比消费者数量还多，适用于文件的传输，一般较少用 http 协议 走 json 序列化 webservice 走 SOAP 文本序列化 dubbo 支持的序列化协议dubbo 实际基于不同的通信协议，支持 hessian、java 二进制序列化、json、SOAP 文本序列化多种序列化协议。 但是 hessian 是其默认的序列化协议。 原文：https://www.cnblogs.com/mengchunchen/p/10075125.html]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringCloud</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 静态资源访问原理解析]]></title>
    <url>%2Fpost%2FSpring-Boot-Static-Resource-Access%2F</url>
    <content type="text"><![CDATA[一 前言 springboot配置静态资源方式是多种多样，接下来我会介绍其中几种方式，并解析一下其中的原理。 二、使用properties属性进行配置 应该说 spring.mvc.static-path-pattern 和 spring.resources.static-locations这两属性是成对使用的，如果不明白其中的原理，总会出现资源404的情况。首先收一下spring.mvc.static-path-pattern代表的是一个Ant Path路径，例如resources/，表示当你的路径中存在resources/的时候才会处理请求。比如我们访问“http://localhost:8080/resources/xxx.js”时，很显然，springboot逻辑中会根据模式匹配对url进行匹配，匹配命中后，是如何再定位到具体的资源的呢？这时候spring.resources.static-locations的配置就起作用了。 忘记说了，在springboot中spring.mvc.static-path-pattern的默认值是/**，spring.resources.static-locations的默认值是classpath:/static,classpath:/public,classpath:/resources,classpath:/META-INF/resources,servlet context:/，springboot中相关的ResourceHttpRequestHandler就会去spring.resources.static-locations配置的所有路径中寻找资源文件。 所以我之前才说spring.mvc.static-path-pattern 和 spring.resources.static-locations这两属性是成对使用的。 三、springboot中默认对静态资源的处理 调试过程中，通过查看 org.springframework.web.servlet.DispatcherServlet中的handlerMappings变量，我们发现有一个很显眼的 resourceHandlerMapping ，这个是springboot为我们提供的一个默认的静态资源handler，通过全文搜索发现出现在org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport这个类中，也就是这个类包含了@EnableWebMvc注解中的大多数功能，更多的扩展功能请参考org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration。 resourceHandlerMapping 的定义如下。 /** * Return a handler mapping ordered at Integer.MAX_VALUE-1 with mapped * resource handlers. To configure resource handling, override * {@link #addResourceHandlers}. */ @Bean public HandlerMapping resourceHandlerMapping() { ResourceHandlerRegistry registry = new ResourceHandlerRegistry(this.applicationContext, this.servletContext, mvcContentNegotiationManager()); addResourceHandlers(registry); AbstractHandlerMapping handlerMapping = registry.getHandlerMapping(); if (handlerMapping != null) { handlerMapping.setPathMatcher(mvcPathMatcher()); handlerMapping.setUrlPathHelper(mvcUrlPathHelper()); handlerMapping.setInterceptors(new ResourceUrlProviderExposingInterceptor(mvcResourceUrlProvider())); handlerMapping.setCorsConfigurations(getCorsConfigurations()); } else { handlerMapping = new EmptyHandlerMapping(); } return handlerMapping; } 请大家先记住ResourceHandlerRegistry这个类。 首先看一下addResourceHandlers(registry);这个方法，父类DelegatingWebMvcConfiguration做了实现，如下。 private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) { this.configurers.addResourceHandlers(registry); } 其中WebMvcConfigurerComposite是操作了WebMvcConfigurer类型的对象的集合。在org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration这个springmvc的自动配置类中，有一个WebMvcConfigurer的实现类，如下。 // Defined as a nested config to ensure WebMvcConfigurerAdapter is not read when not // on the classpath @Configuration @Import(EnableWebMvcConfiguration.class) @EnableConfigurationProperties({ WebMvcProperties.class, ResourceProperties.class }) public static class WebMvcAutoConfigurationAdapter extends WebMvcConfigurerAdapter { ... @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { if (!this.resourceProperties.isAddMappings()) { logger.debug(&quot;Default resource handling disabled&quot;); return; } Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern(&quot;/webjars/**&quot;)) { customizeResourceHandlerRegistration( registry.addResourceHandler(&quot;/webjars/**&quot;) .addResourceLocations( &quot;classpath:/META-INF/resources/webjars/&quot;) .setCachePeriod(cachePeriod)); } String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) { customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); } } ... } 上面的addResourceHandlers方法中，增加了默认的mapping pattern = /webjars/** ，默认的resource location是classpath:/META-INF/resources/webjars/。正是这里的配置，我们在集成swagger的时候，就可以正常访问到swagger webjars中的js文件了。其中红色的代码部分就是用户可以自定义的默认静态资源访问方式，并通过ResourceHandlerRegistry对象进行注册。接着看一下mvcProperties和resourceProperties对应的类吧。 @ConfigurationProperties(“spring.mvc”)public class WebMvcProperties { … /** * Path pattern used for static resources. */ private String staticPathPattern = &quot;/**&quot;; ... } WebMvcProperties类中的staticPathPattern field 对应了spring.mvc.static-path-pattern这个属性，可以看到默认值是 “/**”。 @ConfigurationProperties(prefix = “spring.resources”, ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware { ..... private static final String[] SERVLET_RESOURCE_LOCATIONS = { &quot;/&quot; }; private static final String[] CLASSPATH_RESOURCE_LOCATIONS = { &quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;, &quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; }; private static final String[] RESOURCE_LOCATIONS; static { RESOURCE_LOCATIONS = new String[CLASSPATH_RESOURCE_LOCATIONS.length + SERVLET_RESOURCE_LOCATIONS.length]; System.arraycopy(SERVLET_RESOURCE_LOCATIONS, 0, RESOURCE_LOCATIONS, 0, SERVLET_RESOURCE_LOCATIONS.length); System.arraycopy(CLASSPATH_RESOURCE_LOCATIONS, 0, RESOURCE_LOCATIONS, SERVLET_RESOURCE_LOCATIONS.length, CLASSPATH_RESOURCE_LOCATIONS.length); } private String[] staticLocations = RESOURCE_LOCATIONS; ...... } ResourceProperties中staticLocations field 对应了 spring.resources.static-locations 这个属性。可以看到默认值是classpath:[/META-INF/resources/, /resources/, /static/, /public/], servlet context:/ 四、静态资源的Bean配置 在了解了springboot默认资源的配置的原理（即 spring.mvc.static-path-pattern 和 spring.resources.static-locations），我们可以增加一个WebMvcConfigurer类型的bean，来添加静态资源的访问方式，还记得上面说的“请记住ResourceHandlerRegistry这个类“，下面就用到了哦。 @Configuration public class ResourceWebMvcConfigurer extends WebMvcConfigurerAdapter { @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(&quot;/resources/**&quot;) .addResourceLocations(&quot;classpath:/public-resources/&quot;) .setCacheControl(CacheControl.maxAge(1, TimeUnit.HOURS).cachePublic()); } } 那么当访问路径中包含&quot;resources/**&quot;的时候，resource handler就会去classpath:/public-resources目录下寻找了。 五、静态资源的查找 参考org.springframework.web.servlet.resource.ResourceHttpRequestHandler，ResourceHttpRequestHandler中通过org.springframework.web.servlet.resource.PathResourceResolver进行查找。 举个例子，下图是springboot打包之后的目录结构，现在想要通过url访问application.properties文件，springboot默认的静态文件配置可以吗？当然需要用事实来说话了。 我们已经知道，默认的resource locations中有个 servlet-context:/，访问你的url是http://localhost:8080/工程名/application.properties，调试一下PathResourceResolver，结果如下。 发现servlet-context的根路径如上图所示，查看一下这个路径对应的目录，发现什么都没有，所以很显然无法找到我们要找的文件了。毕竟一般使用springboot都是jar项目，servlet-context path下没有用户自定义的资源。 六、其他方式 在Servlet3协议规范中，包含在JAR文件/META-INFO/resources/路径下的资源可以直接访问了。如果将springboot项目打包成war包，可以配置一个默认的servlet。在WebMvcConfigurationSupport中已经定义好了，不过默认是一个EmptyHandlerMapping。 /** * Return a handler mapping ordered at Integer.MAX_VALUE with a mapped * default servlet handler. To configure &quot;default&quot; Servlet handling, * override {@link #configureDefaultServletHandling}. */ @Bean public HandlerMapping defaultServletHandlerMapping() { DefaultServletHandlerConfigurer configurer = new DefaultServletHandlerConfigurer(servletContext); configureDefaultServletHandling(configurer); AbstractHandlerMapping handlerMapping = configurer.getHandlerMapping(); handlerMapping = handlerMapping != null ? handlerMapping : new EmptyHandlerMapping(); return handlerMapping; } 可以通过自定义一个WebMvcConfigurer类型的bean，改写configureDefaultServletHandling 方法，如下。 @Configuration public class MyWebConfigurer extends WebMvcConfigurerAdapter { @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) { configurer.enable(); } } 这样就设置了一个默认的servlet，在加载静态资源的时候就会按照servelt方式去加载了。 转自:https://www.cnblogs.com/hujunzheng/p/9682960.html]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用了五年的笔记本键盘坏掉了]]></title>
    <url>%2Fpost%2Flaptop-keyboard-disable-enable%2F</url>
    <content type="text"><![CDATA[用了五年的笔记本，在今天键盘突然就阵亡了，毫无征兆o(╥﹏╥)o.键盘失灵的键位还特别的有规律，让我有点怀疑并不是硬件的问题。于是就网上找了各种方法都无果，最后就放大招，重装了系统。。。。。很遗憾，重装仍然无用，可能真的是坏掉了吧，感觉也没有修的价值了，果断某东趁着活动剁手买了款机械键盘，真香~(#^.^#)，每次开机，由于键盘内部可能存在接触不良的情况，个别键总是抖动，让我无法进行操作。 果断一顿操作： WIN+R打开CMD命令行输入以下命令 禁用内置键盘 sc config i8042prt start= disabled 启用内置键盘 sc config i8042prt start= auto 注意:等号后面有一个空格,不要漏了]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>dos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud微服务版本灰度发布新神器]]></title>
    <url>%2Fpost%2Fspring-cloud-version-god-tool%2F</url>
    <content type="text"><![CDATA[强烈建议star、fork该项目，该项目可以作为学习改造Spring Cloud组件的案例项目。 Nepxion Discovery是一款对Spring Cloud的服务注册发现的增强中间件，其功能包括多版本灰度发布，黑/白名单的IP地址过滤，限制注册等，支持Eureka、Consul和Zookeeper。现有的Spring Cloud微服务可以方便引入该插件，代码零侵入，使用者只需要做如下简单的事情： 引入相关Plugin Starter依赖到pom.xml 必须为微服务定义一个版本号（version），在application.properties或者yaml的metadata里 必须为微服务自定义一个便于为微服务归类的Key，例如组名（group）或者应用名（application），在application.properties或者yaml的metadata里，便于远程配置中心推送和灰度界面分析 使用者只需要关注相关规则推送。可以采用如下方式之一 通过远程配置中心推送规则 通过控制台界面推送规则 通过客户端工具（例如Postman）推送推测 Quick Start 图形化演示操作 请访问http://www.iqiyi.com/w_19rzwzovrl.html，视频清晰度改成720P，然后最大化播放 请访问https://pan.baidu.com/s/1eq_N56VbgSCaTXYQ5aKqiA，获取更清晰的视频 更多教程和示例查看最下面的“示例演示”， 痛点 现有Spring Cloud的痛点 如果你是运维负责人，是否会经常发现，你掌管的测试环境中的服务注册中心，被一些不负责的开发人员把他本地开发环境注册上来，造成测试人员测试失败。你希望可以把本地开发环境注册给屏蔽掉，不让注册 如果你是运维负责人，生产环境的某个微服务集群下的某个实例，暂时出了问题，但又不希望它下线。你希望可以把该实例给屏蔽掉，暂时不让它被调用 如果你是业务负责人，鉴于业务服务的快速迭代性，微服务集群下的实例发布不同的版本。你希望根据版本管理策略进行路由，提供给下游微服务区别调用，达到多版本灰度访问控制 如果你是测试负责人，希望对微服务做A/B测试，那么通过动态改变版本达到该目的 简介 实现对基于Spring Cloud的微服务和Zuul网关的支持 具有极大灵活性 - 支持在任何环节做过滤控制和版本灰度发布 具有极小限制性 - 只要开启了服务注册发现，程序入口加了@EnableDiscoveryClient 实现服务注册层面的控制 基于黑/白名单的IP地址过滤机制禁止对相应的微服务进行注册 基于最大注册数的限制微服务注册。一旦微服务集群下注册的实例数目已经达到上限，将禁止后续的微服务进行注册 实现服务发现层面的控制 基于黑/白名单的IP地址过滤机制禁止对相应的微服务被发现 基于版本配对，通过对消费端和提供端可访问版本对应关系的配置，在服务发现和负载均衡层面，进行多版本访问控制 实现灰度发布 通过规则改变，实现灰度发布 通过版本切换，实现灰度发布 实现通过XML进行上述规则的定义 实现通过事件总线机制（EventBus）的功能，实现发布/订阅功能 对接远程配置中心，默认集成阿里巴巴的Nacos，异步接受远程配置中心主动推送规则信息，动态改变微服务的规则 结合Spring Boot Actuator，异步接受Rest主动推送规则信息，动态改变微服务的规则 结合Spring Boot Actuator，动态改变微服务的版本 在服务注册层面的控制中，一旦禁止注册的条件触发，主动推送异步事件，以便使用者订阅 实现通过Listener机制进行扩展 使用者可以自定义更多的规则过滤条件 使用者可以对服务注册发现核心事件进行监听 实现支持Spring Boot Actuator和Swagger集成 实现独立控制台，支持对规则和版本集中管理，未来考虑界面实现 实现支持未来扩展更多的服务注册中心 实现图形化的灰度发布功能 名词解释 IP地址，即根据微服务上报的它所在机器的IP地址。本系统内部强制以IP地址上报，禁止HostName上报，杜绝Spring Cloud应用在Docker或者Kubernetes部署时候出现问题 本地版本，即初始化读取本地配置文件获取的版本，也可以是第一次读取远程配置中心获取的版本。本地版本和初始版本是同一个概念 动态版本，即灰度发布时的版本。动态版本和灰度版本是同一个概念 本地规则，即初始化读取本地配置文件获取的规则，也可以是第一次读取远程配置中心获取的规则。本地规则和初始规则是同一个概念 动态规则，即灰度发布时的规则。动态规则和灰度规则是同一个概念 事件总线，即基于Google Guava的EventBus构建的组件。在使用上，通过事件总线推送动态版本和动态规则的时候，前者只支持异步，后者支持异步和同步 远程配置中心，即可以存储规则配置XML格式的配置中心，可以包括不限于Apollo，DisConf，Spring Cloud Config 场景 黑/白名单的IP地址注册的过滤 开发环境的本地微服务（例如IP地址为172.16.0.8）不希望被注册到测试环境的服务注册发现中心，那么可以在配置中心维护一个黑/白名单的IP地址过滤（支持全局和局部的过滤）的规则 我们可以通过提供一份黑/白名单达到该效果 最大注册数的限制的过滤 当某个微服务注册数目已经达到上限（例如10个），那么后面起来的微服务，将再也不能注册上去 黑/白名单的IP地址发现的过滤 开发环境的本地微服务（例如IP地址为172.16.0.8）已经注册到测试环境的服务注册发现中心，那么可以在配置中心维护一个黑/白名单的IP地址过滤（支持全局和局部的过滤）的规则，该本地微服务不会被其他测试环境的微服务所调用 我们可以通过推送一份黑/白名单达到该效果 多版本灰度访问控制 A服务调用B服务，而B服务有两个实例（B1、B2），虽然三者相同的服务名，但功能上有差异，需求是在某个时刻，A服务只能调用B1，禁止调用B2。在此场景下，我们在application.properties里为B1维护一个版本为1.0，为B2维护一个版本为1.1 我们可以通过推送A服务调用某个版本的B服务对应关系的配置，达到某种意义上的灰度控制，切换版本的时候，我们只需要再次推送即可 动态改变微服务版本 在A/B测试中，通过动态改变版本，不重启微服务，达到访问版本的路径改变 架构 简单描述一下，本系统的核心模块“基于版本控制的灰度发布”，从网关（Zuul）开始的灰度发布操作过程 灰度发布前 假设当前生产环境，调用路径为网关(V1.0)-&gt;服务A(V1.0)-&gt;服务B(V1.0) 运维将发布新的生产环境，部署新服务集群，服务A(V1.1)，服务B(V1.1) 由于网关(1.0)并未指向服务A(V1.1)，服务B(V1.1)，所以它们是不能被调用的 灰度发布中 新增用作灰度发布的网关(V1.1)，指向服务A(V1.1)-&gt;服务B(V1.1) 灰度网关(V1.1)发布到服务注册发现中心，但禁止被服务发现，网关外的调用进来无法负载均衡到网关(V1.1)上 在灰度网关(V1.1)-&gt;服务A(V1.1)-&gt;服务B(V1.1)这条调用路径做灰度测试 灰度测试成功后，把网关(V1.0)指向服务A(V1.1)-&gt;服务B(V1.1) 灰度发布后 下线服务A(V1.0)，服务B(V1.0)，灰度成功 灰度网关(V1.1)可以不用下线，留作下次版本上线再次灰度发布 架构图 兼容 版本兼容情况 Spring Cloud F版，请采用4.x.x版本，具体代码参考master分支 Spring Cloud C版、D版和E版，请采用3.x.x版本，具体代码参考Edgware分支 4.x.x版本由于Swagger和Spring Boot 2.x.x版本的Actuator用法有冲突，故暂时不支持Endpoint功能，其他功能和3.x.x版本一致 中间件兼容情况 Consul Spring Cloud F版，最好采用Consul的1.2.1服务器版本（或者更高），从https://releases.hashicorp.com/consul/1.2.1/获取 Spring Cloud C版、D版和E版，必须采用Consul的0.9.3服务器版本（或者更低），从https://releases.hashicorp.com/consul/0.9.3/获取 Zookeeper Spring Cloud F版，必须采用Zookeeper的3.5.x服务器版本（或者更高） Spring Cloud C版、D版和E版，最好采用Zookeeper的3.5.0以下服务器版本（或者更低） Eureka 跟Spring Cloud版本保持一致 依赖 微服务选择相应的插件引入，最后一个如需对接Nacos远程配置中心，则引入 &lt;dependency&gt; &nbsp; &nbsp;&lt;groupId&gt;com.nepxion&lt;/groupId&gt; &nbsp; &nbsp;&lt;artifactId&gt;discovery-plugin-starter-eureka&lt;/artifactId&gt; &nbsp; &nbsp;&lt;version&gt;${discovery.plugin.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &nbsp; &nbsp;&lt;groupId&gt;com.nepxion&lt;/groupId&gt; &nbsp; &nbsp;&lt;artifactId&gt;discovery-plugin-starter-consul&lt;/artifactId&gt; &nbsp; &nbsp;&lt;version&gt;${discovery.plugin.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &nbsp; &nbsp;&lt;groupId&gt;com.nepxion&lt;/groupId&gt; &nbsp; &nbsp;&lt;artifactId&gt;discovery-plugin-starter-zookeeper&lt;/artifactId&gt; &nbsp; &nbsp;&lt;version&gt;${discovery.plugin.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &nbsp; &nbsp;&lt;groupId&gt;com.nepxion&lt;/groupId&gt; &nbsp; &nbsp;&lt;artifactId&gt;discovery-plugin-config-center-extension-nacos&lt;/artifactId&gt; &nbsp; &nbsp;&lt;version&gt;${discovery.plugin.version}&lt;/version&gt;&lt;/dependency&gt; 独立控制台引入，最后一个如需对接Nacos远程配置中心，则引入 &lt;dependency&gt; &nbsp; &nbsp;&lt;groupId&gt;com.nepxion&lt;/groupId&gt; &nbsp; &nbsp;&lt;artifactId&gt;discovery-console-starter&lt;/artifactId&gt; &nbsp; &nbsp;&lt;version&gt;${discovery.plugin.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &nbsp; &nbsp;&lt;groupId&gt;com.nepxion&lt;/groupId&gt; &nbsp; &nbsp;&lt;artifactId&gt;discovery-console-extension-nacos&lt;/artifactId&gt; &nbsp; &nbsp;&lt;version&gt;${discovery.plugin.version}&lt;/version&gt;&lt;/dependency&gt; 工程 工程名 描述 discovery-plugin-framework 核心框架 discovery-plugin-framework-eureka 核心框架的Eureka实现 discovery-plugin-framework-consul 核心框架的Consul实现 discovery-plugin-framework-zookeeper 核心框架的Zookeeper实现 discovery-plugin-config-center 配置中心实现 discovery-plugin-config-center-extension-nacos 配置中心的Nacos扩展 discovery-plugin-admin-center 管理中心实现 discovery-plugin-starter-eureka Eureka Starter discovery-plugin-starter-consul Consul Starter discovery-plugin-starter-zookeeper Zookeeper Starter discovery-console 独立控制台，提供给UI discovery-console-extension-nacos 独立控制台的Nacos扩展 discovery-console-starter Console Starter discovery-console-desktop 图形化灰度发布等桌面程序 discovery-springcloud-example-console 独立控制台示例 discovery-springcloud-example-eureka Eureka服务器 discovery-springcloud-example 灰度发布等示例 规则和策略 规则示例 请不要被吓到，我只是把注释写的很详细而已，里面配置没几行 &lt;?xml version=”1.0” encoding=”UTF-8”?&gt;&lt;rule&gt; &nbsp; &nbsp;&lt;!– 如果不想开启相关功能，只需要把相关节点删除即可，例如不想要黑名单功能，把blacklist节点删除 –&gt; &nbsp; &nbsp;&lt;register&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 服务注册的黑/白名单注册过滤，只在服务启动的时候生效。白名单表示只允许指定IP地址前缀注册，黑名单表示不允许指定IP地址前缀注册。每个服务只能同时开启要么白名单，要么黑名单 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– filter-type，可选值blacklist/whitelist，表示白名单或者黑名单 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– service-name，表示服务名 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– filter-value，表示黑/白名单的IP地址列表。IP地址一般用前缀来表示，如果多个用“;”分隔，不允许出现空格 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示下面所有服务，不允许10.10和11.11为前缀的IP地址注册（全局过滤） –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;blacklist filter-value=”10.10;11.11”&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示下面服务，不允许172.16和10.10和11.11为前缀的IP地址注册 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service service-name=”discovery-springcloud-example-a” filter-value=”172.16”/&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;/blacklist&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– &lt;whitelist filter-value=””&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service service-name=”” filter-value=””/&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;/whitelist&gt; &nbsp;–&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 服务注册的数目限制注册过滤，只在服务启动的时候生效。当某个服务的实例注册达到指定数目时候，更多的实例将无法注册 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– service-name，表示服务名 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– filter-value，表示最大实例注册数 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示下面所有服务，最大实例注册数为10000（全局配置） –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;count filter-value=”10000”&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示下面服务，最大实例注册数为5000，全局配置值10000将不起作用，以局部配置值为准 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service service-name=”discovery-springcloud-example-a” filter-value=”5000”/&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;/count&gt; &nbsp; &nbsp;&lt;/register&gt; &nbsp; &nbsp;&lt;discovery&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 服务发现的黑/白名单发现过滤，使用方式跟“服务注册的黑/白名单过滤”一致 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示下面所有服务，不允许10.10和11.11为前缀的IP地址被发现（全局过滤） –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;blacklist filter-value=”10.10;11.11”&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示下面服务，不允许172.16和10.10和11.11为前缀的IP地址被发现 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service service-name=”discovery-springcloud-example-b” filter-value=”172.16”/&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;/blacklist&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 服务发现的多版本灰度访问控制 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– service-name，表示服务名 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– version-value，表示可供访问的版本，如果多个用“;”分隔，不允许出现空格 –&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;version&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示消费端服务a的1.0，允许访问提供端服务b的1.0和1.1版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-a” provider-service-name=”discovery-springcloud-example-b” consumer-version-value=”1.0” provider-version-value=”1.0;1.1”/&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示消费端服务b的1.0，允许访问提供端服务c的1.0和1.1版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-b” provider-service-name=”discovery-springcloud-example-c” consumer-version-value=”1.0” provider-version-value=”1.0;1.1”/&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示消费端服务b的1.1，允许访问提供端服务c的1.2版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-b” provider-service-name=”discovery-springcloud-example-c” consumer-version-value=”1.1” provider-version-value=”1.2”/&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;/version&gt; &nbsp; &nbsp;&lt;/discovery&gt;&lt;/rule&gt; 多版本灰度规则策略 版本策略介绍1. 标准配置，举例如下 &nbsp; &lt;service consumer-service-name=”a” provider-service-name=”b” consumer-version-value=”1.0” provider-version-value=”1.0,1.1”/&gt; 表示消费端1.0版本，允许访问提供端1.0和1.1版本2. 版本值不配置，举例如下 &nbsp; &lt;service consumer-service-name=”a” provider-service-name=”b” provider-version-value=”1.0,1.1”/&gt; 表示消费端任何版本，允许访问提供端1.0和1.1版本 &nbsp; &lt;service consumer-service-name=”a” provider-service-name=”b” consumer-version-value=”1.0”/&gt; 表示消费端1.0版本，允许访问提供端任何版本 &nbsp; &lt;service consumer-service-name=”a” provider-service-name=”b”/&gt; 表示消费端任何版本，允许访问提供端任何版本3. 版本值空字符串，举例如下 &nbsp; &lt;service consumer-service-name=”a” provider-service-name=”b” consumer-version-value=”” provider-version-value=”1.0,1.1”/&gt; 表示消费端任何版本，允许访问提供端1.0和1.1版本 &nbsp; &lt;service consumer-service-name=”a” provider-service-name=”b” consumer-version-value=”1.0” provider-version-value=””/&gt; 表示消费端1.0版本，允许访问提供端任何版本 &nbsp; &lt;service consumer-service-name=”a” provider-service-name=”b” consumer-version-value=”” provider-version-value=””/&gt; 表示消费端任何版本，允许访问提供端任何版本4. 版本对应关系未定义，默认消费端任何版本，允许访问提供端任何版本特殊情况处理，在使用上需要极力避免该情况发生1. 消费端的application.properties未定义版本号，则该消费端可以访问提供端任何版本2. 提供端的application.properties未定义版本号，当消费端在xml里不做任何版本配置，才可以访问该提供端 动态改变规则策略 微服务启动的时候，由于规则（例如：rule.xml）已经配置在本地，使用者希望改变一下规则，而不重启微服务，达到规则的改变 规则分为本地规则和动态规则 本地规则是通过在本地规则（例如：rule.xml）文件定义的，也可以从远程配置中心获取，在微服务启动的时候读取 动态规则是通过POST方式动态设置，或者由远程配置中心推送设置 规则初始化的时候，如果接入了远程配置中心，先读取远程规则，如果不存在，再读取本地规则文件 多规则灰度获取规则的时候，先获取动态规则，如果不存在，再获取本地规则 动态改变版本策略 微服务启动的时候，由于版本已经写死在application.properties里，使用者希望改变一下版本，而不重启微服务，达到访问版本的路径改变 版本分为本地版本和动态版本 本地版本是通过在application.properties里配置的，在微服务启动的时候读取 动态版本是通过POST方式动态设置 多版本灰度获取版本值的时候，先获取动态版本，如果不存在，再获取本地版本 黑/白名单的IP地址注册的过滤策略 微服务启动的时候，禁止指定的IP地址注册到服务注册发现中心。支持黑/白名单，白名单表示只允许指定IP地址前缀注册，黑名单表示不允许指定IP地址前缀注册 全局过滤，指注册到服务注册发现中心的所有微服务，只有IP地址包含在全局过滤字段的前缀中，都允许注册（对于白名单而言），或者不允许注册（对于黑名单而言） 局部过滤，指专门针对某个微服务而言，那么真正的过滤条件是全局过滤+局部过滤结合在一起 最大注册数的限制的过滤策略 微服务启动的时候，一旦微服务集群下注册的实例数目已经达到上限（可配置），将禁止后续的微服务进行注册 全局配置值，只下面配置所有的微服务集群，最多能注册多少个 局部配置值，指专门针对某个微服务而言，那么该值如存在，全局配置值失效 黑/白名单的IP地址发现的过滤策略 微服务启动的时候，禁止指定的IP地址被服务发现。它使用的方式和“黑/白名单的IP地址注册的过滤”一致 版本属性字段定义策略 不同的服务注册发现组件对应的版本配置值 # Eureka configeureka.instance.metadataMap.version=1.0eureka.instance.metadataMap.group=xxx-service-group# 奇葩的Consul配置（参考https://springcloud.cc/spring-cloud-consul.html - 元数据和Consul标签）# Consul config（多个值用“,”分隔，例如version=1.0,value=abc）spring.cloud.consul.discovery.tags=version=1.0,group=xxx-service-group# Zookeeper configspring.cloud.zookeeper.discovery.metadata.version=1.0spring.cloud.zookeeper.discovery.metadata.group=xxx-service-group 功能开关策略 # Plugin config# 开启和关闭服务注册层面的控制。一旦关闭，服务注册的黑/白名单过滤功能将失效，最大注册数的限制过滤功能将失效。缺失则默认为truespring.application.register.control.enabled=true# 开启和关闭服务发现层面的控制。一旦关闭，服务多版本调用的控制功能将失效，动态屏蔽指定IP地址的服务实例被发现的功能将失效。缺失则默认为truespring.application.discovery.control.enabled=true# 开启和关闭通过Rest方式对规则配置的控制和推送。一旦关闭，只能通过远程配置中心来控制和推送。缺失则默认为truespring.application.config.rest.control.enabled=true# 本地规则文件的路径，支持两种方式：classpath:rule.xml - 规则文件放在resources目录下，便于打包进jar；file:rule.xml - 规则文件放在工程根目录下，放置在外部便于修改。缺失则默认为不装载本地规则spring.application.config.path=classpath:rule.xml# 为微服务归类的Key，一般通过group字段来归类，例如eureka.instance.metadataMap.group=xxx-group或者eureka.instance.metadataMap.application=xxx-application。缺失则默认为group# spring.application.group.key=group# spring.application.group.key=application 配置中心 跟远程配置中心整合 本系统默认跟Nacos集成，如何安装使用，请参考https://github.com/alibaba/nacos。使用者也可以跟携程Apollo，百度DisConf等远程配置中心整合，实现规则读取和订阅 拉取配置，参考discovery-plugin-config-center-extension-nacos工程 推送配置，参考discovery-console-extension-nacos工程 管理中心 PORT端口号为server.port或者management.port都可以（management.port开放只支持3.x.x版本） 配置接口 版本接口 路由接口 参考Swagger界面，如下图 独立控制台 为UI提供相关接口，包括 一系列批量功能 跟Nacos集成，实现配置推送和清除 PORT端口号为server.port或者management.port都可以（management.port开放只支持3.x.x版本） 控制台接口 参考Swagger界面，如下图 扩展和自定义更多规则或者监听 使用者可以继承如下类 AbstractRegisterListener，实现服务注册的扩展和监听 AbstractDiscoveryListener，实现服务发现的扩展和监听，注意，在Consul下，同时会触发service和management两个实例的事件，需要区别判断，如下图 集成了健康检查的Consul控制台 示例演示 场景描述 本例将模拟一个较为复杂的场景，如下图 系统部署情况： 网关Zuul集群部署了1个 微服务集群部署了3个，分别是A服务集群、B服务集群、C服务集群，分别对应的实例数为2、2、3 微服务集群的调用关系为网关Zuul-&gt;服务A-&gt;服务B-&gt;服务C 系统调用关系 网关Zuul的1.0版本只能调用服务A的1.0版本，网关Zuul的1.1版本只能调用服务A的1.1版本 服务A的1.0版本只能调用服务B的1.0版本，服务A的1.1版本只能调用服务B的1.1版本 服务B的1.0版本只能调用服务C的1.0和1.1版本，服务B的1.1版本只能调用服务C的1.2版本 用规则来表述上述关系 &lt;?xml version=”1.0” encoding=”UTF-8”?&gt;&lt;rule&gt; &nbsp; &nbsp;&lt;discovery&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;version&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示网关z的1.0，允许访问提供端服务a的1.0版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-zuul” provider-service-name=”discovery-springcloud-example-a” consumer-version-value=”1.0” provider-version-value=”1.0”/&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示网关z的1.1，允许访问提供端服务a的1.1版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-zuul” provider-service-name=”discovery-springcloud-example-a” consumer-version-value=”1.1” provider-version-value=”1.1”/&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示消费端服务a的1.0，允许访问提供端服务b的1.0版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-a” provider-service-name=”discovery-springcloud-example-b” consumer-version-value=”1.0” provider-version-value=”1.0”/&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示消费端服务a的1.1，允许访问提供端服务b的1.1版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-a” provider-service-name=”discovery-springcloud-example-b” consumer-version-value=”1.1” provider-version-value=”1.1”/&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示消费端服务b的1.0，允许访问提供端服务c的1.0和1.1版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-b” provider-service-name=”discovery-springcloud-example-c” consumer-version-value=”1.0” provider-version-value=”1.0;1.1”/&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;!– 表示消费端服务b的1.1，允许访问提供端服务c的1.2版本 –&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-b” provider-service-name=”discovery-springcloud-example-c” consumer-version-value=”1.1” provider-version-value=”1.2”/&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;/version&gt; &nbsp; &nbsp;&lt;/discovery&gt;&lt;/rule&gt; 上述微服务分别见discovery-springcloud-example字样的8个DiscoveryApplication，分别对应各自的application.properties。这8个应用，对应的版本和端口号如下表 微服务 服务端口 管理端口 版本 A1 1100 5100 1.0 A2 1101 5101 1.1 B1 1200 5200 1.0 B2 1201 5201 1.1 C1 1300 5300 1.0 C2 1301 5301 1.1 C3 1302 5302 1.2 Zuul 1400 5400 1.0 独立控制台见discovery-springcloud-example-console，对应的版本和端口号如下表 服务端口 管理端口 2222 3333 开始演示 启动服务注册发现中心，默认是Eureka。可供选择的有Eureka，Zuul，Zookeeper。Eureka，请启动discovery-springcloud-example-eureka下的应用，后两者自行安装服务器 根据上面选择的服务注册发现中心，对示例下的discovery-springcloud-example/pom.xml进行组件切换 &lt;dependency&gt; &nbsp; &nbsp;&lt;groupId&gt;com.nepxion&lt;/groupId&gt; &nbsp; &nbsp;&lt;artifactId&gt;discovery-plugin-starter-eureka&lt;/artifactId&gt; &nbsp; &nbsp;&lt;!– &lt;artifactId&gt;discovery-plugin-starter-consul&lt;/artifactId&gt; –&gt; &nbsp; &nbsp;&lt;!– &lt;artifactId&gt;discovery-plugin-starter-zookeeper&lt;/artifactId&gt; –&gt; &nbsp; &nbsp;&lt;version&gt;${discovery.plugin.version}&lt;/version&gt;&lt;/dependency&gt; 根据上面选择的服务注册发现中心，对控制台下的discovery-springcloud-example-console/pom.xml进行组件切换切换 &lt;dependency&gt; &nbsp; &nbsp;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &nbsp; &nbsp;&lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &nbsp; &nbsp;&lt;!– &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; –&gt; &nbsp; &nbsp;&lt;!– &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; –&gt;&lt;/dependency&gt; 服务注册过滤的操作演示 黑/白名单的IP地址注册的过滤 在rule.xml把本地IP地址写入到相应地方 启动DiscoveryApplicationA1.java 抛出禁止注册的异常，即本地服务受限于黑名单的IP地址列表，不会注册到服务注册发现中心；白名单操作也是如此，不过逻辑刚好相反 最大注册数的限制的过滤 在rule.xml修改最大注册数为0 启动DiscoveryApplicationA1.java 抛出禁止注册的异常，即本地服务受限于最大注册数，不会注册到服务注册发现中心 黑/白名单的IP地址发现的过滤 在rule.xml把本地IP地址写入到相应地方 启动DiscoveryApplicationA1.java和DiscoveryApplicationB1.java、DiscoveryApplicationB2.java 你会发现A服务无法获取B服务的任何实例，即B服务受限于黑名单的IP地址列表，不会被A服务的发现；白名单操作也是如此，不过逻辑刚好相反 服务发现和负载均衡控制的操作演示 基于图形化方式的多版本灰度访问控制 请访问http://www.iqiyi.com/w_19s07thtsh.html，视频清晰度改成720P，然后最大化播放 请访问https://pan.baidu.com/s/1eq_N56VbgSCaTXYQ5aKqiA，获取更清晰的视频 基于Rest方式的多版本灰度访问控制 基于服务的操作过程和效果 启动discovery-springcloud-example下7个DiscoveryApplication（除去Zuul），无先后顺序，等待全部启动完毕 下面URL的端口号，可以是服务端口号，也可以是管理端口号 通过版本切换，达到灰度访问控制，针对A服务 1.1 通过Postman或者浏览器，执行POST&nbsp;http://localhost:1100/routes，填入discovery-springcloud-example-b;discovery-springcloud-example-c，查看路由路径，如图1，可以看到符合预期的调用路径 1.2 通过Postman或者浏览器，执行POST&nbsp;http://localhost:1100/version/update，填入1.1，动态把服务A的版本从1.0切换到1.1 1.3 通过Postman或者浏览器，再执行第一步操作，如图2，可以看到符合预期的调用路径，通过版本切换，灰度访问控制成功 通过规则改变，达到灰度访问控制，针对B服务 2.1 通过Postman或者浏览器，执行POST&nbsp;http://localhost:1200/config/update-sync，发送新的规则XML（内容见下面） 2.2 通过Postman或者浏览器，执行POST&nbsp;http://localhost:1201/config/update-sync，发送新的规则XML（内容见下面） 2.3 上述操作也可以通过独立控制台，进行批量更新，见图5。操作的逻辑：B服务的所有版本都只能访问C服务3.0版本，而本例中C服务3.0版本是不存在的，意味着这么做B服务不能访问C服务 2.4 重复1.1步骤，发现调用路径只有A服务-&gt;B服务，如图3，通过规则改变，灰度访问控制成功 负载均衡的灰度测试 3.1 通过Postman或者浏览器，执行POST&nbsp;http://localhost:1100/invoke，这是example内置的访问路径示例（通过Feign实现） 3.2 重复“通过版本切换，达到灰度访问控制”或者“通过规则改变，达到灰度访问控制”操作，查看Ribbon负载均衡的灰度结果，如图4 上述操作，都是单次操作，如需要批量操作，可通过“独立控制台”接口，它集成批量操作和推送到远程配置中心的功能，可以取代上面的某些调用方式 其它更多操作，请参考“配置中心”、“管理中心”和“独立控制台” 新XML规则 &lt;?xml version=”1.0” encoding=”UTF-8”?&gt;&lt;rule&gt; &nbsp; &nbsp;&lt;discovery&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;version&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;service consumer-service-name=”discovery-springcloud-example-b” provider-service-name=”discovery-springcloud-example-c” consumer-version-value=”” provider-version-value=”3.0”/&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;/version&gt; &nbsp; &nbsp;&lt;/discovery&gt;&lt;/rule&gt; 基于网关的操作过程和效果 在上面基础上，启动discovery-springcloud-example下DiscoveryApplicationZuul 因为Zuul是一种特殊的微服务，所有操作过程跟上面完全一致 项目地址：https://github.com/Nepxion/Discovery&nbsp; 转自：https://juejin.im/entry/5b54985b518825597f6b7475]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EnableDiscoveryClient与EnableEurekaClient的区别(Edgware版本)]]></title>
    <url>%2Fpost%2Fspring-cloud-enableDiscoveryClient-and-enableEurekaClient%2F</url>
    <content type="text"><![CDATA[在基于SpringCloud做开发的时候，EnableDiscoveryClient和EnableEurekaClient这两个注解我们并不陌生，今天就来聊聊它们的区别，和网上更早期的类似文章不同的是：本文会聊到Dalston之后的版本中，这两个注解的区别； Spring Cloud版本说明大致发展情况如下：Angle -&gt; Brixton -&gt; Camden -&gt; Dalston -&gt; Edgware -&gt; Finchley 文章概览全文由以下几部分组成，注意Dalston版本是个很重要的时间点，这之后的版本中EnableDiscoveryClient、EnableEurekaClient的作用发生了很大的变化，因此我们接下来的讨论都要先分清楚是Dalston版本之前还是之后： 问题的起源； 来自作者的权威答案（Dalston或更早期的版本）； 官方文档（Dalston或更早期的版本）； 看源码（Dalston或更早期的版本）； Edgware版本中EnableEurekaClient的变化； Edgware版本官方文档对EnableDiscoveryClient的解释； 源码揭示EnableDiscoveryClient的变化； 一点遗留问题待确定； 小结； 问题的起源在使用Spring Cloud的Dalston版本或更早期的版本中，为了将应用发布到Eureka注册中心，我们会在配置类中增加@EnableDiscoveryClient或者@EnableEurekaClient注解，例如以下代码： package com.bolingcavalry.springclouddeepprovider; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class SpringclouddeepproviderApplication { public static void main(String[] args) { SpringApplication.run(SpringclouddeepproviderApplication.class, args); } } 于是就有了疑问：EnableDiscoveryClient和EnableEurekaClient的区别和关系。 来自作者的权威答案（Dalston或更早期的版本） 请注意，下面这段内容的背景是Spring Cloud的Dalston版本，或更早期的版本，这一点很重要！EnableDiscoveryClient和EnableEurekaClient的区别在网上有不少文章分析，但最权威的答案应该来自这两个类的作者Spencer Gibb，他在StackOverflow上有回复，地址是：https://stackoverflow.com/questions/31976236/whats-the-difference-between-enableeurekaclient-and-enablediscoveryclient 内容如下图： 我的理解：注册发现服务有三种实现方式：eureka、consul、zookeeper，EnableDiscoveryClient注解在common包中，通过项目的classpath来决定使用哪种实现，而EnableEurekaClient注解在netflix包中，只会使用eureka这种实现方式； 有两个时间点需要注意： Spencer Gibb的这段话发表于2015年8月13日； Spencer Gibb于2017年10月25日，在Spring官方博客宣布Edgware.RC1版本发布，如下图，此时距离他在StackOverflow上那个回答已经过去了两年： 因此，如果您使用的Spring Cloud版本是Edgware或者更新的版本，您在考虑EnableDiscoveryClient和EnableEurekaClient的区别时，Spencer Gibb在StackOverflow上的那个解释就未必准确了，因为您的版本距离他当时的版本已经有了两年以上的间隔； 官方文档（Dalston或更早期的版本）在Spring官方博客，于2014年12月9日宣布Spring Cloud 1.0.0.RC1发布，地址是：https://spring.io/blog/2014/12/19/spring-cloud-1-0-0-rc1-available-now，里面有段描述如下图红框所示： 我对以上描述的理解： 服务注册发现功能被抽象后放入spring-cloud-commons库，该库的EnableDiscoveryClient可以取代旧的EnableEurekaClient，使用注解EnableDiscoveryClient就能启用服务注册发现功能； 同理，EnableHystrix也被EnableCircuitBreaker取代了； 可见，从Spring Cloud 1.0.0.RC1版本开始，就已经不推荐使用EnableEurekaClient和EnableHystrix了； 看源码（Dalston或更早期的版本）看一下Dalston版本的EnableEurekaClient源码： @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @EnableDiscoveryClient public @interface EnableEurekaClient { } 上述代码显示，EnableEurekaClient 中使用了EnableDiscoveryClient，因此，从使用者角度来看两者确实已经没有什么区别了，按照官方的建议使用EnableDiscoveryClient其实是个不错的选择； Edgware版本中EnableEurekaClient的变化来看看Edgware版本中，EnableEurekaClient.java的内容： @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited public @interface EnableEurekaClient { } 如上所示，之前版本中的@EnableDiscoveryClient注解已经不存在了，而且也没有用到任何@Import注解，因此，EnableEurekaClient这个注解已经没什么用处了，在代码中用不用它，是没什么差别的； Edgware版本官方文档对EnableDiscoveryClient的解释Dalston之后的第一个版本为Edgware，Spring官方博客在2017年10月25日宣布发布，一起来看看此版本的EnableEurekaClient和EnableDiscoveryClient的区别； 首先还是看官方博客，关键信息如下图： https://img-blog.csdn.net/20180914085834726?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JvbGluZ19jYXZhbHJ5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70 我对以上内容的理解： EnableDiscoveryClient注解现在是可选项了(你用不用这个注解，是不会影响服务注册发现功能的)； 只要依赖了以spring-cloud-starter-netflix为前缀的库(例如spring-cloud-starter-netflix-eureka-client)，就启用了服务注册发现功能； 使用配置项spring.cloud.service-registry.auto-registration.enabled=false即可禁止服务注册发现功能； 从官方博客上看来EnableDiscoveryClient注解已经不会影响服务注册发现功能了； 如何理解“@EnableDiscoveryClient is now optional”？既然注解@EnableDiscoveryClient用或者不用都不影响服务注册发现功能，那为什么官方文档将其描述为”is now optional”（可选项），为什么不直接废弃这个注解呢？从官方文档对EnableDiscoveryClient的描述，我们可以看个明白，如下图： 上图是Edgware版本的开发文档，地址：http://cloud.spring.io/spring-cloud-static/Edgware.SR4/multi/multi__spring_cloud_commons_common_abstractions.html#__enablediscoveryclient 从上图描述可以看出，spring容器在查询spring.factories的过程中，如果找到了EnableDiscoveryClient的配置，就会实例化该配置对应的服务注册发现：例如eureka、consul、zookeeper等； 红框中提到，EnableDiscoveryClient不是必须的，只要classpath中存在DiscoveryClient的实现就可以保证将应用注册到注册中心了，这个功能是如何实现的，后面我们会分析到(和spring.factories有关)； 源码揭示EnableDiscoveryClient的变化通过源码来确认官方文档的信息，这种方式可以加深对Spring Cloud的理解； 寻找突破点：面对浩瀚的源码，如何下手呢？前面官方文档的那句话给了我们一个线索，如下图红框所示： 只依赖以spring-cloud-starter-netflix为前缀的库(例如spring-cloud-starter-netflix-eureka-client)，就启用了服务注册发现功能，这个特性让我想起了spring容器通过META-INF/spring.factories文件加载配置的能力； 于是打开工程spring-cloud-netflix-eureka-client(Edgware版对应的该工程版本号为1.4.0.RELEASE)，去看src\main\resources\META-INF目录下的spring.factories文件，发现在springboot的自动配置项中，出现了一个关键配置EurekaDiscoveryClientConfiguration，如下图： EurekaDiscoveryClientConfiguration负责启动实现服务注册发现功能，实现机制相对复杂，在此不展开细说了，看看部分源码如下： 真相大白：服务注册发现功能是否启动，是由配置类EurekaDiscoveryClientConfiguration控制的，在Edgware版本中，如果开启了springboot的自动配置，那么EurekaDiscoveryClientConfiguration就会生效，因此不是靠EnableDiscoveryClient注解来控制了； 现在我们对Edgware版本的服务注册发现已经有所了解，再去看看Dalston版本下的spring.factories，应该能有不少收获； Dalston版的Spring Cloud，其spring-cloud-netflix-eureka-client工程的版本号为1.3.6.RELEASE，打开该工程下面的spring.factories文件，内容如下： 真相大白：在Dalston版本下，使用注解EnableDiscoveryClient才会使配置类EurekaDiscoveryClientConfiguration生效； 一点遗留问题待确定前面我们在Edgware和Dalston版本下分别打开spring-cloud-netflix-eureka-client工程的spring.factories，通过对比spring.factories，弄清楚了服务注册发现功能是如何启动的； 但是似乎有个问题： 在Edgware版本中，官方建议使用spring-cloud-netflix-eureka-client作为starter； 在Dalston版本中，官方建议使用spring-cloud-starter-eureka作为start，也就是所我们的pom.xml中并没有出现spring-cloud-netflix-eureka-client； 那么问题来了，如果Dalston版本中没有用到spring-cloud-netflix-eureka-client库，那么它的spring.factories自然也就不会生效，那我们刚才的分析岂不是无用了？ 除非是被pom.xml中的其他库间接依赖了，还是创建一个工程来验证一下吧； 基于maven创建一个springboot工程，里面依赖了Spring Cloud的Dalston版本，pom.xml内容如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.bolingcavalry&lt;/groupId&gt; &lt;artifactId&gt;springclouddeepprovider&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;springclouddeepprovider&lt;/name&gt; &lt;description&gt;Demo project for Spring Cloud service provider&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 注意starter用的是spring官方推荐的spring-cloud-starter-eureka，现在工程目录下执行命令mvn dependency:tree看依赖关系，如下图红框所示，spring-cloud-netflix-eureka-client被spring-cloud-starter-eureka间接依赖了： 之前的疑惑已解开，分析如下： 由于spring-cloud-starter-eureka的间接依赖，spring-cloud-netflix-eureka-client会出现在classpath中； 因此spring启动时会扫描到spring-cloud-netflix-eureka-client.jar包中的spring.factories文件； 如果当前工程使用了EnableDiscoveryClient注解，按照spring.factories中的配置，配置类EurekaDiscoveryClientConfiguration会生效，进而开启服务注册发现功能； 小结至此，EnableDiscoveryClient与EnableEurekaClient的区别我们已经全部弄明白了，在这里小结一下吧： 在Spring Cloud的Dalston及其之前的版本中： 从2014年的Spring Cloud 1.0.0.RC1版本开始，官方就推荐使用EnableDiscoveryClient来取代EnableEurekaClient； EnableEurekaClient源码中使用了注解EnableDiscoveryClient，因此如果要使用eureka的注册发现服务，两者功能是一样的； EnableDiscoveryClient注解在spring.factories配置中通过配置项EurekaDiscoveryClientConfiguration来开启服务注册发现功能； 在Dalston之后的版本中（不含Dalston）： 在spring.factories配置中，配置类EurekaDiscoveryClientConfiguration被配置到springboot的自动配置注解中，与EnableDiscoveryClient注解没有关系了,也就是说只要开启了springboot的自动配置，服务注册发现功能就会启用； EnableEurekaClient源码中没有使用注解EnableDiscoveryClient，此时EnableEurekaClient已经没用了； 转自： https://blog.csdn.net/boling_cavalry/article/details/82668480]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[slf4j比log4j更优秀的一点是可以使用占位符]]></title>
    <url>%2Fpost%2Fslf4j%26log4j%2F</url>
    <content type="text"><![CDATA[对于log4j来说，使用logger.debug()消息的时候，如果需要连接字符串，则很麻烦，需要类似这样： private static Logger logger = Logger.getLogger(ExchangeService.class); logger.debug(&quot;你好，我是&quot;+name+&quot;,你好呀&quot;); 使用这种方式的时候，要写很多+号和双引号””，但如果使用slf4j的话，就会方便很多： protected Logger logger = LoggerFactory.getLogger(getClass()); logger.debug(&quot;你好，我是{},你好呀&quot;,name); 使用{}占位，然后再将参数紧跟在,后面，这样就省去了很多+号和双引号””。 我很喜欢slf4j的这个优点，那么在写单纯的Java字符串时，除了使用+号，stringbuffer将字符串拼接起来，还有其它便捷的方法可以利用吗，尤其是没有类似slf4j占位符的方法？ 答案当然是有的： String.format(&quot;%s过大，不超过%sM&quot;, msg, size) String的format方法可以做到。 转自：https://blog.csdn.net/qing_gee/article/details/79396800]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quartz使用总结。---在某一个有规律的时间点干某件事。]]></title>
    <url>%2Fpost%2Fquartz-sometime-todo%2F</url>
    <content type="text"><![CDATA[废话的前言以前凭借年轻，凡事都靠脑记。现在工作几年后发现，很多以前看过、用过的东西，再次拿起的时候总觉得记不牢靠。”好记性不如烂笔头”应该是某位上了年纪的大叔的切肤之痛（仅次于上了年纪的难言之瘾）。 我觉得这事得怪怪中国的应试教育，中国的考试方式就是要求把脑袋当数据库，以前中学那点知识，确实还能装得下。但现在所需的知识量再一次性装入大脑，就是内存溢出的节奏。另，再相信什么人脑只开发5%的蠢话了（「人脑只用了不到 5%」 的说法是否确有科学依据？）。更可行的方式，应该学学数据库，大脑只记忆知识的索引，而把知识的本身定义在外部的存储中（比如笔记）。基于这个理念，现在准备学着写点总结性的笔记。 那为什么不能基于google学习呢？因为google的索引不是你自己，不能精确找到你想要的东西。但它的好处是更海量，能给你原本压根不知道东西。所以，配合使用，疗效更好。 Quartz可以用来做什么？ Quartz是一个任务调度框架。比如你遇到这样的问题 想每月25号，信用卡自动还款想每年4月1日自己给当年暗恋女神发一封匿名贺卡想每隔1小时，备份一下自己的爱情动作片 学习笔记到云盘 这些问题总结起来就是：在某一个有规律的时间点干某件事。并且时间的触发的条件可以非常复杂（比如每月最后一个工作日的17:50），复杂到需要一个专门的框架来干这个事。 Quartz就是来干这样的事，你给它一个触发条件的定义，它负责到了时间点，触发相应的Job起来干活。 一个简单的示例 这里面的所有例子都是基于Quartz 2.2.1 package com.test.quartz;import static org.quartz.DateBuilder.newDate;import static org.quartz.JobBuilder.newJob;import static org.quartz.SimpleScheduleBuilder.simpleSchedule;import static org.quartz.TriggerBuilder.newTrigger;import java.util.GregorianCalendar;import org.quartz.JobDetail;import org.quartz.Scheduler;import org.quartz.Trigger;import org.quartz.impl.StdSchedulerFactory;import org.quartz.impl.calendar.AnnualCalendar;public class QuartzTest { public static void main(String[] args) { try { //创建scheduler Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); //定义一个Trigger Trigger trigger = newTrigger().withIdentity(“trigger1”, “group1”) //定义name/group .startNow()//一旦加入scheduler，立即生效 .withSchedule(simpleSchedule() //使用SimpleTrigger .withIntervalInSeconds(1) //每隔一秒执行一次 .repeatForever()) //一直执行，奔腾到老不停歇 .build(); //定义一个JobDetail JobDetail job = newJob(HelloQuartz.class) //定义Job类为HelloQuartz类，这是真正的执行逻辑所在 .withIdentity(“job1”, “group1”) //定义name/group .usingJobData(“name”, “quartz”) //定义属性 .build(); //加入这个调度 scheduler.scheduleJob(job, trigger); //启动之 scheduler.start(); //运行一段时间后关闭 Thread.sleep(10000); scheduler.shutdown(true); } catch (Exception e) { e.printStackTrace(); } }}package com.test.quartz;import java.util.Date;import org.quartz.DisallowConcurrentExecution;import org.quartz.Job;import org.quartz.JobDetail;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;public class HelloQuartz implements Job { public void execute(JobExecutionContext context) throws JobExecutionException { JobDetail detail = context.getJobDetail(); String name = detail.getJobDataMap().getString(“name”); System.out.println(“say hello to “ + name + “ at “ + new Date()); }}这个例子很好的覆盖了Quartz最重要的3个基本要素：Scheduler：调度器。所有的调度都是由它控制。Trigger： 定义触发的条件。例子中，它的类型是SimpleTrigger，每隔1秒中执行一次（什么是SimpleTrigger下面会有详述）。JobDetail &amp; Job： JobDetail 定义的是任务数据，而真正的执行逻辑是在Job中，例子中是HelloQuartz。 为什么设计成JobDetail + Job，不直接使用Job？这是因为任务是有可能并发执行，如果Scheduler直接使用Job，就会存在对同一个Job实例并发访问的问题。而JobDetail &amp; Job 方式，sheduler每次执行，都会根据JobDetail创建一个新的Job实例，这样就可以规避并发访问的问题。Quartz APIQuartz的API的风格在2.x以后，采用的是DSL风格（通常意味着fluent interface风格），就是示例中newTrigger()那一段东西。它是通过Builder实现的，就是以下几个。（ 下面大部分代码都要引用这些Builder )//job相关的builderimport static org.quartz.JobBuilder.;//trigger相关的builderimport static org.quartz.TriggerBuilder.;import static org.quartz.SimpleScheduleBuilder.;import static org.quartz.CronScheduleBuilder.;import static org.quartz.DailyTimeIntervalScheduleBuilder.;import static org.quartz.CalendarIntervalScheduleBuilder.;//日期相关的builderimport static org.quartz.DateBuilder.;DSL风格写起来会更加连贯，畅快，而且由于不是使用setter的风格，语义上会更容易理解一些。对比一下：JobDetail jobDetail=new JobDetailImpl(“jobDetail1”,“group1”,HelloQuartz.class);jobDetail.getJobDataMap().put(“name”, “quartz”);SimpleTriggerImpl trigger=new SimpleTriggerImpl(“trigger1”,“group1”);trigger.setStartTime(new Date());trigger.setRepeatInterval(1);trigger.setRepeatCount(-1);关于name和groupJobDetail和Trigger都有name和group。name是它们在这个sheduler里面的唯一标识。如果我们要更新一个JobDetail定义，只需要设置一个name相同的JobDetail实例即可。group是一个组织单元，sheduler会提供一些对整组操作的API，比如 scheduler.resumeJobs()。Trigger在开始详解每一种Trigger之前，需要先了解一下Trigger的一些共性。StartTime &amp; EndTimestartTime和endTime指定的Trigger会被触发的时间区间。在这个区间之外，Trigger是不会被触发的。 所有Trigger都会包含这两个属性 优先级（Priority）当scheduler比较繁忙的时候，可能在同一个时刻，有多个Trigger被触发了，但资源不足（比如线程池不足）。那么这个时候比剪刀石头布更好的方式，就是设置优先级。优先级高的先执行。需要注意的是，优先级只有在同一时刻执行的Trigger之间才会起作用，如果一个Trigger是9:00，另一个Trigger是9:30。那么无论后一个优先级多高，前一个都是先执行。优先级的值默认是5，当为负数时使用默认值。最大值似乎没有指定，但建议遵循Java的标准，使用1-10，不然鬼才知道看到【优先级为10】是时，上头还有没有更大的值。Misfire(错失触发）策略类似的Scheduler资源不足的时候，或者机器崩溃重启等，有可能某一些Trigger在应该触发的时间点没有被触发，也就是Miss Fire了。这个时候Trigger需要一个策略来处理这种情况。每种Trigger可选的策略各不相同。这里有两个点需要重点注意：MisFire的触发是有一个阀值，这个阀值是配置在JobStore的。比RAMJobStore是org.quartz.jobStore.misfireThreshold。只有超过这个阀值，才会算MisFire。小于这个阀值，Quartz是会全部重新触发。所有MisFire的策略实际上都是解答两个问题：已经MisFire的任务还要重新触发吗？如果发生MisFire，要调整现有的调度时间吗？比如SimpleTrigger的MisFire策略有：MISFIRE_INSTRUCTION_IGNORE_MISFIRE_POLICY这个不是忽略已经错失的触发的意思，而是说忽略MisFire策略。它会在资源合适的时候，重新触发所有的MisFire任务，并且不会影响现有的调度时间。比如，SimpleTrigger每15秒执行一次，而中间有5分钟时间它都MisFire了，一共错失了20个，5分钟后，假设资源充足了，并且任务允许并发，它会被一次性触发。这个属性是所有Trigger都适用。MISFIRE_INSTRUCTION_FIRE_NOW忽略已经MisFire的任务，并且立即执行调度。这通常只适用于只执行一次的任务。MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNT将startTime设置当前时间，立即重新调度任务，包括的MisFire的MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_REMAINING_REPEAT_COUNT类似MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNT，区别在于会忽略已经MisFire的任务MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_EXISTING_COUNT在下一次调度时间点，重新开始调度任务，包括的MisFire的MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_REMAINING_COUNT类似于MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_EXISTING_COUNT，区别在于会忽略已经MisFire的任务。MISFIRE_INSTRUCTION_SMART_POLICY所有的Trigger的MisFire默认值都是这个，大致意思是“把处理逻辑交给聪明的Quartz去决定”。基本策略是，如果是只执行一次的调度，使用MISFIRE_INSTRUCTION_FIRE_NOW如果是无限次的调度(repeatCount是无限的)，使用MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_REMAINING_COUNT否则，使用MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNTMisFire的东西挺繁杂的，可以参考这篇Calendar这里的Calendar不是jdk的java.util.Calendar，不是为了计算日期的。它的作用是在于补充Trigger的时间。可以排除或加入某一些特定的时间点。以”每月25日零点自动还卡债“为例，我们想排除掉每年的2月25号零点这个时间点（因为有2.14，所以2月一定会破产）。这个时间，就可以用Calendar来实现。例子：AnnualCalendar cal = new AnnualCalendar(); //定义一个每年执行Calendar，精度为天，即不能定义到2.25号下午2:00java.util.Calendar excludeDay = new GregorianCalendar();excludeDay.setTime(newDate().inMonthOnDay(2, 25).build());cal.setDayExcluded(excludeDay, true); //设置排除2.25这个日期scheduler.addCalendar(“FebCal”, cal, false, false); //scheduler加入这个Calendar//定义一个TriggerTrigger trigger = newTrigger().withIdentity(“trigger1”, “group1”) .startNow()//一旦加入scheduler，立即生效 .modifiedByCalendar(“FebCal”) //使用Calendar !! .withSchedule(simpleSchedule() .withIntervalInSeconds(1) .repeatForever()) .build();Quartz体贴地为我们提供以下几种Calendar，注意，所有的Calendar既可以是排除，也可以是包含，取决于：HolidayCalendar。指定特定的日期，比如20140613。精度到天。DailyCalendar。指定每天的时间段（rangeStartingTime, rangeEndingTime)，格式是HH:MM[:SS[:mmm]]。也就是最大精度可以到毫秒。WeeklyCalendar。指定每星期的星期几，可选值比如为java.util.Calendar.SUNDAY。精度是天。MonthlyCalendar。指定每月的几号。可选值为1-31。精度是天AnnualCalendar。 指定每年的哪一天。使用方式如上例。精度是天。CronCalendar。指定Cron表达式。精度取决于Cron表达式，也就是最大精度可以到秒。Trigger实现类Quartz有以下几种Trigger实现:SimpleTrigger指定从某一个时间开始，以一定的时间间隔（单位是毫秒）执行的任务。它适合的任务类似于：9:00 开始，每隔1小时，执行一次。它的属性有：repeatInterval 重复间隔repeatCount 重复次数。实际执行次数是 repeatCount+1。因为在startTime的时候一定会执行一次。 下面有关repeatCount 属性的都是同理。 例子：simpleSchedule() .withIntervalInHours(1) //每小时执行一次 .repeatForever() //次数不限 .build();simpleSchedule() .withIntervalInMinutes(1) //每分钟执行一次 .withRepeatCount(10) //次数为10次 .build();CalendarIntervalTrigger类似于SimpleTrigger，指定从某一个时间开始，以一定的时间间隔执行的任务。 但是不同的是SimpleTrigger指定的时间间隔为毫秒，没办法指定每隔一个月执行一次（每月的时间间隔不是固定值），而CalendarIntervalTrigger支持的间隔单位有秒，分钟，小时，天，月，年，星期。相较于SimpleTrigger有两个优势：1、更方便，比如每隔1小时执行，你不用自己去计算1小时等于多少毫秒。 2、支持不是固定长度的间隔，比如间隔为月和年。但劣势是精度只能到秒。它适合的任务类似于：9:00 开始执行，并且以后每周 9:00 执行一次它的属性有:interval 执行间隔intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）例子:calendarIntervalSchedule() .withIntervalInDays(1) //每天执行一次 .build();calendarIntervalSchedule() .withIntervalInWeeks(1) //每周执行一次 .build();DailyTimeIntervalTrigger指定每天的某个时间段内，以一定的时间间隔执行任务。并且它可以支持指定星期。它适合的任务类似于：指定每天9:00 至 18:00 ，每隔70秒执行一次，并且只要周一至周五执行。它的属性有:startTimeOfDay 每天开始时间endTimeOfDay 每天结束时间daysOfWeek 需要执行的星期interval 执行间隔intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）repeatCount 重复次数例子:dailyTimeIntervalSchedule() .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始 .endingDailyAt(TimeOfDay.hourAndMinuteOfDay(16, 0)) //16：00 结束 .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行 .withIntervalInHours(1) //每间隔1小时执行一次 .withRepeatCount(100) //最多重复100次（实际执行100+1次） .build();dailyTimeIntervalSchedule() .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始 .endingDailyAfterCount(10) //每天执行10次，这个方法实际上根据 startTimeOfDay+intervalcount 算出 endTimeOfDay .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行 .withIntervalInHours(1) //每间隔1小时执行一次 .build();CronTrigger适合于更复杂的任务，它支持类型于Linux Cron的语法（并且更强大）。基本上它覆盖了以上三个Trigger的绝大部分能力（但不是全部）—— 当然，也更难理解。它适合的任务类似于：每天0:00,9:00,18:00各执行一次。它的属性只有:Cron表达式。但这个表示式本身就够复杂了。下面会有说明。例子：cronSchedule(“0 0/2 8-17 ?”) // 每天8:00-17:00，每隔2分钟执行一次 .build();cronSchedule(“0 30 9 ? MON”) // 每周一，9:30执行一次.build();weeklyOnDayAndHourAndMinute(MONDAY,9, 30) //等同于 0 30 9 ? MON .build();Cron表达式位置时间域允许值特殊值1秒0-59, - /2分钟0-59, - /3小时0-23, - /4日期1-31, - ? / L W C5月份1-12, - /6星期1-7, - ? / L C #7年份（可选）1-31, - /星号()：可用在所有字段中，表示对应时间域的每一个时刻，例如，&nbsp;在分钟字段时，表示“每分钟”；问号（?）：该字符只在日期和星期字段中使用，它通常指定为“无意义的值”，相当于点位符；减号(-)：表达一个范围，如在小时字段中使用“10-12”，则表示从10到12点，即10,11,12；逗号(,)：表达一个列表值，如在星期字段中使用“MON,WED,FRI”，则表示星期一，星期三和星期五；斜杠(/)：x/y表达一个等步长序列，x为起始值，y为增量步长值。如在分钟字段中使用0/15，则表示为0,15,30和45秒，而5/15在分钟字段中表示5,20,35,50，你也可以使用/y，它等同于0/y；L：该字符只在日期和星期字段中使用，代表“Last”的意思，但它在两个字段中意思不同。L在日期字段中，表示这个月份的最后一天，如一月的31号，非闰年二月的28号；如果L用在星期中，则表示星期六，等同于7。但是，如果L出现在星期字段里，而且在前面有一个数值X，则表示“这个月的最后X天”，例如，6L表示该月的最后星期五；W：该字符只能出现在日期字段里，是对前导日期的修饰，表示离该日期最近的工作日。例如15W表示离该月15号最近的工作日，如果该月15号是星期六，则匹配14号星期五；如果15日是星期日，则匹配16号星期一；如果15号是星期二，那结果就是15号星期二。但必须注意关联的匹配日期不能够跨月，如你指定1W，如果1号是星期六，结果匹配的是3号星期一，而非上个月最后的那天。W字符串只能指定单一日期，而不能指定日期范围；LW组合：在日期字段可以组合使用LW，它的意思是当月的最后一个工作日；井号(#)：该字符只能在星期字段中使用，表示当月某个工作日。如6#3表示当月的第三个星期五(6表示星期五，#3表示当前的第三个)，而4#5表示当月的第五个星期三，假设当月没有第五个星期三，忽略不触发；C：该字符只在日期和星期字段中使用，代表“Calendar”的意思。它的意思是计划所关联的日期，如果日期没有被关联，则相当于日历中所有日期。例如5C在日期字段中就相当于日历5日以后的第一天。1C在星期字段中相当于星期日后的第一天。Cron表达式对特殊字符的大小写不敏感，对代表星期的缩写英文大小写也不敏感。一些例子：表示式说明0 0 12 ?每天12点运行0 15 10 ? 每天10:15运行0 15 10 ?每天10:15运行0 15 10 ? 每天10:15运行0 15 10 ? 2008在2008年的每天10：15运行0 14 ?每天14点到15点之间每分钟运行一次，开始于14:00，结束于14:59。0 0/5 14 ?每天14点到15点每5分钟运行一次，开始于14:00，结束于14:55。0 0/5 14,18 ?每天14点到15点每5分钟运行一次，此外每天18点到19点每5钟也运行一次。0 0-5 14 ?每天14:00点到14:05，每分钟运行一次。0 10,44 14 ? 3 WED3月每周三的14:10分到14:44，每分钟运行一次。0 15 10 ? MON-FRI每周一，二，三，四，五的10:15分运行。0 15 10 15 ?每月15日10:15分运行。0 15 10 L ?每月最后一天10:15分运行。0 15 10 ? 6L每月最后一个星期五10:15分运行。0 15 10 ? 6L 2007-2009在2007,2008,2009年每个月的最后一个星期五的10:15分运行。0 15 10 ? 6#3每月第三个星期五的10:15分运行。JobDetail &amp; JobJobDetail是任务的定义，而Job是任务的执行逻辑。在JobDetail里会引用一个Job Class定义。一个最简单的例子public class JobTest { public static void main(String[] args) throws SchedulerException, IOException { JobDetail job=newJob() .ofType(DoNothingJob.class) //引用Job Class .withIdentity(“job1”, “group1”) //设置name/group .withDescription(“this is a test job”) //设置描述 .usingJobData(“age”, 18) //加入属性到ageJobDataMap .build(); job.getJobDataMap().put(“name”, “quertz”); //加入属性name到JobDataMap //定义一个每秒执行一次的SimpleTrigger Trigger trigger=newTrigger() .startNow() .withIdentity(“trigger1”) .withSchedule(simpleSchedule() .withIntervalInSeconds(1) .repeatForever()) .build(); Scheduler sche=StdSchedulerFactory.getDefaultScheduler(); sche.scheduleJob(job, trigger); sche.start(); System.in.read(); sche.shutdown(); }}public class DoNothingJob implements Job { public void execute(JobExecutionContext context) throws JobExecutionException { System.out.println(“do nothing”); }}从上例我们可以看出，要定义一个任务，需要干几件事：创建一个org.quartz.Job的实现类，并实现实现自己的业务逻辑。比如上面的DoNothingJob。定义一个JobDetail，引用这个实现类加入scheduleJobQuartz调度一次任务，会干如下的事：JobClass jobClass=JobDetail.getJobClass()Job jobInstance=jobClass.newInstance()。所以Job实现类，必须有一个public的无参构建方法。jobInstance.execute(JobExecutionContext context)。JobExecutionContext是Job运行的上下文，可以获得Trigger、Scheduler、JobDetail的信息。也就是说，每次调度都会创建一个新的Job实例，这样的好处是有些任务并发执行的时候，不存在对临界资源的访问问题——当然，如果需要共享JobDataMap的时候，还是存在临界资源的并发访问的问题。JobDataMapJob都次都是newInstance的实例，那我怎么传值给它？ 比如我现在有两个发送邮件的任务，一个是发给”liLei”,一个发给”hanmeimei”,不能说我要写两个Job实现类LiLeiSendEmailJob和HanMeiMeiSendEmailJob。实现的办法是通过JobDataMap。每一个JobDetail都会有一个JobDataMap。JobDataMap本质就是一个Map的扩展类，只是提供了一些更便捷的方法，比如getString()之类的。我们可以在定义JobDetail，加入属性值，方式有二：newJob().usingJobData(“age”, 18) //加入属性到ageJobDataMap or job.getJobDataMap().put(“name”, “quertz”); //加入属性name到JobDataMap然后在Job中可以获取这个JobDataMap的值，方式同样有二：public class HelloQuartz implements Job { private String name; public void execute(JobExecutionContext context) throws JobExecutionException { JobDetail detail = context.getJobDetail(); JobDataMap map = detail.getJobDataMap(); //方法一：获得JobDataMap System.out.println(“say hello to “ + name + “[“ + map.getInt(“age”) + “]” + “ at “ + new Date()); } //方法二：属性的setter方法，会将JobDataMap的属性自动注入 public void setName(String name) { this.name = name; }}对于同一个JobDetail实例，执行的多个Job实例，是共享同样的JobDataMap，也就是说，如果你在任务里修改了里面的值，会对其他Job实例（并发的或者后续的）造成影响。除了JobDetail，Trigger同样有一个JobDataMap，共享范围是所有使用这个Trigger的Job实例。Job并发Job是有可能并发执行的，比如一个任务要执行10秒中，而调度算法是每秒中触发1次，那么就有可能多个任务被并发执行。有时候我们并不想任务并发执行，比如这个任务要去”获得数据库中所有未发送邮件的名单“，如果是并发执行，就需要一个数据库锁去避免一个数据被多次处理。这个时候一个@DisallowConcurrentExecution解决这个问题。就是这样public class DoNothingJob implements Job { @DisallowConcurrentExecution public void execute(JobExecutionContext context) throws JobExecutionException { System.out.println(“do nothing”); }}注意，@DisallowConcurrentExecution是对JobDetail实例生效，也就是如果你定义两个JobDetail，引用同一个Job类，是可以并发执行的。JobExecutionExceptionJob.execute()方法是不允许抛出除JobExecutionException之外的所有异常的（包括RuntimeException)，所以编码的时候，最好是try-catch住所有的Throwable，小心处理。其他属性Durability(耐久性？)如果一个任务不是durable，那么当没有Trigger关联它的时候，它就会被自动删除。RequestsRecovery如果一个任务是”requests recovery”，那么当任务运行过程非正常退出时（比如进程崩溃，机器断电，但不包括抛出异常这种情况），Quartz再次启动时，会重新运行一次这个任务实例。可以通过JobExecutionContext.isRecovering()查询任务是否是被恢复的。SchedulerScheduler就是Quartz的大脑，所有任务都是由它来设施。Schduelr包含一个两个重要组件: JobStore和ThreadPool。JobStore是会来存储运行时信息的，包括Trigger,Schduler,JobDetail，业务锁等。它有多种实现RAMJob(内存实现)，JobStoreTX(JDBC，事务由Quartz管理），JobStoreCMT(JDBC，使用容器事务)，ClusteredJobStore(集群实现)、TerracottaJobStore(什么是Terractta)。ThreadPool就是线程池，Quartz有自己的线程池实现。所有任务的都会由线程池执行。SchedulerFactorySchdulerFactory，顾名思义就是来用创建Schduler了，有两个实现：DirectSchedulerFactory和 StdSchdulerFactory。前者可以用来在代码里定制你自己的Schduler参数。后者是直接读取classpath下的quartz.properties（不存在就都使用默认值）配置来实例化Schduler。通常来讲，我们使用StdSchdulerFactory也就足够了。SchdulerFactory本身是支持创建RMI stub的，可以用来管理远程的Scheduler，功能与本地一样，可以远程提交个Job什么的。DirectSchedulerFactory的创建接口 /* Same as {@link DirectSchedulerFactory#createScheduler(ThreadPool threadPool, JobStore jobStore)}, with the addition of specifying the scheduler name and instance ID. This scheduler can only be retrieved via {@link DirectSchedulerFactory#getScheduler(String)} @param schedulerName The name for the scheduler. @param schedulerInstanceId The instance ID for the scheduler. @param threadPool The thread pool for executing jobs @param jobStore The type of job store @throws SchedulerException if initialization failed / public void createScheduler(String schedulerName, String schedulerInstanceId, ThreadPool threadPool, JobStore jobStore) throws SchedulerException;StdSchdulerFactory的配置例子， 更多配置，参考Quartz配置指南：org.quartz.scheduler.instanceName = DefaultQuartzSchedulerorg.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPoolorg.quartz.threadPool.threadCount = 10org.quartz.threadPool.threadPriority = 5org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = trueorg.quartz.jobStore.class = org.quartz.simpl.RAMJobStore这里未讲的稍微高级的主题JobStore&nbsp;介绍、配置集群:&nbsp;介绍、配置RMI监听器&nbsp;TriggerListeners and JobListeners、SchedulerListeners插件参考主要的资料来自官方文档，这里有教程，例子，配置等，非常详细Cron表达式的说明，大段引用自这里中文文档，虽然版本比较旧，但是很多东西还是没过时的，比如插件、RMI，Quartz_Job_Scheduling_Framework_CN_V1.0.0]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高并发，分布式电商订单号生成]]></title>
    <url>%2Fpost%2Fhigh-concurrency-order%2F</url>
    <content type="text"><![CDATA[在分布式与高并发的情况下，生成订单号应满足以下几点： 全局唯一 订单号信息安全要求（不可推测性） 趋势递增要求 效率（生成、使用、索引） 控制并发（时间） 策略一：UUID和GUID（通用唯一识别码）组成：当前日期+时间+时钟序列+机器识别码（Mac地址或其他），正常情况下十几年之内可以达到全球唯一性。 优点：简单 UUID.randomUUID() 缺点： 用户不友好，无序，不可读 索引关联效率较低，查询慢 分布式集群情况下有几率重复 策略二：数据库自增ID在数据库集群环境下，不同的数据库节点可以设置不同的起步值、相同的步长值来实现订单号唯一 tab_A 起步值1 步长值10 1 11 21 31 41 tab_B 起步值2 步长值10 2 12 22 32 42 优点： 无需编码 递增 缺点： DB单点故障 高并发下插入数据需要事务机制 扩展性瓶颈 策略三：Twitter SnowFlake整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，SnowFlake每秒能够产生26wID左右。 优点： 低位趋势递增 缺点： 依赖服务器时间（极端情况：更改服务器时间会导致ID重复） 策略四：Redis 自增redis 提供incr(key)方法， 将key中的数字值增1，如key不存在，key的值会被初始化为0。 优点： 无单点故障 性能优于DB 递增 缺点： redis集群维护 转自：https://blog.csdn.net/qq_15807785/article/details/81331376]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>高并发</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发环境、生产环境、测试环境的基本理解和区别]]></title>
    <url>%2Fpost%2Fdev-pro-fat-env-diff%2F</url>
    <content type="text"><![CDATA[对于刚刚来到一个新的团队或是新环境的“新人”来说，当你无所事事且故作投入之时，听着几个“老人”在自己可视范围之外或严肃或轻松的讨论着业务，其措辞拿捏精准，语气抑扬顿挫，期间，涉及到一些的概念可能难免让你不明觉厉……然默默道：”高端，大气，上档次！“ ”不识庐山真面目，只缘身在此山中“，对于一些术语，它既有官方称呼，也有通俗叫法，对于不明觉厉的我只是正巧漫步在这座叫做大山的山中啊！ 菜鸟话多…… 开发环境：开发环境是程序猿们专门用于开发的服务器，配置可以比较随意， 为了开发调试方便，一般打开全部错误报告。 测试环境：一般是克隆一份生产环境的配置，一个程序在测试环境工作不正常，那么肯定不能把它发布到生产机上。 生产环境：是值正式提供对外服务的，一般会关掉错误报告，打开错误日志。 三个环境也可以说是系统开发的三个阶段：开发-&gt;测试-&gt;上线，其中生产环境也就是通常说的真实环境。]]></content>
      <categories>
        <category>理论</category>
      </categories>
      <tags>
        <tag>软件工程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis五大类型用法]]></title>
    <url>%2Fpost%2Fredis-five-type-usage-method%2F</url>
    <content type="text"><![CDATA[五大类型： Redis五大类型:字符串（String）、哈希/散列/字典（Hash）、列表（List）、集合（Set）、有序集合（sorted&nbsp;set）五种Controller:@Resource RedisTemplate&lt;String, String&gt; redisTemplate;总括:redisTemplate.opsForValue();//操作字符串redisTemplate.opsForHash();//操作hashredisTemplate.opsForList();//操作listredisTemplate.opsForSet();//操作setredisTemplate.opsForZSet();//操作有序setString:1.redisTemplate.opsForValue().set(key,value)); 2.redisTemplate.opsForValue().get(key)); 3.redisTemplate.opsForValue().get(key, start, end);4.redisTemplate.opsForValue().getAndSet(key, value);5.redisTemplate.opsForValue().getBit(key, offset);//下方注释6.redisTemplate.opsForValue().multiGet(keys);7.redisTemplate.opsForValue().setBit(key, offset, value);//下方注释8.redisTemplate.opsForValue().set(K key, V value, long timeout, TimeUnit unit);//TimeUnit是timeout的类型,如毫秒\秒\天等9.redisTemplate.opsForValue().setIfAbsent(key, value);10.redisTemplate.opsForValue().set(K key, V value, long offset);//博主此处未做java验证11.redisTemplate.opsForValue().size(key));12.redisTemplate.opsForValue().multiGet(Collection&lt;K&gt; keys);13.redisTemplate.opsForValue().multiSetIfAbsent(Map&lt;? extends K, ? extends V&gt; m);14.同815\16\17\18\19.redisTemplate.opsForValue().increment(K key, long delta);或.increment(K key, double delta);20.redisTemplate.opsForValue().append(key, value);//在key键对应值的右面追加值value可以看到并没有删除等方法,博主研究了一下可以这样:21.del key——21.redisTemplate.opsForValue().getOperations().delete(key);&nbsp;编号命令描述说明1SET key value此命令设置指定键的值。2GET key获取指定键的值。3GETRANGE key start end获取存储在键上的字符串的子字符串。4GETSET key value设置键的字符串值并返回其旧值。5GETBIT key offset返回在键处存储的字符串值中偏移处的位值。6MGET key1 [key2..]获取所有给定键的值7SETBIT key offset value存储在键上的字符串值中设置或清除偏移处的位8SETEX key seconds value使用键和到期时间来设置值9SETNX key value设置键的值，仅当键不存在时10SETRANGE key offset value在指定偏移处开始的键处覆盖字符串的一部分11STRLEN key获取存储在键中的值的长度12MSET key value [key value …]为多个键分别设置它们的值13MSETNX key value [key value …]为多个键分别设置它们的值，仅当键不存在时14PSETEX key milliseconds value设置键的值和到期时间(以毫秒为单位)15INCR key将键的整数值增加116INCRBY key increment将键的整数值按给定的数值增加17INCRBYFLOAT key increment将键的浮点值按给定的数值增加18DECR key将键的整数值减119DECRBY key decrement按给定数值减少键的整数值20APPEND key value将指定值附加到键.setBit(key, offset, value):key键对应的值value对应的ascii码,在offset的位置(从左向右数)变为value.(此处感谢@参考文章对我理解的帮助),由于二进制只有0和1,此处value只能取0和1,如图,其他值是超出范围的.getBit(key, offset):获取键对应值的ascii码的在offset处位值.@ascii码对照表&nbsp;&nbsp;Hash:1.redisTemplate.opsForHash().delete(H key, Object… hashKeys);//…表示可以传入多个map的key，用，隔开。或用数组传值2.redisTemplate.opsForHash().hasKey(key, hashKey)；3.redisTemplate.opsForHash().get(key, hashKey)；4.redisTemplate.opsForHash().entries(key);//返回map集合5、6.redisTemplate.opsForHash().increment(H key, HK hashKey, long delta);//或increment(H key, HK hashKey, double delta);；7.redisTemplate.opsForHash().keys(key)；//返回map的key集合Set8.redisTemplate.opsForHash().size(key)；9.redisTemplate.opsForHash().multiGet(H key, Collection&lt;HK&gt; hashKeys);10.redisTemplate.opsForHash().putAll(H key, Map&lt;? extends HK, ? extends HV&gt; m)；11.redisTemplate.opsForHash().put(key, hashKey, value);12.redisTemplate.opsForHash().putIfAbsent(key, hashKey, value)；13.redisTemplate.opsForHash().values(key);//返回map中的value集合List；序号&nbsp;命令说明1HDEL key field2 [field2]删除一个或多个哈希字段。2HEXISTS key field判断是否存在散列字段。3HGET key field获取存储在指定键的哈希字段的值。4HGETALL key获取存储在指定键的哈希中的所有字段和值5HINCRBY key field increment将哈希字段的整数值按给定数字增加6HINCRBYFLOAT key field increment将哈希字段的浮点值按给定数值增加7HKEYS key获取哈希中的所有字段8HLEN key获取散列中的字段数量9HMGET key field1 [field2]获取所有给定哈希字段的值10HMSET key field1 value1 [field2 value2 ]为多个哈希字段分别设置它们的值11HSET key field value设置散列字段的字符串值12HSETNX key field value仅当字段不存在时，才设置散列字段的值13HVALS key获取哈希中的所有值List：redisTemplate.opsForList().leftPush(key,&nbsp;value);//从左向右存压栈redisTemplate.opsForList().leftPop(key);//从左出栈redisTemplate.opsForList().size(key);//队/栈长redisTemplate.opsForList().range(key,&nbsp;start,&nbsp;end);//范围检索,返回ListredisTemplate.opsForList().remove(key,&nbsp;i,&nbsp;value);//移除key中值为value的i个,返回删除的个数；如果没有这个元素则返回0 redisTemplate.opsForList().index(key,&nbsp;index);//检索redisTemplate.opsForList().set(key,&nbsp;index,&nbsp;value);//赋值redisTemplate.opsForList().trim(key,&nbsp;start,&nbsp;end);//裁剪,void,删除除了[start,end]以外的所有元素&nbsp; redisTemplate.opsForList().rightPopAndLeftPush(String sourceKey, String destinationKey);//将源key的队列的右边的一个值删除，然后塞入目标key的队列的左边，返回这个值注意:要缓存的对象必须实现Serializable接口,因为 Spring 会将对象先序列化再存入 Redis,否则报异常nested exception is java.lang.IllegalArgumentException: DefaultSerializer requires a Serializable……//；；/序号&nbsp;命令说明1BLPOP key1 [key2 ] timeout删除并获取列表中的第一个元素，或阻塞，直到有一个元素可用2BRPOP key1 [key2 ] timeout删除并获取列表中的最后一个元素，或阻塞，直到有一个元素可用3BRPOPLPUSH source destination timeout从列表中弹出值，将其推送到另一个列表并返回它; 或阻塞，直到一个可用4LINDEX key index通过其索引从列表获取元素5LINSERT key BEFORE/AFTER pivot value在列表中的另一个元素之前或之后插入元素6LLEN key获取列表的长度7LPOP key删除并获取列表中的第一个元素8LPUSH key value1 [value2]将一个或多个值添加到列表9LPUSHX key value仅当列表存在时，才向列表添加值10LRANGE key start stop从列表中获取一系列元素11LREM key count value从列表中删除元素12LSET key index value通过索引在列表中设置元素的值13LTRIM key start stop修剪列表的指定范围14RPOP key删除并获取列表中的最后一个元素15RPOPLPUSH source destination删除列表中的最后一个元素，将其附加到另一个列表并返回16RPUSH key value1 [value2]将一个或多个值附加到列表17RPUSHX key value仅当列表存在时才将值附加到列表Set：redisTemplate.opsForValue().getAndSet(key, value)&nbsp;序号命令说明1SADD key member1 [member2]将一个或多个成员添加到集合2SCARD key获取集合中的成员数3SDIFF key1 [key2]减去多个集合4SDIFFSTORE destination key1 [key2]减去多个集并将结果集存储在键中5SINTER key1 [key2]相交多个集合6SINTERSTORE destination key1 [key2]交叉多个集合并将结果集存储在键中7SISMEMBER key member判断确定给定值是否是集合的成员8SMOVE source destination member将成员从一个集合移动到另一个集合9SPOP key从集合中删除并返回随机成员10SRANDMEMBER key [count]从集合中获取一个或多个随机成员11SREM key member1 [member2]从集合中删除一个或多个成员12SUNION key1 [key2]添加多个集合13SUNIONSTORE destination key1 [key2]添加多个集并将结果集存储在键中14SSCAN key cursor [MATCH pattern] [COUNT count]递增地迭代集合中的元素&nbsp;&nbsp;艾玛，太累了，写着写着发现不用这么麻烦，看到文章中的表了吗？若在java中找不到相应方法就对照表中的一些”字段“在java中找，肯定能找到，而且基本不会浪费多少时间。关于List与Set万能的后人补充吧！ 转自：https://www.cnblogs.com/yanan7890/p/6617305.html]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 基本原理与配置]]></title>
    <url>%2Fpost%2FNginx-Basic-Principles%2F</url>
    <content type="text"><![CDATA[一、选用 Nginx 的理由1）支持高并发连接 得益于 Nginx 使用最新的 epoll（Linux 2.6 内核）和 kqueue(FreeBSD) 网络 I/O 模型，官方测试 Nginx 可最高支持 5 万的并发连接，在实际的生产环境中，可实际支持 2~4 万的并发连接数。2）内存消耗低 3）成本低 4）配置简单 5）支持 Rewrite 重写规则，能够根据域名、URL 的不同将 http 请求分发到不同的后端服务器群组。 6）内置健康检查功能，如果 Nginx proxy 后端的某台服务器宕机了，不会影响前端访问 7）节省带宽，支持 GZIP 压缩，可添加浏览器本地缓存的 header 8）稳定性高，用于反向代理，宕机概率极低 9）支持热部署，启动容易，几乎可以 7x24 小时不间断运行，且支持不间断服务的情况下，对软件进行升级。 二、Nginx 的启停运行环境：max os, Nginx 通过 brew install 安装，路径为：/usr/local/Cellar/nginx/1.10.2_1/ 1、启动 nginx [-c path] -c 选项可用来指定配置文件路径， 如 nginx -c /usr/local/etc/nginx.conf 2、停止 一般通过发送系统信号给 Nginx 主进程的方式来停止。可通过ps -ef | grep nginx 查看进程号 $ ps -ef | grep nginx 501 3709 1 0 3:10下午 ?? 0:00.00 nginx: master process nginx 501 3710 3709 0 3:10下午 ?? 0:00.00 nginx: worker process 501 3711 3709 0 3:10下午 ?? 0:00.01 nginx: worker process 501 3712 3709 0 3:10下午 ?? 0:00.01 nginx: worker process 501 3713 3709 0 3:10下午 ?? 0:00.01 nginx: worker process 501 3724 686 0 3:11下午 ttys001 0:00.00 grep nginx 如上所示，3709 为主进程，3710 ~ 3713 为工作子进程。nginx.conf 配置文件中指定了 pid 文件的存放路径， 如 / usr/local/var/run/nginx.pid， 其中存放了当前 Nginx 运行的主进程号，可通过该进程号，来平滑停止 Nginx 服务。 1) 平滑停止 $ kill -QUIT 3709 $ ps -ef | grep nginx 501 3989 686 0 3:49下午 ttys001 0:00.00 grep nginx # 或者，通过pid文件获取主进程号来停止 $ kill -QUIT `cat /usr/local/var/run/nginx.pid` 2）快速停止 $ kill -TERM 3709 $ ps -ef | grep nginx 501 3989 686 0 3:49下午 ttys001 0:00.00 grep nginx # 或者，通过pid文件获取主进程号来停止 $ kill -TERM `cat /usr/local/var/run/nginx.pid` # 另一种方式 $ kill -INT 3709 $ ps -ef | grep nginx 501 3989 686 0 3:49下午 ttys001 0:00.00 grep nginx # 或者，通过pid文件获取主进程号来停止 $ kill -INT `cat /usr/local/var/run/nginx.pid` 3）强制停止 $ pkill -9 nginx $ ps -ef | grep nginx 501 4081 686 0 3:57下午 ttys001 0:00.00 grep nginx 3、平滑重启 如果修改了配置文件 nginx.conf，想重启 Nginx，需要发送信号给 Nginx 主进程来实现。 $ ps -ef | grep nginx 501 4188 1 0 4:13下午 ?? 0:00.00 nginx: master process nginx 501 4189 4188 0 4:13下午 ?? 0:00.00 nginx: worker process 501 4190 4188 0 4:13下午 ?? 0:00.00 nginx: worker process 501 4191 4188 0 4:13下午 ?? 0:00.00 nginx: worker process 501 4192 4188 0 4:13下午 ?? 0:00.00 nginx: worker process 501 4195 686 0 4:13下午 ttys001 0:00.00 grep nginx $ kill -HUP `cat /usr/local/var/run/nginx.pid` $ ps -ef | grep nginx 501 4188 1 0 4:13下午 ?? 0:00.01 nginx: master process nginx 501 4201 4188 0 4:13下午 ?? 0:00.00 nginx: worker process 501 4202 4188 0 4:13下午 ?? 0:00.00 nginx: worker process 501 4203 4188 0 4:13下午 ?? 0:00.00 nginx: worker process 501 4204 4188 0 4:13下午 ?? 0:00.00 nginx: worker process 501 4206 686 0 4:13下午 ttys001 0:00.00 grep nginx 可以看出，重启的只是工作进程，当接收到 HUP 信号后，当前工作进程会关闭监听套接字，并继续为当前连接的客户端服务，当所有客户端服务完成后，旧的工作进程关闭。 4、其他信号 USR1: 重新打开日志文件，切割日志文件时有用 USR2: 平滑升级可执行程序 WINCTH: 从容关闭工作进程 $ kill -WINCH `cat /usr/local/var/run/nginx.pid` $ ps -ef | grep nginx 501 4188 1 0 4:13下午 ?? 0:00.01 nginx: master process nginx 501 4258 686 0 4:21下午 ttys001 0:00.00 grep nginx 三、Nginx 基本配置1、虚拟主机配置 虚拟主机提供了同一台服务器，同一个 Nginx 进程上运行多个网站的功能，Nginx 支持配置多种类型的虚拟主机： 基于 IP 的， 基于域名的， 基于端口号的。 在 nginx.conf 中，一台简化的虚拟主机配置如下： http { server { listen 8080; server_name localhost; access_log logs/host.access.log main; location / { root html; index index.html index.htm; } } } 基于 IP 的虚拟主机配置 通过 ifconfig 和 route 命令为当前服务器主机添加 IP 别名，如下： $ ifconfig eth0:1 192.168.1.102 broadcast 192.168.1.255 netmask 255.255.255.0 up $ route add -host 192.168.1.102 dev eth0:1 接下来分别对 192.168.1.101 和 192.168.1.102 配置虚拟主机 http { # 第一个虚拟主机 server { # 监听的IP和端口 listen 192.168.1.101:8080; # 主机名称 server_name 192.168.1.101; # 访问日志文件存放路径 access_log logs/host.access.log main; location / { # html网页文件存放目录 root /data0/htmldoc/server1; # 默认首页文件，从左至右，找不到index.html，就查找index.htm，都查找不到则报错 index index.html index.htm; } } # 第二个虚拟主机 server { listen 192.168.1.102:8080; server_name 192.168.1.102; access_log logs/host.access.log main; location / { root /data0/htmldoc/server2; index index.html index.htm; } } } 基于域名的虚拟主机配置 配置你的 DNS 服务器，将你的 IP 映射到不同的域名即可实现，可以有效解决 IP 地址不足的问题。 http { # 第一个虚拟主机 server { # 监听的IP和端口 listen 8080; # 主机名称 server_name aaa.ssl.com; # 访问日志文件存放路径 access_log logs/host.access.log main; location / { # html网页文件存放目录 root /data0/htmldoc/server1; # 默认首页文件，从左至右，找不到index.html，就查找index.htm，都查找不到则报错 index index.html index.htm; } } # 第二个虚拟主机 server { listen 8080; server_name bbb.ssl.com; access_log logs/host.access.log main; location / { root /data0/htmldoc/server2; index index.html index.htm; } } } 2、日志文件配置与切割 1）配置 log_format 日志格式 log_format name format [format..] log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;&apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;&apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; name 用来指定日志格式的名称，保持唯一性。 remoteaddr 用于记录远程客户端 IP 地址，还有另外一个变量http_x_forwarded_for 用来记录用户的 X-Forwarded-For IP 地址。 2）配置日志文件存放路径 access_log path [format [ buffer=size | off]] path: 存放路径 format: 日志格式名称，log_format 中设置的 name buffer: 内存缓冲区大小 off: 表示关闭日志记录 如： access_log /data0/logs/log1 combined buffer=32k; 3) 日志切割 a) 重命名原日志文件，然后向 Nginx 主进程发送 USR1 信号，让 Nginx 重新生成一个新的日志文件。 mv /data0/logs/access.log /data0/logs/20170716.log kill -USR1 cat /usr/local/var/run/nginx.pid b）按天定时切割日志文件的方式 # !/bin/bash # 这个脚本须在每天的00：00运行, 保存为cut_nginx.log.sh # Nginx日志文件的存放路径 logs_path=&quot;/data0/logs&quot; mkdir -p ${logs_path}$(date -d &quot;yesterday&quot;+&quot;%Y&quot;)/$(date -d &quot;yesterday&quot;+&quot;%m&quot;)/ mv ${logs_path}access.log ${logs_path}$(date -d &quot;yesterday&quot;+&quot;%Y&quot;)/$(date -d &quot;yesterday&quot;+&quot;%m&quot;)/access_$(date -d &quot;yesterday&quot;+&quot;%Y%m%d&quot;).log kill -USR1 `cat /usr/local/var/nginx/nginx.pid` 配置 crontab 每天凌晨 00:00 定时执行该脚本 crontab -e 输入： 00 00 * * * /bin/bash /usr/local/var/nginx/sbin/cut_nginx.log.sh 3、压缩配置 gzip 压缩后，页面大小可变为原来的 30% 甚至更小，这样用户浏览页面时速度会快很多。 4、自动列目录 location / { # html网页文件存放目录 root /Users/qwe/Desktop; # 自动列出目录 autoindex on; } 5、浏览器本地缓存设置 浏览器将用户最近请求过的页面存储到本地磁盘，当用户再次访问时，可以直接从本地磁盘显示文档，加速页面浏览速度，节约网络资源。 浏览器缓存通过 expires 指令输出 header 头来实现 。 语法： expires [time | epoch | max | off] 默认值： expires off 作用域：http, server, location 用途： 使用本指令可以控制 HTTP 应答中的 “Expires” 和“Cache-Control” epoch 指定 Expires 值为 1 January，1970，00：00：01 GMT max 指定 Expires 值为 31 December，2037 23：59：59 GMT， Cache-Control 值为 10 年 -1 指定 “Expires” 值为服务器当前时间，即永远过期。 Cache-Control 的值由你指定的时间来决定， 负数表示 no-cache， 正数或零为你指定时间的秒数。 ”off“表示不修改 “Expires” 和”Cache-Control“的值。 一般对常见格式的图片、Flash 文件缓存 30 天，对 js、css 文件缓存 1 小时。如下： location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 30d; } location ~ .*\.(js|css)${ expires 1h; } 原文：https://www.cnblogs.com/java-wgm/p/7160530.html]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[已知一个下载文件的后端接口，前端如何请求该接口，实现点击按钮、下载文件到本地。]]></title>
    <url>%2Fpost%2Fdownload-file-method%2F</url>
    <content type="text"><![CDATA[在线例子：https://hamupp.github.io/gitblog/app/jsBasic/jsButtonDownloadFile/index.html方法一：window.open(“下载文件的后端接口”); html结构 &lt;button type=&quot;button&quot; id=&quot;btn1&quot;&gt;下载一个zip（方法1）&lt;/button&gt; &lt;button type=&quot;button&quot; id=&quot;btn2&quot;&gt;下载一个zip（方法2）&lt;/button&gt; js部分 var $eleBtn1 = $(&quot;#btn1&quot;); var $eleBtn2 = $(&quot;#btn2&quot;); //已知一个下载文件的后端接口：https://codeload.github.com/douban/douban-client/legacy.zip/master //方法一：window.open() $eleBtn1.click(function(){ window.open(&quot;https://codeload.github.com/douban/douban-client/legacy.zip/master&quot;); }); 然而有个问题：浏览器会打开一个新窗口，然后迅速自动关闭，体验非常不好。 方法二：通过form提交 由于ajax函数的返回类型只有xml、text、json、html等类型，没有“流”类型，所以通过ajax去请求该接口是无法下载文件的，所以我们创建一个新的form元素来请求接口。 js部分 //方法二：通过form $eleBtn2.click(function(){ var $eleForm = $(&quot;&lt;form method=&apos;get&apos;&gt;&lt;/form&gt;&quot;); $eleForm.attr(&quot;action&quot;,&quot;https://codeload.github.com/douban/douban-client/legacy.zip/master&quot;); $(document.body).append($eleForm); //提交表单，实现下载 $eleForm.submit(); }); 转自：https://blog.csdn.net/qq_33058239/article/details/78840275]]></content>
      <categories>
        <category>html</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java根据list中对象的属性找出list重复数据或去除list重复数据]]></title>
    <url>%2Fpost%2Fjava-list-remov-repeat%2F</url>
    <content type="text"><![CDATA[在实际开发中，经常会遇到需要找出(删除)一个list中某些元素的属性相同的元素，或者两个list中某些元素的属性相等的元素，这种方法很多，这里整理列出一些：废话不说，上代码，有注释掉的你们自己看 import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; public class Test { public static void main(String[] args) { List&lt;Student&gt; testList = new ArrayList&lt;Student&gt;(); testList.add(new Student(&quot;张一&quot;)); testList.add(new Student(&quot;张二&quot;)); testList.add(new Student(&quot;张三&quot;)); testList.add(new Student(&quot;老王&quot;)); testList.add(new Student(&quot;张四&quot;)); testList.add(new Student(&quot;张五&quot;)); testList.add(new Student(&quot;张六&quot;)); testList.add(new Student(&quot;张七&quot;)); testList.add(new Student(&quot;老王&quot;)); testList.add(new Student(&quot;张八&quot;)); testList.add(new Student(&quot;张九&quot;)); testList.add(new Student(&quot;老王&quot;)); List&lt;Student&gt; repeatList = new ArrayList&lt;Student&gt;();//用于存放重复的元素的list // 以一种方法：两个循环(最蠢的方法) for (int i = 0; i &lt; testList.size() - 1; i++) { for (int j = testList.size() - 1; j &gt; i; j--) { if (testList.get(j).getStuName().equals(testList.get(i).getStuName())) { repeatList.add(testList.get(j));//把相同元素加入list(找出相同的) testList.remove(j);//删除重复元素 } } } // for(Student s : repeatList){ // System.out.println(&quot;相同的元素:&quot; + s.getStuName()); // } //第二种方法：利用map.containsKey() Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for(Student s : testList){ //1:map.containsKey() 检测key是否重复 if(map.containsKey(s.getStuName())){ repeatList.add(s);//获取重复的学生名称 Integer num = map.get(s.getStuName()); map.put(s.getStuName(), num+1); }else{ map.put(s.getStuName(), 1); } //2: 这个key是不是存在对应的value(key是否在map中) // Integer count = map.get(s.getStuName());//这种写法也可以，异曲同工 // if (count == null) { // map.put(s.getStuName(), 1); // } else { // map.put(s.getStuName(), (count + 1)); // } } // for(Student s : repeatList){ // System.out.println(&quot;相同的元素:&quot; + s.getStuName()); // } // for(Map.Entry&lt;String, Integer&gt; entry : map.entrySet()){ // System.out.println(&quot;学生:&quot; + entry.getKey() + &quot;的名字出现了：&quot; + entry.getValue() + &quot;次&quot;); // } //第三种方法：contains()方法 这个个人认为有一定的局限性，个人理解哈 List&lt;Integer&gt; repeatList1 = new ArrayList&lt;&gt;(); List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(1); list.add(2); list.add(1); list.add(3); list.add(4); list.add(1); list.add(5); for(int i=0;i&lt;list.size();i++){ if(!repeatList1.contains(list.get(i))){ repeatList1.add(list.get(i)); } } for(Integer s : repeatList1){ System.out.println(s); } } Student类： public class Student { public Student(String stuName){ this.stuName = stuName; } private String stuName; public String getStuName() { return stuName; } public void setStuName(String stuName) { this.stuName = stuName; } } 这个是java8的stream，由于我用的和是jdk7 这里就找了一个 给你们当例子看，有兴趣可以看stream相关的知识，很强大的功能 List&lt;String&gt; list = Arrays.asList(&quot;123&quot;, &quot;1234&quot;, &quot;12345&quot;, &quot;123456&quot;, &quot;1234567&quot;, &quot;122222223&quot;, &quot;123&quot;, &quot;1234&quot;, &quot;2422&quot;); Map&lt;String, Long&gt; collect = list.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting())); System.out.println(collect); 就列出这么几种，应该够用了 转自：https://blog.csdn.net/qq_34203492/article/details/78561562]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String.isEmpty() 方法使用的坑点]]></title>
    <url>%2Fpost%2FString-isEmpty-function%2F</url>
    <content type="text"><![CDATA[String的三种状态：null ， “” 和new String；怎么判断String是否为空呢？ public static void main(String[] args) { String a = null; String b = &quot;&quot;; String c = new String(); //test(a); //test(b); test(c); } public static void test(String string){ if(string==null){ System.out.println(&quot;string == null&quot;); } if(&quot;&quot;.equals(string)){ System.out.println(&quot;string 为 &apos;&apos; &quot;); } if(string.isEmpty()){ System.out.println(&quot;string 为 empty&quot;); } } 这个里面有一个坑点：String的isEmpty()方法，在String为null的时候，会出现空指针错误！！！！因为，”” 和 new String()，会有占位符，也就是创建了对象，而null的时候，String 不会创建占位符。————–更通俗的说就是：”” 和new String() 的时候，String是有长度的，而null没有长度。 综上，以后判断String的时候，使用lang3下的StringUtiles工具类可以完美的避过以上的坑点。StringUtils.isNotBlank（）和StringUtils.isNotEmpty() 转自:https://blog.csdn.net/fcfwang_net/article/details/79404338]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql语句获取今天、昨天、近7天、本周、上周、本月、上月、半年数据]]></title>
    <url>%2Fpost%2Fsql-get-data-by-date%2F</url>
    <content type="text"><![CDATA[话说有一文章表article，存储文章的添加文章的时间是add_time字段，该字段为int(5)类型的，现需要查询今天添加的文章总数并且按照时间从大到小排序，则查询语句如下： 1 select * from `article` where date_format(from_UNIXTIME(`add_time`),&apos;%Y-%m-%d&apos;) = date_format(now(),&apos;%Y-%m-%d&apos;); 或者： 2 select * from `article` where to_days(date_format(from_UNIXTIME(`add_time`),&apos;%Y-%m-%d&apos;)) = to_days(now()); 假设以上表的add_time字段的存储类型是DATETIME类型或者TIMESTAMP类型，则查询语句也可按如下写法： 查询今天的信息记录： 3 select * from `article` where to_days(`add_time`) = to_days(now()); 查询昨天的信息记录： 4 select * from `article` where to_days(now()) – to_days(`add_time`) &lt;= 1; 查询近7天的信息记录： 5 select * from `article` where date_sub(curdate(), INTERVAL 7 DAY) &lt;= date(`add_time`); 查询近30天的信息记录： 6 select * from `article` where date_sub(curdate(), INTERVAL 30 DAY) &lt;= date(`add_time`); 查询本月的信息记录： 7 select * from `article` where date_format(`add_time`, ‘%Y%m&apos;) = date_format(curdate() , ‘%Y%m&apos;); 查询上一月的信息记录： 8 select * from `article` where period_diff(date_format(now() , ‘%Y%m&apos;) , date_format(`add_time`, ‘%Y%m&apos;)) =1; 对上面的SQL语句中的几个函数做一下分析： （1）to_days 就像它的名字一样，它是将具体的某一个日期或时间字符串转换到某一天所对应的unix时间戳，如： 01 mysql&gt; select to_days(&apos;2010-11-22 14:39:51&apos;); 02 +--------------------------------+ 03 | to_days(&apos;2010-11-22 14:39:51&apos;) | 04 +--------------------------------+ 05 | 734463 | 06 +--------------------------------+ 07 08 mysql&gt; select to_days(&apos;2010-11-23 14:39:51&apos;); 09 +--------------------------------+ 10 | to_days(&apos;2010-11-23 14:39:51&apos;) | 11 +--------------------------------+ 12 | 734464 | 13 +--------------------------------+ 可以看出22日与23日的差别就是，转换之后的数增加了1，这个粒度的查询是比较粗糙的，有时可能不能满足我们的查询要求，那么就需要使用细粒度的查询方法str_to_date函数了，下面将分析这个函数的用法。 提醒： （1）to_days() 不用于阳历出现(1582)前的值，原因是当日历改变时，遗失的日期不会被考虑在内。因此对于1582 年之前的日期(或许在其它地区为下一年 ), 该函数的结果实不可靠的。 （2）MySQL&quot;日期和时间类型&quot;中的规则是将日期中的二位数年份值转化为四位。因此对于&apos;1997-10-07&apos;和&apos;97-10-07&apos;将被视为同样的日期: 1 mysql&gt; select to_days(&apos;1997-10-07&apos;), to_days(&apos;97-10-07&apos;); 2 3 -&gt; 729669, 729669 （2）str_to_date 这个函数可以把字符串时间完全的翻译过来，如： 1 mysql&gt; select str_to_date(&quot;2010-11-23 14:39:51&quot;,&apos;%Y-%m-%d %H:%i:%s&apos;); 2 3 +--------------------------------------------------------+ 4 | str_to_date(&quot;2010-11-23 14:39:51&quot;,&apos;%Y-%m-%d %H:%i:%s&apos;) | 5 +--------------------------------------------------------+ 6 | 2010-11-23 14:39:51 | 7 +--------------------------------------------------------+ 具体案例操作如下： 1 select str_to_date(article.`add_time`,&apos;%Y-%m-%d %H:%i:%s&apos;) 2 from article 3 where str_to_date(article.`add_time`,&apos;%Y-%m-%d %H:%i:%s&apos;)&gt;=&apos;2012-06-28 08:00:00&apos; and str_to_date(article.`add_time`,&apos;%Y-%m-%d %H:%i:%s&apos;)&lt;=&apos;2012-06-28 09:59:59&apos;; 查询 今天 select * from 表名 where to_days(时间字段名) = to_days(now()); 昨天 SELECT * FROM 表名 WHERE TO_DAYS( NOW( ) ) – TO_DAYS( 时间字段名) &lt;= 1 7天 SELECT * FROM 表名 where DATE_SUB(CURDATE(), INTERVAL 7 DAY) &lt;= date(时间字段名) 近30天 SELECT * FROM 表名 where DATE_SUB(CURDATE(), INTERVAL 30 DAY) &lt;= date(时间字段名) 本月 SELECT * FROM 表名 WHERE DATE_FORMAT( 时间字段名, ‘%Y%m’ ) = DATE_FORMAT( CURDATE( ) , ‘%Y%m’ ) 上一月 SELECT * FROM 表名 WHERE PERIOD_DIFF( date_format( now( ) , ‘%Y%m’ ) , date_format( 时间字段名, ‘%Y%m’ ) ) =1 同时，再附上 一个 mysql官方的相关document #查询本季度数据 select * from `ht_invoice_information` where QUARTER(create_date)=QUARTER(now()); #查询上季度数据 select * from `ht_invoice_information` where QUARTER(create_date)=QUARTER(DATE_SUB(now(),interval 1 QUARTER)); #查询本年数据 select * from `ht_invoice_information` where YEAR(create_date)=YEAR(NOW()); #查询上年数据 select * from `ht_invoice_information` where year(create_date)=year(date_sub(now(),interval 1 year)); 查询当前这周的数据 SELECT name,submittime FROM enterprise WHERE YEARWEEK(date_format(submittime,&apos;%Y-%m-%d&apos;)) = YEARWEEK(now()); 查询上周的数据 SELECT name,submittime FROM enterprise WHERE YEARWEEK(date_format(submittime,&apos;%Y-%m-%d&apos;)) = YEARWEEK(now())-1; 查询当前月份的数据 select name,submittime from enterprise where date_format(submittime,&apos;%Y-%m&apos;)=date_format(now(),&apos;%Y-%m&apos;) 查询距离当前现在6个月的数据 select name,submittime from enterprise where submittime between date_sub(now(),interval 6 month) and now(); 查询上个月的数据 select name,submittime from enterprise where date_format(submittime,&apos;%Y-%m&apos;)=date_format(DATE_SUB(curdate(), INTERVAL 1 MONTH),&apos;%Y-%m&apos;) select * from ` user ` where DATE_FORMAT(pudate, &apos; %Y%m &apos; ) = DATE_FORMAT(CURDATE(), &apos; %Y%m &apos; ) ; select * from user where WEEKOFYEAR(FROM_UNIXTIME(pudate,&apos;%y-%m-%d&apos;)) = WEEKOFYEAR(now()) select * from user where MONTH (FROM_UNIXTIME(pudate, &apos; %y-%m-%d &apos; )) = MONTH (now()) select * from [ user ] where YEAR (FROM_UNIXTIME(pudate, &apos; %y-%m-%d &apos; )) = YEAR (now()) and MONTH (FROM_UNIXTIME(pudate, &apos; %y-%m-%d &apos; )) = MONTH (now()) select * from [ user ] where pudate between 上月最后一天 and 下月第一天 where date(regdate) = curdate(); select * from test where year(regdate)=year(now()) and month(regdate)=month(now()) and day(regdate)=day(now()) SELECT date( c_instime ) ,curdate( ) FROM `t_score` WHERE 1 LIMIT 0 , 30 转自：https://www.cnblogs.com/xiaoqian1993/p/5260789.html]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>sql</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底解决 Intellij IDEA 卡顿 优化笔记]]></title>
    <url>%2Fpost%2Fidea-config%2F</url>
    <content type="text"><![CDATA[由于工作中经常出现分支各种切换，使用Eclipse便不再像以前那么舒服了，不停的修改工作空间，每次修改完工作空间又是一堆一堆的个性化设置，来回的切换，真的很累。我们做软件的，怎么能不去尝试新鲜的呢，毕竟，再难走的路，也有人已经走过，我们只需要Google一下而已。 本篇适用于Idea 14.x 15.x 16.x这次在使用了2天的IDEA之后，我发现这玩意简直屌爆了！这次我重新进行征服IDEA过程中，遇到了很多很多的问题，当然，有一句话说的很好，遇到一件很难搞的事情，但凡你有半点犹豫，那就肯定是有办法搞定，而你只不过不愿意搞而已。于是硬着头皮，下载IDEA14，注册，破解，优化，背快捷键，debug，解决idea卡顿，等等等等。真是用的多了，就发现了它比Eclipse好太多了，整个开发流程很清晰，效率提升了不少。那么我来说一下最重要的几点吧，网上的文章也都比较老了，今天是2015年11月26日。怎么安装我就不说了。1.解决卡顿这个是重中之重的！！必须解决，否则你每敲一行代码就卡你一下午的滋味真的不好受，首先你要有8G内存，没有8G内存的话，下面的应该也有用。但是我还是建议开发起来上8G好一些。(1)File-Settings-Editor-General- 去掉 show quick doc on mouse move(2)File-Settings-Perferences-&gt;Inspections,点Copy，复制一份，名称任意。然后点击下面工具栏中的Reset to empty。保存。(3)去idea安装路径的bin目录下找到 idea.exe.vmoptions，调整IDEA的启动JVM参数，64位的修改idea64.exe.vmoptions，最小512M最大2048M即可。32位的修改idea.exe.vmoptions，最小256M，最大512M即可。2.每次打开IDEA都会有一个进度条idea updating indices删掉 c:/user/.IntellIJIdea14/system/caches 这个文件夹，然后 file - Invalidate Caches / Restart，点击Invalidate Caches按钮 之后，Idea会重启，重启完了，会再次updating indices，之后你随便关闭都哦了~~3.IDEA不实时编译话说，还是让它实时编译的好，因为有时候不编译挺难受的。参考：http://www.mincoder.com/article/2365.shtmlhttp://my.oschina.net/fdblog/blog/1722294.Jetty 热部署参考:http://www.cnblogs.com/java-koma/archive/2012/11/30/2796737.html5.重要的快捷键(1)ALT+F7 类似于EClipse的 show call history 查看被谁调用(2)Alt + 回车 智能提示(3)Shift + Alt + 上下，类似于Eclipse Alt + 上下 把当前选中的上下移动(4)调试Debug必备快捷键F9 resume programe 恢复程序Alt+F10 show execution point 显示执行断点F8 Step Over 相当于eclipse的f6 跳到下一步F7 Step Into 相当于eclipse的f5就是 进入到代码Alt+shift+F7 Force Step Into 这个是强制进入代码Shift+F8 Step Out 相当于eclipse的f8跳到下一个断点，也相当于eclipse的f7跳出函数Atl+F9 Run To Cursor 运行到光标处ctrl+shift+F9 debug运行java类ctrl+shift+F10 正常运行java类alt+F8 debug时选中查看值(5)Ctrl + B 类似于Eclipse的F3,直接进入某类，就和鼠标+Ctrl是一样一样的。(6)当修改了java文件时，在IntelliJ中按：‘Ctrl+Shift+F9’ 将重新编译该java文件，如果修改了多个java文件，按‘Ctrl+F9’ 可以重新编译整个工程。6.一个窗口开启多个项目用Eclipse的我们都知道，一个workspace里面放置多个工程，彼此依赖啊项目什么的玩的66的，然而IDEA，新手刚上来也想要这种效果就是IDEA一个窗口里面运行多个项目，有些人说这是不科学的，他们都是一个窗口开WEB，一个窗口开Java项目，或者另一个Web项目。下面我说下我的办法，其实是利用IDEA的Module模式，首先引入Web项目，之后再引用它依赖的项目，只不过有一定的操作步骤，跟我前来。导入Web项目打开项目管理器Project Structure，选择Modules，点加号，然后将它所依赖的模块导入进来还是项目管理器Project Structure，选择Modules，点Web主项目，再点右边的加号，选择Module dependency,之后选择它依赖的模块，就算是引入进来了这还没有结束，因为，你还想在Debug的时候，通过进入类的方法，不进入Class文件，直接进入它所依赖的模块的源码中，这就需要这么玩，把你的项目放在maven或者jar之前就行啦。下面这样操作。未完，继续补充 转自：https://www.cnblogs.com/ae6623/]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>IDE</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Eureka 服务关闭但是未从注册中心删除?]]></title>
    <url>%2Fpost%2FSpring-Cloud-Eureka-Self-protection-mechanism%2F</url>
    <content type="text"><![CDATA[自我保护背景首先对 Eureka 注册中心需要了解的是 Eureka 各个节点都是平等的，没有 ZK 中角色的概念， 即使 N-1 个节点挂掉也不会影响其他节点的正常运行。 默认情况下，如果 Eureka Server 在一定时间内（默认 90 秒）没有接收到某个微服务实例的心跳，Eureka Server 将会移除该实例。但是当网络分区故障发生时，微服务与 Eureka Server 之间无法正常通信，而微服务本身是正常运行的，此时不应该移除这个微服务，所以引入了自我保护机制。 自我保护机制官方对于自我保护机制的定义： https://github.com/Netflix/eureka/wiki/Understanding-Eureka-Peer-to-Peer-Communication 自我保护模式正是一种针对网络异常波动的安全保护措施，使用自我保护模式能使 Eureka 集群更加的健壮、稳定的运行。 自我保护机制的工作机制是如果在 15 分钟内超过 85% 的客户端节点都没有正常的心跳，那么 Eureka 就认为客户端与注册中心出现了网络故障，Eureka Server 自动进入自我保护机制，此时会出现以下几种情况： 1、Eureka Server 不再从注册列表中移除因为长时间没收到心跳而应该过期的服务。 2、Eureka Server 仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上，保证当前节点依然可用。 3、当网络稳定时，当前 Eureka Server 新的注册信息会被同步到其它节点中。 因此 Eureka Server 可以很好的应对因网络故障导致部分节点失联的情况，而不会像 ZK 那样如果有一半不可用的情况会导致整个集群不可用而变成瘫痪。 自我保护开关Eureka 自我保护机制，通过配置 eureka.server.enable-self-preservation 来 true 打开 / false 禁用自我保护机制，默认打开状态，建议生产环境打开此配置。 服务器端配置： eureka: server: # 测试时关闭自我保护机制，保证不可用服务及时踢出 enable-self-preservation: false 客户配置： # 心跳检测检测与续约时间 # 测试时将值设置设置小些，保证服务关闭后注册中心能及时踢出服务 eureka: instance: lease-renewal-interval-in-seconds: 1 lease-expiration-duration-in-seconds: 2 以上配置说明 lease-renewal-interval-in-seconds 每间隔 1s，向服务端发送一次心跳，证明自己依然” 存活 “ lease-expiration-duration-in-seconds 告诉服务端，如果我 2s 之内没有给你发心跳，就代表我 “死” 了，将我踢出掉。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中的Transactional注解放在类级别和方法级别上有什么不同？]]></title>
    <url>%2Fpost%2Fspring-transactional%2F</url>
    <content type="text"><![CDATA[spring中的@Transactional 放在类级别 和 方法级别 上有什么不同？ @Transactional 放在类级别上是否等同于该类的每个方法都放上了@Transactional？是的一般类上这么写 //默认将类中的所有函数纳入事务管理. @Transactional(readOnly=true) //配置事务 查询使用只读 public Demo{ //方法的写法 (增删改要写 ReadOnly=false 为可写) @Transactiona(propagation=Propagation.REQUIRED,isolation=Isolation.DEFAULT,readOnly=false) public void saveUser(){ } } Propagation.REQUIRED ：有事务就处于当前事务中，没事务就创建一个事务isolation=Isolation.DEFAULT：事务数据库的默认隔离级别readOnly=false：可写 针对 增删改操作 注意：方法的@Transactional会覆盖类上面声明的事务]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot启动加载MySQL配置Establishing SSL报错解决]]></title>
    <url>%2Fpost%2Fmysql-useSSL%2F</url>
    <content type="text"><![CDATA[原因：mysql版本过高创建连接的时候会出现如下报告Tue May 16 09:08:59 CST 2017 WARN: Establishing SSL connection without server&#39;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&#39;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &#39;false&#39;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification. 解决办法：在mysql连接上加上&amp;useSSL=true 如下：jdbc:mysql:///:3366:test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true ssl是一种加密技术在客户端连接数据库的中间做了加密，TCP/IP层中。 SSL的百度百科]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组集合字符串转换对象的ArrayList异常问题]]></title>
    <url>%2Fpost%2FJSONException%2F</url>
    <content type="text"><![CDATA[一、异常描述 关于基于alibaba的fastjson.jar包实现字符串及对象集合间转换（具体示例参考示例页面），最新在实现网关数据集合字符串转换为对象集合的时候报出“com.alibaba.fastjson.JSONException: not match : - =..”异常,详细日志如下所示 com.alibaba.fastjson.JSONException: not match : - = at com.alibaba.fastjson.parser.JSONLexerBase.nextTokenWithChar(JSONLexerBase.java:387) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.parser.JSONLexerBase.nextTokenWithColon(JSONLexerBase.java:497) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.parseField(JavaBeanDeserializer.java:789) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:596) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:188) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:184) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.parser.DefaultJSONParser.parseArray(DefaultJSONParser.java:726) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.parser.DefaultJSONParser.parseArray(DefaultJSONParser.java:662) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.parser.DefaultJSONParser.parseArray(DefaultJSONParser.java:657) ~[fastjson-1.2.29.jar:?] at com.alibaba.fastjson.JSON.parseArray(JSON.java:514) ~[fastjson-1.2.29.jar:?] at com.pingan.bank.cfss.ldsp.dispatchorder.web.TaskSheetController.taskSheetResult(TaskSheetController.java:141) [classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.7.0_80] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[?:1.7.0_80] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.7.0_80] at java.lang.reflect.Method.invoke(Method.java:606) ~[?:1.7.0_80] at com.woopa.soofa.annotation.MethodESA.invokeMethod(MethodESA.java:134) at com.woopa.soofa.annotation.MethodESA.perform(MethodESA.java:45) at com.woopa.soofa.annotation.MethodESADispatcher._handleRequest(MethodESADispatcher.java:114) at com.woopa.soofa.annotation.MethodESADispatcher.handleRequest(MethodESADispatcher.java:50) at com.woopa.soofa.papp.sar.context.DefaultSARDispatcherBean._handleRequest(DefaultSARDispatcherBean.java:118) at com.woopa.soofa.papp.sar.context.DefaultSARDispatcherBean.handleRequest(DefaultSARDispatcherBean.java:56) at com.woopa.soofa.papp.sar.SARContextBean.handleRequest(SARContextBean.java:224) at com.woopa.soofa.papp.context.support.ESAManagerBean.handleInnerRequest(ESAManagerBean.java:205) at com.woopa.soofa.papp.context.support.ESAManagerBean.handleRequest(ESAManagerBean.java:178) at com.woopa.soofa.papp.PAppContextBean.handleRequest(PAppContextBean.java:120) at com.woopa.soofa.papp.protocol.dubbo.ESADubboGenericService.handleAction(ESADubboGenericService.java:52) at com.woopa.soofa.papp.protocol.dubbo.ESADubboGenericService.$invoke(ESADubboGenericService.java:42) at com.alibaba.dubbo.common.bytecode.Wrapper1.invokeMethod(Wrapper1.java) [?:2.4.15] at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:64) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:42) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:74) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:78) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:63) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:112) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:38) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:38) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:108) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:84) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:170) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:52) [dubbo-2.4.15.jar:2.4.15] at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:82) [dubbo-2.4.15.jar:2.4.15] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_80] at java.lang.Thread.run(Thread.java:745) [?:1.7.0_80] 二、解决方法 1.传过来的字符串格式如下所示 { id=1, name=444, class=class com.woopa.web.form.DataForm, list=[ { child_id=123412, child_name=0 } ] } 2.最开始写的转换代码如下 List&lt;DataDTO&gt; datalist = JSONArray.parseArray(form.getList(),DataDTO.class); 3.修改如下即解决问题 String listTxt = JSONArray.toJSONString(form.getList()); List&lt;DataDTO&gt; list = JSONArray.parseArray(listTxt, DataDTO.class); 转自：http://www.xwood.net/_site_domain_/_root/5870/5874/t_c267786.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA中【isEmpty】和【null】以及【""】的区别]]></title>
    <url>%2Fpost%2FisEmpty%26null%26emptyString%2F</url>
    <content type="text"><![CDATA[这是一个比较容易混淆的概念，为了弄清楚这个问题，最好的方法当然是写程序来验证，上代码吧~~： package JavaTest; public class TestNull { /** * @param args */ public static void main(String[] args) { String a = new String(); String b = &quot;&quot;; String c = null; if(a.isEmpty()) { System.out.println(&quot;String a = new String&quot;); } if(b.isEmpty()) { System.out.println(&quot;String b = \&quot;\&quot;&quot;); } if(c==null) { System.out.println(&quot;String c =null&quot;); } if(null == a) { System.out.println(&quot;String a =null&quot;); } if(a==&quot;&quot;) { System.out.println(&quot;a = &apos;&apos;&quot;); } } } 以上输出： String a = new String String b = &quot;&quot; String c =null 分析： 此时a是分配了内存空间，但值为空，是绝对的空，是一种有值（值存在为空而已） 此时b是分配了内存空间，值为空字符串，是相对的空，是一种有值（值存在为空字串） 此时c是未分配内存空间，无值，是一种无值(值不存在) 转自：https://blog.csdn.net/lhflower123/article/details/8223607]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot自动配置的实现原理]]></title>
    <url>%2Fpost%2FSpringBoot-Auto-Configure-Principle%2F</url>
    <content type="text"><![CDATA[之前一直在用 SpringBoot 框架，一直感觉 SpringBoot 框架自动配置的功能很强大，但是并没有明白它是怎么实现自动配置的，现在有空研究了一下，大概明白了 SpringBoot 框架是怎么实现自动配置的功能，我们编写一个最简单的自动配置功能，大概的总结一下. 一, 配置属性类 其实就是值对象注入的方式去配置一些 Spring 常用的配置，我们编写一个最简单的配置对象。 @ConfigurationProperties(prefix = &quot;hello&quot;) //@Component //如果这里添加了注解那么在自动配置类的时候就不用添加@enableConfigurationProperties(HelloProperties.class)注解. public class HelloProperties { private String msg=&quot;default&quot;;//现在我们在配置文件写hello.msg=world,因为简单就不再展示;如果那么默认为default. public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; } } 这是一个简单的属性值对象，那么相当于写死的字段就是 SpringBoot 为我们自动配置的配置，那么我们很多时候可以自己在 application.properties 中修改某些配置就是这样的道理，我们不设置就是默认的，设置了就是我们设置的属性。 二, 自动配置类 上面已经构建了我们简单的属性对象，那么现在我们要通过属性对象得到相应的属性值将其注入到我们的 Bean 中，这些 Bean 也就是一些 SpringBoot 启动后为我们自动配置生成的 Bean，当然 SpringBoot 优先使用我们配置的 Bean 这个功能是如何实现的, 我们往下看一下就明白了。 首先我们需要一个功能 Bean，可以把这个 Bean 看做是 SpringBoot 框架启动后在容器里面生成的为我们服务的内置 Bean, 简单的写一个。 //@Component 这里很重要，如果我们添加了这个注解那么，按照我们下面的设置SpringBoot会优先使用我们配置的这个Bean，这是符合SpringBoot框架优先使用自定义Bean的原则的。 public class HelloService { private String msg = &quot;service&quot;;//如果自动配置没有读入成功，那么为默认值 public String say() { return &quot;hello &quot; + msg; }//为我们服务的方法 public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; } } 现在编写我们的自动配置类。 @Configuration //配置类 @EnableConfigurationProperties(HelloProperties.class)//这里就是前面说的，这个注解读入我们的配置对象类 @ConditionalOnClass(HelloService.class)//当类路径存在这个类时才会加载这个配置类，否则跳过,这个很有用比如不同jar包间类依赖，依赖的类不存在直接跳过，不会报错 public class HelloAutoConfiguration { @Autowired private HelloProperties helloProperties; @Bean @ConditionalOnMissingBean(HelloService.class)//这个配置就是SpringBoot可以优先使用自定义Bean的核心所在，如果没有我们的自定义Bean那么才会自动配置一个新的Bean public HelloService auto(){ HelloService helloService =new HelloService(); helloService.setMsg(helloProperties.getMsg()); return helloService; } } 好了现在自动配置的类也写好了，我们可以启动一下 SpringBoot 应用，测试一下。 三, 测试自动配置 @SpringBootApplication @RestController public class MyRun { @Autowired private HelloService helloService; @RequestMapping(&quot;/auto/home&quot;) public String home(){ return helloService.say(); } public static void main(String[] args) { SpringApplication.run(MyRun.class,args); } } ok , 运行后访问你会看到： hello world 代表我们的自动配置功能成功。 四, SpringBoot 管理自动配置 其实在很多时候我们的配置是在很多 jar 包里的，那么我们新的应用该怎么读入这些 jar 包里的配置文件呢，SpringBoot 是这样管理的。 最主要的注解就是 @enableAutoConfiguration, 而这个注解会导入一个 EnableAutoConfigurationImportSelector 的类, 而这个类会去读取一个 spring.factories 下 key 为 EnableAutoConfiguration 全限定名对应值. # Auto Configure org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\ org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\ org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\ org.springframework.boot.autoconfigure.MessageSourceAutoConfiguration,\ org.springframework.boot.autoconfigure.PropertyPlaceholderAutoConfiguration,\ org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\ org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\ org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\ org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\ org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\ org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\ org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\ org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\ org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\ org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\ org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\ org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\ org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\ org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\ org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\ org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\ org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\ org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\ org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\ org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\ org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\ org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\ org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\ org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.hornetq.HornetQAutoConfiguration,\ org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\ org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\ org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\ org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\ org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\ org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\ org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\ org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\ org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\ org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\ org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\ org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\ org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\ org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\ org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\ org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\ org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\ org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\ org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\ org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\ org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\ org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\ org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\ org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\ org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\ org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\ org.springframework.boot.autoconfigure.velocity.VelocityAutoConfiguration,\ org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\ org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\ org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\ org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\ org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\ org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\ org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\ org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\ org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\ org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\ org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\ org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\ org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\ org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\ org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 所以如果需要我们可以在我们的 resources 目录下创建 spring.factories 下添加类似的配置即可。。 ok，自动配置的原理差不多就这样，我现在了解的并不深入，还需要继续学习。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 实现前后端分离的跨域访问（CORS）]]></title>
    <url>%2Fpost%2FSpringBoot-CORS%2F</url>
    <content type="text"><![CDATA[一、基本介绍简单来说，CORS 是一种访问机制，英文全称是 Cross-Origin Resource Sharing，即我们常说的跨域资源共享，通过在服务器端设置响应头，把发起跨域的原始域名添加到 Access-Control-Allow-Origin 即可。 CORS 工作原理CORS 实现跨域访问并不是一蹴而就的，需要借助浏览器的支持，从原理题图我们可以清楚看到，简单的请求（通常指 GET/POST/HEAD 方式，并没有去增加额外的请求头信息）直接创建了跨域请求的 XHR 对象，而复杂的请求则要求先发送一个” 预检” 请求，待服务器批准后才能真正发起跨域访问请求。 根据官方文档 W3C 规范 - CORS 的描述，目前 CORS 使用了如下头部信息： 注：请求头信息由浏览器检测到跨域自动添加，无需过多干预，重点放在 Response headers，它可以帮助我们在服务器进行跨域授权，例如允许哪些原始域可放行，是否需要携带 Cookie 信息等。 Request Headers（请求头）Origin 表示跨域请求的原始域。Access-Control-Request-Method表示跨域请求的方式。（如 GET/POST）Access-Control-Request-Headers表示跨域请求的请求头信息。 Response headers（响应头 ）Access-Control-Allow-Origin表示允许哪些原始域进行跨域访问。（字符数组）Access-Control-Allow-Credentials表示是否允许客户端获取用户凭据。（布尔类型）使用场景：例如现在从浏览器发起跨域请求，并且要附带 Cookie 信息给服务器。则必须具备两个条件：1. 浏览器端：发送 AJAX 请求前需设置通信对象 XHR 的 withCredentials 属性为 true。 2. 服务器端：设置 Access-Control-Allow-Credentials 为 true。两个条件缺一不可，否则即使服务器同意发送 Cookie，浏览器也无法获取。正确姿势如下： Access-Control-Allow-Methods表示跨域请求的方式的允许范围。（例如只授权 GET/POST）Access-Control-Allow-Headers表示跨域请求的头部的允许范围。Access-Control-Expose-Headers表示暴露哪些头部信息，并提供给客户端。（因为基于安全考虑，如果没有设置额外的暴露，跨域的通信对象 XMLHttpRequest 只能获取标准的头部信息）Access-Control-Max-Age表示预检请求 [Preflight Request] 的最大缓存时间。 CORS 实现跨域访问授权方式方式 1：返回新的 CorsFilter方式 2：重写 WebMvcConfigurer方式 3：使用注解（@CrossOrigin）方式 4：手工设置响应头（HttpServletResponse ）注：CorsFilter / WebMvcConfigurer / @CrossOrigin 需要 SpringMVC 4.2 以上的版本才支持，对应 SpringBoot 1.3 版本以上都支持这些 CORS 特性。不过，使用 SpringMVC4.2 以下版本的小伙伴也不用慌，直接使用方式 4 通过手工添加响应头来授权 CORS 跨域访问也是可以的。附：在 SpringBoot 1.2.8 + SpringMVC 4.1.9 亲测成功。 注：方式 1 和方式 2 属于全局 CORS 配置，方式 3 和方式 4 属于局部 CORS 配置。如果使用了局部跨域是会覆盖全局跨域的规则，所以可以通过 @CrossOrigin 注解来进行细粒度更高的跨域资源控制。 返回新的 CorsFilter（全局跨域）在任意配置类，返回一个新的 CorsFilter Bean，并添加映射路径和具体的 CORS 配置信息。 package com.hehe.yyweb.config; @Configuration public class GlobalCorsConfig { @Bean public CorsFilter corsFilter() { //1.添加CORS配置信息 CorsConfiguration config = new CorsConfiguration(); //放行哪些原始域 config.addAllowedOrigin(&quot;*&quot;); //是否发送Cookie信息 config.setAllowCredentials(true); //放行哪些原始域(请求方式) config.addAllowedMethod(&quot;*&quot;); //放行哪些原始域(头部信息) config.addAllowedHeader(&quot;*&quot;); //暴露哪些头部信息（因为跨域访问默认不能获取全部头部信息） config.addExposedHeader(&quot;*&quot;); //2.添加映射路径 UrlBasedCorsConfigurationSource configSource = new UrlBasedCorsConfigurationSource(); configSource.registerCorsConfiguration(&quot;/**&quot;, config); //3.返回新的CorsFilter. return new CorsFilter(configSource); } } 重写 WebMvcConfigurer（全局跨域）在任意配置类，返回一个新的 WebMvcConfigurer Bean，并重写其提供的跨域请求处理的接口，目的是添加映射路径和具体的 CORS 配置信息。 package com.hehe.yyweb.config; @Configuration public class GlobalCorsConfig { @Bean public WebMvcConfigurer corsConfigurer() { return new WebMvcConfigurer() { @Override //重写父类提供的跨域请求处理的接口 public void addCorsMappings(CorsRegistry registry) { //添加映射路径 registry.addMapping(&quot;/**&quot;) //放行哪些原始域 .allowedOrigins(&quot;*&quot;) //是否发送Cookie信息 .allowCredentials(true) //放行哪些原始域(请求方式) .allowedMethods(&quot;GET&quot;,&quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;) //放行哪些原始域(头部信息) .allowedHeaders(&quot;*&quot;) //暴露哪些头部信息（因为跨域访问默认不能获取全部头部信息） .exposedHeaders(&quot;Header1&quot;, &quot;Header2&quot;); } }; } } 使用注解（局部跨域）在方法上（@RequestMapping）使用注解 @CrossOrigin ： @RequestMapping(&quot;/hello&quot;) @ResponseBody @CrossOrigin(&quot;http://localhost:8080&quot;) public String index( ){ return &quot;Hello World&quot;; } 或者在控制器（@Controller）上使用注解 @CrossOrigin ： @Controller @CrossOrigin(origins = &quot;http://xx-domain.com&quot;, maxAge = 3600) public class AccountController { @RequestMapping(&quot;/hello&quot;) @ResponseBody public String index( ){ return &quot;Hello World&quot;; } } 手工设置响应头（局部跨域 ）使用 HttpServletResponse 对象添加响应头（Access-Control-Allow-Origin）来授权原始域，这里 Origin 的值也可以设置为”*” ，表示全部放行。 @RequestMapping(&quot;/hello&quot;) @ResponseBody public String index(HttpServletResponse response){ response.addHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;http://localhost:8080&quot;); return &quot;Hello World&quot;; } 测试跨域访问首先使用 Spring Initializr 快速构建一个 Maven 工程，什么都不用改，在 static 目录下，添加一个页面：index.html 来模拟跨域访问。目标地址: http://localhost:8090/hello &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;Page Index&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h2&gt;前台系统&lt;/h2&gt; &lt;p&gt;&lt;/p&gt; &lt;/body&gt; &lt;script src=&quot;webjars/jquery/3.2.1/jquery.js&quot;&gt;&lt;/script&gt; &lt;script&gt; $.ajax({ url: &apos;http://localhost:8090/hello&apos;, type: &quot;POST&quot;, success: function (data) { $(&quot;#info&quot;).html(&quot;跨域访问成功:&quot;+data); }, error: function (data) { $(&quot;#info&quot;).html(&quot;跨域失败!!&quot;); } }) &lt;/script&gt; &lt;/html&gt; 然后创建另一个工程，在 Root Package 添加 Config 目录并创建配置类来开启全局 CORS。 package com.hehe.yyweb.config; @Configuration public class GlobalCorsConfig { @Bean public WebMvcConfigurer corsConfigurer() { return new WebMvcConfigurer() { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/**&quot;); } }; } } 接着，简单编写一个 Rest 接口 ，并指定应用端口为 8090。 package com.hehe.yyweb; @SpringBootApplication @RestController public class YyWebApplication { @Bean public TomcatServletWebServerFactory tomcat() { TomcatServletWebServerFactory tomcatFactory = new TomcatServletWebServerFactory(); tomcatFactory.setPort(8090); //默认启动8090端口 return tomcatFactory; } @RequestMapping(&quot;/hello&quot;) public String index() { return &quot;Hello World&quot;; } public static void main(String[] args) { SpringApplication.run(YyWebApplication.class, args); } } 最后分别启动两个应用，然后在浏览器访问：http://localhost:8080/index.html ，可以正常接收 JSON 数据，说明跨域访问成功！！ 尝试把全局 CORS 关闭，或者没有单独在方法或类上授权跨域，再次访问：http://localhost:8080/index.html 时会看到跨域请求失败！！ 四、源码和文档 源码地址： SpringBoot-Cross-Orgin 专题阅读：《SpringBoot 布道系列》 官方文档： W3C 规范 - CORS 传统文档： SpringMVC-CORS 使用手册 推荐阅读： 跨域资源共享 CORS 详解 - 阮一峰 转自：http://www.jianshu.com/p/477e7eaa6c2f]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 针对嵌套对象，多层级结构存储]]></title>
    <url>%2Fpost%2FMongoDB-Multilayer-Structural-Storage%2F</url>
    <content type="text"><![CDATA[简要介绍 NOSQLmongoDB 是属于 NOSQL. 什么是 nosql,NoSQL(NoSQL = Not Only SQL)，意即” 不仅仅是 SQL”。NoSQL，指的是非关系型的数据库。NoSQL 有时也称作 Not Only SQL 的缩写，是对不同于传统的关系型数据库的数据库管理系统的统称。NoSQL 用于超大规模数据的存储。（例如谷歌或 Facebook 每天为他们的用户收集万亿比特的数据）。这些类型的数据存储不需要固定的模式，无需多余操作就可以横向扩展。 mongodb 介绍MongoDB 的提供了一个面向文档存储，操作起来比较简单和容易。你可以在 MongoDB 记录中设置任何属性的索引 (如：FirstName=”Sameer”,Address=”8 Gandhi Road”) 来实现更快的排序。 你可以通过本地或者网络创建数据镜像，这使得 MongoDB 有更强的扩展性。 MongoDb 使用 update() 命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。 Mongodb 中的 Map/reduce 主要是用来对数据进行批量处理和聚合操作。 Map 和 Reduce。Map 函数调用 emit(key,value) 遍历集合中所有的记录，将 key 与 value 传给 Reduce 函数进行处理。Map 函数和 Reduce 函数是使用 Javascript 编写的，并可以通过 db.runCommand 或 mapreduce 命令来执行 MapReduce 操作。 GridFS 是 MongoDB 中的一个内置功能，可以用于存放大量小文件。 MongoDB 允许在服务端执行脚本，可以用 Javascript 编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。 MongoDB 支持各种编程语言: RUBY，PYTHON，JAVA，C++，PHP，C# 等多种语言。 MongoDB 安装简单。 spring 集成使用 mongodb我自己使用 mongodb ，是用 spring 中带的 mongodb 包来使用的。只要的 jar 包是，下面是 maven 引用包 &lt;dependency&gt; &lt;groupId&gt;org.mongodb&lt;/groupId&gt; &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt; &lt;version&gt;2.13.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-mongodb&lt;/artifactId&gt; &lt;version&gt;1.6.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mongodb&lt;/groupId&gt; &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt; &lt;version&gt;2.13.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-mongodb&lt;/artifactId&gt; &lt;version&gt;1.6.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; 配置 mongodb 数据源数据连接地址。用一个 properties 保存。 mongo.dburl=172.16.40.18:27017 mongo.dbname=qingxing mongo.connectionsPerHost=100 mongo.threadsAllowedToBlockForConnectionMultiplier=4 mongo.maxWaitTime=1500 mongo.socketTimeout=1500 mongo.connectTimeout=1000 mongo.autoConnectRetry=true mongo.socketKeepAlive=true mongo.slaveOk=true mongo.dburl=172.16.40.18:27017 mongo.dbname=qingxing mongo.connectionsPerHost=100 mongo.threadsAllowedToBlockForConnectionMultiplier=4 mongo.maxWaitTime=1500 mongo.socketTimeout=1500 mongo.connectTimeout=1000 mongo.autoConnectRetry=true mongo.socketKeepAlive=true mongo.slaveOk=true 在 spring 配置文件中配置数据源 &lt;!-- 一些连接属性的设置 --&gt; &lt;mongo:mongo replica-set=&quot;${mongo.dburl}&quot;&gt; &lt;mongo:options connections-per-host=&quot;${mongo.connectionsPerHost}&quot; threads-allowed-to-block-for-connection-multiplier=&quot;${mongo.threadsAllowedToBlockForConnectionMultiplier}&quot; connect-timeout=&quot;${mongo.connectTimeout}&quot; max-wait-time=&quot;${mongo.maxWaitTime}&quot; auto-connect-retry=&quot;${mongo.autoConnectRetry}&quot; socket-keep-alive=&quot;${mongo.socketKeepAlive}&quot; socket-timeout=&quot;${mongo.socketTimeout}&quot; slave-ok=&quot;${mongo.slaveOk}&quot; write-number=&quot;1&quot; write-timeout=&quot;0&quot; write-fsync=&quot;true&quot; /&gt; &lt;/mongo:mongo&gt; &lt;!-- mongo的工厂，通过它来取得mongo实例,dbname为mongodb的数据库名，没有的话会自动创建 --&gt; &lt;mongo:db-factory dbname=&quot;${mongo.dbname}&quot; mongo-ref=&quot;mongo&quot; /&gt; &lt;bean /&gt; &lt;!-- 去除集合里的_class属性 --&gt; &lt;bean &gt; &lt;constructor-arg name=&quot;typeKey&quot;&gt; &lt;null /&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean &gt; &lt;constructor-arg name=&quot;mongoDbFactory&quot; ref=&quot;mongoDbFactory&quot; /&gt; &lt;constructor-arg name=&quot;mappingContext&quot; ref=&quot;mappingContext&quot; /&gt; &lt;property name=&quot;typeMapper&quot; ref=&quot;defaultMongoTypeMapper&quot; /&gt; &lt;/bean&gt; &lt;!-- mongodb的主要操作对象，所有对mongodb的增删改查的操作都是通过它完成 --&gt; &lt;bean&gt; &lt;constructor-arg name=&quot;mongoDbFactory&quot; ref=&quot;mongoDbFactory&quot; /&gt; &lt;constructor-arg name=&quot;mongoConverter&quot; ref=&quot;mappingMongoConverter&quot; /&gt; &lt;/bean&gt; &lt;!-- 映射转换器，扫描back-package目录下的文件，根据注释，把它们作为mongodb的一个collection的映射 --&gt; &lt;mongo:mapping-converter base-package=&quot;com.qx.mongodb.doc&quot; /&gt; &lt;!-- mongodb bean的仓库目录，会自动扫描扩展了MongoRepository接口的接口进行注入 --&gt; &lt;mongo:repositories base-package=&quot;com.qx.mongodb.dao&quot; /&gt; &lt;!-- ***************************** mongoDB over ********************************** --&gt; &lt;!-- 一些连接属性的设置 --&gt; &lt;mongo:mongo replica-set=&quot;${mongo.dburl}&quot;&gt; &lt;mongo:options connections-per-host=&quot;${mongo.connectionsPerHost}&quot; threads-allowed-to-block-for-connection-multiplier=&quot;${mongo.threadsAllowedToBlockForConnectionMultiplier}&quot; connect-timeout=&quot;${mongo.connectTimeout}&quot; max-wait-time=&quot;${mongo.maxWaitTime}&quot; auto-connect-retry=&quot;${mongo.autoConnectRetry}&quot; socket-keep-alive=&quot;${mongo.socketKeepAlive}&quot; socket-timeout=&quot;${mongo.socketTimeout}&quot; slave-ok=&quot;${mongo.slaveOk}&quot; write-number=&quot;1&quot; write-timeout=&quot;0&quot; write-fsync=&quot;true&quot; /&gt; &lt;/mongo:mongo&gt; &lt;!-- mongo的工厂，通过它来取得mongo实例,dbname为mongodb的数据库名，没有的话会自动创建 --&gt; &lt;mongo:db-factory dbname=&quot;${mongo.dbname}&quot; mongo-ref=&quot;mongo&quot; /&gt; &lt;bean /&gt; &lt;!-- 去除集合里的_class属性 --&gt; &lt;bean &gt; &lt;constructor-arg name=&quot;typeKey&quot;&gt; &lt;null /&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean &gt; &lt;constructor-arg name=&quot;mongoDbFactory&quot; ref=&quot;mongoDbFactory&quot; /&gt; &lt;constructor-arg name=&quot;mappingContext&quot; ref=&quot;mappingContext&quot; /&gt; &lt;property name=&quot;typeMapper&quot; ref=&quot;defaultMongoTypeMapper&quot; /&gt; &lt;/bean&gt; &lt;!-- mongodb的主要操作对象，所有对mongodb的增删改查的操作都是通过它完成 --&gt; &lt;bean&gt; &lt;constructor-arg name=&quot;mongoDbFactory&quot; ref=&quot;mongoDbFactory&quot; /&gt; &lt;constructor-arg name=&quot;mongoConverter&quot; ref=&quot;mappingMongoConverter&quot; /&gt; &lt;/bean&gt; &lt;!-- 映射转换器，扫描back-package目录下的文件，根据注释，把它们作为mongodb的一个collection的映射 --&gt; &lt;mongo:mapping-converter base-package=&quot;com.qx.mongodb.doc&quot; /&gt; &lt;!-- mongodb bean的仓库目录，会自动扫描扩展了MongoRepository接口的接口进行注入 --&gt; &lt;mongo:repositories base-package=&quot;com.qx.mongodb.dao&quot; /&gt; &lt;!-- ***************************** mongoDB over ********************************** --&gt; 对象的操作。建立映射关系对应。/** * 教练版的语音播报 * * @author luoyang * */ @Document(collection = &quot;mg_voice&quot;) //存入的表名称 public class MgVoice { @Id //标志为主键 private Long cid; /** * M 男声 F 女声 */ private String voiceType; /** * 速度 */ private Integer voiceSpeed; private List&lt;MgVoiceLibrary&gt; voiceLibrarys; private List&lt;MgVoicePlan&gt; voicePlans; public Long getCid(){ return cid; } .... /** * 教练版的语音播报 * * @author luoyang * */ @Document(collection = &quot;mg_voice&quot;) //存入的表名称 public class MgVoice { @Id //标志为主键 private Long cid; /** * M 男声 F 女声 */ private String voiceType; /** * 速度 */ private Integer voiceSpeed; private List&lt;MgVoiceLibrary&gt; voiceLibrarys; private List&lt;MgVoicePlan&gt; voicePlans; public Long getCid(){ return cid; } 内嵌对象 MgVoiceLibrary/** * 教练版的语音库 * * @author luoyang * */ public class MgVoiceLibrary { private String lid; /** * 2 科目二 3 科目三 4 起步灯光 */ private Integer type; private String title; private String content; /** * 0 不是 1 是 */ private Integer isTemp; private String tempCode; private String tempTitle; private String tempContent; private Date updateDate; public String getLid(){ return lid; } ..... /** * 教练版的语音库 * * @author luoyang * */ public class MgVoiceLibrary { private String lid; /** * 2 科目二 3 科目三 4 起步灯光 */ private Integer type; private String title; private String content; /** * 0 不是 1 是 */ private Integer isTemp; private String tempCode; private String tempTitle; private String tempContent; private Date updateDate; public String getLid(){ return lid; } ..... 增删改查操作在做一下的操作之前先介绍 spring 中操作 mongodb 的类。在之前的配置中可以看到，我们已经引入了一个类：mongoTemplateimport org.springframework.data.mongodb.core.MongoTemplate; 其中所引用的包 import org.springframework.data.mongodb.core.query.Criteria; import org.springframework.data.mongodb.core.query.Query; import org.springframework.data.mongodb.core.query.Update; import org.springframework.stereotype.Service; import com.alibaba.fastjson.JSON; import com.mongodb.BasicDBObject; import org.springframework.data.mongodb.core.query.Criteria; import org.springframework.data.mongodb.core.query.Query; import org.springframework.data.mongodb.core.query.Update; import org.springframework.stereotype.Service; import com.alibaba.fastjson.JSON; import com.mongodb.BasicDBObject; 所以在我们的 service 层 ，利用注解直接使用这个类 @Autowired protected MongoTemplate mongoTemplate; @Autowired protected MongoTemplate mongoTemplate; 新增//新增很简单，将新增的对象设置好值，直接保存 MgVoice mgVoice = new MgVoice(); mgVoice.set ....// mongoTemplate.save(mgVoice); //新增很简单，将新增的对象设置好值，直接保存 MgVoice mgVoice = new MgVoice(); mgVoice.set ....// mongoTemplate.save(mgVoice); 修改。（修改对象的直接属性）{ &quot;cid&quot;: 1100658, //教练ID &quot;voiceType&quot;: &quot;F&quot;,//语音类型 F女声 M 男声 &quot;voiceSpeed&quot;: 30, //语音速度 &quot;voiceLibrarys&quot;: [ { &quot;lid&quot;: &quot;p2_b9dc7616-b476-40ee-8fd7-982711cece98&quot;,//语音ID &quot;type&quot;: 2,//语音类型 2科目二 3科目三 &quot;title&quot;: &quot;上坡起步&quot;, //标题 &quot;content&quot;: &quot;上坡起步和定点停车&quot;,//内容 &quot;isTemp&quot;: 1, //是否是模板 0 不是 1 是 &quot;tempCode&quot;: &quot;k2_spqb&quot;,//模板代码 ，也是模板图片标题 &quot;tempTitle&quot;: &quot;上坡起步&quot;,//模板标题 &quot;tempContent&quot;: &quot;上坡起步和定点停车&quot;,//模板内容，供恢复默认使用 &quot;updateDate&quot;: &quot;2016-04-28 00:00:00&quot; }, { &quot;lid&quot;: &quot;p3_ead65a9a-c659-4f55-a7d4-067d8935ee19&quot;, &quot;type&quot;: 3, &quot;title&quot;: &quot;靠边停车&quot;, &quot;content&quot;: &quot;请靠边停车&quot;, &quot;isTemp&quot;: 1, &quot;tempCode&quot;: &quot;k3_kbtc&quot;, &quot;tempTitle&quot;: &quot;靠边停车&quot;, &quot;tempContent&quot;: &quot;请靠边停车&quot;, &quot;updateDate&quot;: &quot;2016-04-28 00:00:00&quot; }] } { &quot;cid&quot;: 1100658, //教练ID &quot;voiceType&quot;: &quot;F&quot;,//语音类型 F女声 M 男声 &quot;voiceSpeed&quot;: 30, //语音速度 &quot;voiceLibrarys&quot;: [ { &quot;lid&quot;: &quot;p2_b9dc7616-b476-40ee-8fd7-982711cece98&quot;,//语音ID &quot;type&quot;: 2,//语音类型 2科目二 3科目三 &quot;title&quot;: &quot;上坡起步&quot;, //标题 &quot;content&quot;: &quot;上坡起步和定点停车&quot;,//内容 &quot;isTemp&quot;: 1, //是否是模板 0 不是 1 是 &quot;tempCode&quot;: &quot;k2_spqb&quot;,//模板代码 ，也是模板图片标题 &quot;tempTitle&quot;: &quot;上坡起步&quot;,//模板标题 &quot;tempContent&quot;: &quot;上坡起步和定点停车&quot;,//模板内容，供恢复默认使用 &quot;updateDate&quot;: &quot;2016-04-28 00:00:00&quot; }, { &quot;lid&quot;: &quot;p3_ead65a9a-c659-4f55-a7d4-067d8935ee19&quot;, &quot;type&quot;: 3, &quot;title&quot;: &quot;靠边停车&quot;, &quot;content&quot;: &quot;请靠边停车&quot;, &quot;isTemp&quot;: 1, &quot;tempCode&quot;: &quot;k3_kbtc&quot;, &quot;tempTitle&quot;: &quot;靠边停车&quot;, &quot;tempContent&quot;: &quot;请靠边停车&quot;, &quot;updateDate&quot;: &quot;2016-04-28 00:00:00&quot; }] } 我们要修改对象中的 voiceType 和 voiceSpeed 属性代码如下我们要修改对象中的 voiceType 和 voiceSpeed 属性代码如下 @Override public void updateCfg(Long cid,Integer speed,String type){ Criteria criteria = Criteria.where(&quot;cid&quot;).is(cid); Query query = new Query(criteria); Update update = Update.update(&quot;voiceType&quot;, type).set(&quot;voiceSpeed&quot;, speed); mongoTemplate.updateFirst(query, update, MgVoice.class); } @Override public void updateCfg(Long cid, Integer speed,String type){ Criteria criteria = Criteria.where(&quot;cid&quot;).is(cid); Query query = new Query(criteria); Update update = Update.update(&quot;voiceType&quot;, type).set(&quot;voiceSpeed&quot;, speed); mongoTemplate.updateFirst(query, update, MgVoice.class); } 修改。（对象中的 嵌套对象）我们要修改 voiceLibrarys 数组 中 lid = “p2_b9dc7616-b476-40ee-8fd7-982711cece98”, 的对象中的 title 和 content 属性。使用 set //是修改 Query query = new Query(Criteria.where(&quot;cid&quot;).is(cid).and(&quot;voiceLibrarys.lid&quot;).is(lid)); Update update = Update.update(&quot;voiceLibrarys.$.title&quot;, title).set(&quot;voiceLibrarys.$.content&quot;, content); mongoTemplate.updateFirst(query, update, MgVoice.class); //是修改 Query query = new Query(Criteria.where(&quot;cid&quot;).is(cid).and(&quot;voiceLibrarys.lid&quot;).is(lid)); Update update = Update.update(&quot;voiceLibrarys.$.title&quot;, title).set(&quot;voiceLibrarys.$.content&quot;, content); mongoTemplate.updateFirst(query, update, MgVoice.class); 如果是要再 voiceLibrarys 这个数组中新增一个对象 使用 addToset //语音的ID 为空是新增 lid = getCreateId(type); MgVoiceLibrary voice = new MgVoiceLibrary(); voice.setLid(lid); voice.setType(type); voice.setTitle(title); voice.setContent(content); voice.setIsTemp(0); voice.setUpdateDate(RDate.getCurrentDate()); Query query = Query.query(Criteria.where(&quot;cid&quot;).is(cid)); Update update = new Update(); update.addToSet(&quot;voiceLibrarys&quot;, voice); mongoTemplate.upsert(query, update, MgVoice.class); //语音的ID 为空是新增 lid = getCreateId(type); MgVoiceLibrary voice = new MgVoiceLibrary(); voice.setLid(lid); voice.setType(type); voice.setTitle(title); voice.setContent(content); voice.setIsTemp(0); voice.setUpdateDate(RDate.getCurrentDate()); Query query = Query.query(Criteria.where(&quot;cid&quot;).is(cid)); Update update = new Update(); update.addToSet(&quot;voiceLibrarys&quot;, voice); mongoTemplate.upsert(query, update, MgVoice.class); 如果要删除数组 voiceLibrarys 中的一个对象，对象 lid=”p2_b9dc7616-b476-40ee-8fd7-982711cece98” 。 使用 pull 属性 //删除 语音 cid 记录的ID plid 数组中的一个标记 Query query = Query.query(Criteria.where(&quot;cid&quot;).is(cid)); BasicDBObject s = new BasicDBObject(); s.put(&quot;lid&quot;, plid); Update update = new Update(); update.pull(&quot;voiceLibrarys&quot;, s); mongoTemplate.updateFirst(query, update, MgVoice.class); //删除 语音 cid 记录的ID plid 数组中的一个标记 Query query = Query.query(Criteria.where(&quot;cid&quot;).is(cid)); BasicDBObject s = new BasicDBObject(); s.put(&quot;lid&quot;, plid); Update update = new Update(); update.pull(&quot;voiceLibrarys&quot;, s); mongoTemplate.updateFirst(query, update, MgVoice.class); 除了以上的操作 还有一些属性，例如 unset.如果 update.upset 一个数组。 就会清空对象，但是数组大小不会变。 modifies使用 update.modifies(key) 。 就会把这个对象里面除了 ID 以外的值全部删除。 如果对象是这样的。voiceLibrarys 是一个对象，不是数组。同样要修改 title 和 content 对象。 { &quot;cid&quot;: 1100658, //教练ID &quot;voiceType&quot;: &quot;F&quot;,//语音类型 F女声 M 男声 &quot;voiceSpeed&quot;: 30, //语音速度 &quot;voiceLibrarys&quot;: { &quot;lid&quot;: &quot;p2_b9dc7616-b476-40ee-8fd7-982711cece98&quot;,//语音ID &quot;type&quot;: 2,//语音类型 2科目二 3科目三 &quot;title&quot;: &quot;上坡起步&quot;, //标题 &quot;content&quot;: &quot;上坡起步和定点停车&quot;,//内容 &quot;isTemp&quot;: 1, //是否是模板 0 不是 1 是 &quot;tempCode&quot;: &quot;k2_spqb&quot;,//模板代码 ，也是模板图片标题 &quot;tempTitle&quot;: &quot;上坡起步&quot;,//模板标题 &quot;tempContent&quot;: &quot;上坡起步和定点停车&quot;,//模板内容，供恢复默认使用 &quot;updateDate&quot;: &quot;2016-04-28 00:00:00&quot; } } { &quot;cid&quot;: 1100658, //教练ID &quot;voiceType&quot;: &quot;F&quot;,//语音类型 F女声 M 男声 &quot;voiceSpeed&quot;: 30, //语音速度 &quot;voiceLibrarys&quot;: { &quot;lid&quot;: &quot;p2_b9dc7616-b476-40ee-8fd7-982711cece98&quot;,//语音ID &quot;type&quot;: 2,//语音类型 2科目二 3科目三 &quot;title&quot;: &quot;上坡起步&quot;, //标题 &quot;content&quot;: &quot;上坡起步和定点停车&quot;,//内容 &quot;isTemp&quot;: 1, //是否是模板 0 不是 1 是 &quot;tempCode&quot;: &quot;k2_spqb&quot;,//模板代码 ，也是模板图片标题 &quot;tempTitle&quot;: &quot;上坡起步&quot;,//模板标题 &quot;tempContent&quot;: &quot;上坡起步和定点停车&quot;,//模板内容，供恢复默认使用 &quot;updateDate&quot;: &quot;2016-04-28 00:00:00&quot; } } 代码 //是修改 Query query = new Query(Criteria.where(&quot;cid&quot;).is(cid)); Update update = Update.update(&quot;voiceLibrarys.title&quot;, title).set(&quot;voiceLibrarys.content&quot;, content); mongoTemplate.updateFirst(query, update, MgVoice.class); //是修改 Query query = new Query(Criteria.where(&quot;cid&quot;).is(cid)); Update update = Update.update(&quot;voiceLibrarys.title&quot;, title).set(&quot;voiceLibrarys.content&quot;, content); mongoTemplate.updateFirst(query, update, MgVoice.class); 如果要删除整条记录。 使用 remove @Override public boolean removeVoice(Long cid){ //删除 语音 Query query = Query.query(Criteria.where(&quot;cid&quot;).is(cid)); mongoTemplate.remove(query, MgVoice.class); return true; } @Override public boolean removeVoice(Long cid){ //删除 语音 Query query = Query.query(Criteria.where(&quot;cid&quot;).is(cid)); mongoTemplate.remove(query, MgVoice.class); return true; } 这里只是简单的介绍一些基本的操作方法。本人只是简单的看了一下。spring mongodb 源码包中的代码。源码包中 也并没有写的很详细。只是给了其他的文档地址。例如 /** * Update using the {@literal $pull} update modifier * * @see http://docs.mongodb.org/manual/reference/operator/update/pull/ * @param key * @param value * @return */ public Update pull(String key, Object value) { addMultiFieldOperation(&quot;$pull&quot;, key, value); return this; } /** * Update using the {@literal $pull} update modifier * * @see http://docs.mongodb.org/manual/reference/operator/update/pull/ * @param key * @param value * @return */ public Update pull(String key, Object value) { addMultiFieldOperation(&quot;$pull&quot;, key, value); return this; } 根据http://docs.mongodb.org/manual/reference/operator/update/pull/再去查看一些基本的方法的使用。 转自:https://blog.csdn.net/xwnxwn/article/details/77884009]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS组件系列——Form表单验证神器： BootstrapValidator]]></title>
    <url>%2Fpost%2Fform-bootstrap-validator%2F</url>
    <content type="text"><![CDATA[前言：做Web开发的我们，表单验证是再常见不过的需求了。友好的错误提示能增加用户体验。博主搜索bootstrap表单验证，搜到的结果大部分都是文中的主题：bootstrapvalidator。今天就来看看它如何使用吧。 一、 源码及API地址介绍它之前，还是给出它的源码以及API的地址吧。 bootstrapvalidator源码：https://github.com/nghuuphuoc/bootstrapvalidator boostrapvalidator api：http://bv.doc.javake.cn/api/ 二、代码以及效果展示1、初级用法来看bootstrapvalidator的描述：A jQuery form validator for Bootstrap 3。从描述中我们就可以知道它至少需要jQuery、bootstrap的支持。我们首先引入需要的js组件 &lt;script src=&quot;~/Scripts/jquery-1.10.2.js&quot;&gt;&lt;/script&gt; &lt;scriptb src=&quot;~/Content/bootstrap/js/bootstrap.min.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;~/Content/bootstrap/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script src=&quot;~/Content/bootstrapValidator/js/bootstrapValidator.min.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;~/Content/bootstrapValidator/css/bootstrapValidator.min.css&quot; rel=&quot;stylesheet&quot; /&gt; 我们知道，既然是表单验证，那么我们在cshtml页面就必须要有一个Form，并且我们知道Form里面取元素都是通过name属性去取值的，所以，表单里面的元素都要有一个name的属性值。 &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Username&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; name=&quot;username&quot; /&gt;&lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Email address&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; name=&quot;email&quot; /&gt;&lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;button type=&quot;submit&quot; name=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Submit&lt;/button&gt; &lt;/div&gt; 有了表单元素之后，就是我们的js初始化了。 $(function () { $(&apos;form&apos;).bootstrapValidator({ message: &apos;This value is not valid&apos;, feedbackIcons: { valid: &apos;glyphicon glyphicon-ok&apos;, invalid: &apos;glyphicon glyphicon-remove&apos;, validating: &apos;glyphicon glyphicon-refresh&apos; }, fields: { username: { message: &apos;用户名验证失败&apos;, validators: { notEmpty: { message: &apos;用户名不能为空&apos; } } }, email: { validators: { notEmpty: { message: &apos;邮箱地址不能为空&apos; } } } } }); }); 内容应该很容易看懂。来看效果：验证通不过，提交按钮灰掉不能点击验证通过，提交按钮恢复看看效果先感受下，最大优点：使用简单，界面友好。下面我们来看看重叠验证。 2、中级用法上面我们知道了非空验证的写法，除此之外肯定还有其他验证方式啊。别急，我们慢慢来看。上面的代码cshtml部分不动，js部分我们稍作修改： $(function () { $(&apos;form&apos;).bootstrapValidator({ message: &apos;This value is not valid&apos;, feedbackIcons: { valid: &apos;glyphicon glyphicon-ok&apos;, invalid: &apos;glyphicon glyphicon-remove&apos;, validating: &apos;glyphicon glyphicon-refresh&apos; }, fields: { username: { message: &apos;用户名验证失败&apos;, validators: { notEmpty: { message: &apos;用户名不能为空&apos; }, stringLength: { min: 6, max: 18, message: &apos;用户名长度必须在6到18位之间&apos; }, regexp: { regexp: /^[a-zA-Z0-9_]+$/, message: &apos;用户名只能包含大写、小写、数字和下划线&apos; } } }, email: { validators: { notEmpty: { message: &apos;邮箱不能为空&apos; }, emailAddress: { message: &apos;邮箱地址格式有误&apos; } } } } }); }); 加上了重叠验证我们来看效果：由上面的代码可以看出在validators属性对应一个Json对象，里面可以包含多个验证的类型： notEmpty：非空验证； stringLength：字符串长度验证； regexp：正则表达式验证； emailAddress：邮箱地址验证（都不用我们去写邮箱的正则了~~） 除此之外，在文档里面我们看到它总共有46个验证类型，我们抽几个常见的出来看看： base64：64位编码验证； between：验证输入值必须在某一个范围值以内，比如大于10小于100； creditCard：身份证验证； date：日期验证； ip：IP地址验证； numeric：数值验证； phone：电话号码验证； uri：url验证； 更多验证类型详见：http://bv.doc.javake.cn/validators/。当然涉及中文的验证可能会有些小问题，园友们如果有需要可以自行下去用代码测试下。 还有一个比较常用的就是submitHandler属性，它对应着提交按钮的事件方法。使用如下： $(function () { $(&apos;form&apos;).bootstrapValidator({ message: &apos;This value is not valid&apos;, feedbackIcons: { valid: &apos;glyphicon glyphicon-ok&apos;, invalid: &apos;glyphicon glyphicon-remove&apos;, validating: &apos;glyphicon glyphicon-refresh&apos; }, fields: { username: { message: &apos;用户名验证失败&apos;, validators: { notEmpty: { message: &apos;用户名不能为空&apos; }, stringLength: { min: 6, max: 18, message: &apos;用户名长度必须在6到18位之间&apos; }, regexp: { regexp: /^[a-zA-Z0-9_]+$/, message: &apos;用户名只能包含大写、小写、数字和下划线&apos; } } }, email: { validators: { notEmpty: { message: &apos;邮箱不能为空&apos; }, emailAddress: { message: &apos;邮箱地址格式有误&apos; } } } }, submitHandler: function (validator, form, submitButton) { alert(&quot;submit&quot;); } }); }); 在它的Demo里面介绍了很多验证的实例。我们简单看看它的效果，至于实现代码，其实很简单，有兴趣的可以直接看api。颜色验证 转自：https://www.cnblogs.com/landeanfen/p/5035608.html]]></content>
      <categories>
        <category>jQuery</category>
      </categories>
      <tags>
        <tag>jQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 快速整合Mybatis（去XML化+注解进阶）]]></title>
    <url>%2Fpost%2FSpringBoot%26Mybatis%2F</url>
    <content type="text"><![CDATA[一. 基础注解MyBatis 主要提供了以下 CRUD 注解： @Select @Insert @Update @Delete 增删改查占据了绝大部分的业务操作，掌握这些基础注解的使用还是很有必要的，例如下面这段代码无需 XML 即可完成数据查询： @Mapper public interface UserMapper { @Select(&quot;select * from t_user&quot;) List&lt;User&gt; list(); } 使用过 Hibernate 的同学可能会好奇，这里为什么没有配置映射关系也能完成属性注入？在传统项目中使用过 Mybatis 的童鞋可能很快就反应过来，是因为在配置文件中开启了全局驼峰映射，SpringBoot 中同样能够做到，并且更为简单快捷。 虽然开启了全局驼峰映射，但你可能还会质疑，如果不符合下划线转驼峰规则的字段，拿查询回来的实体对象属性将获取为 null，比如上述 User 对象属性 mobileNum 和对应的数据库字段 phoneNum，则查询结果为： [ { &quot;userId&quot;: &quot;1&quot;, &quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;admin&quot;, &quot;mobileNum&quot;: null }, { &quot;userId&quot;: &quot;2&quot;, &quot;username&quot;: &quot;roots&quot;, &quot;password&quot;: &quot;roots&quot;, &quot;mobileNum&quot;: null } ] 为了解决对象属性和字段驼峰不一致的问题，我们可以使用映射注解 @Results 来指定映射关系。 二. 映射注解Mybatis 主要提供这些映射注解： @Results 用于填写结果集的多个字段的映射关系. @Result 用于填写结果集的单个字段的映射关系. @ResultMap 根据 ID 关联 XML 里面 . 例如上面的 list 方法，我们可以在查询 SQL 的基础上，指定返回的结果集的映射关系，其中 property 表示实体对象的属性名，column 表示对应的数据库字段名。 @Results({ @Result(property = &quot;userId&quot;, column = &quot;USER_ID&quot;), @Result(property = &quot;username&quot;, column = &quot;USERNAME&quot;), @Result(property = &quot;password&quot;, column = &quot;PASSWORD&quot;), @Result(property = &quot;mobileNum&quot;, column = &quot;PHONE_NUM&quot;) }) @Select(&quot;select * from t_user&quot;) List&lt;User&gt; list(); 查询结果如下，： [ { &quot;userId&quot;: &quot;1&quot;, &quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;admin&quot;, &quot;mobileNum&quot;: &quot;15011791234&quot; }, { &quot;userId&quot;: &quot;2&quot;, &quot;username&quot;: &quot;roots&quot;, &quot;password&quot;: &quot;roots&quot;, &quot;mobileNum&quot;: &quot;18812342017&quot; } ] 为了方便演示和免除手工编写映射关系的烦恼，这里提供了一个快速生成映射结果集的方法，具体内容如下： /** * 1.用于获取结果集的映射关系 */ public static String getResultsStr(Class origin) { StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(&quot;@Results({\n&quot;); for (Field field : origin.getDeclaredFields()) { String property = field.getName(); //映射关系：对象属性(驼峰)-&gt;数据库字段(下划线) String column = new PropertyNamingStrategy.SnakeCaseStrategy().translate(field.getName()).toUpperCase(); stringBuilder.append(String.format(&quot;@Result(property = \&quot;%s\&quot;, column = \&quot;%s\&quot;),\n&quot;, property, column)); } stringBuilder.append(&quot;})&quot;); return stringBuilder.toString(); } 在当前 Main 方法执行效果如下：然后我们将控制台这段打印信息复制到接口方法上即可。 三. 高级注解MyBatis-3 主要提供了以下 CRUD 的高级注解： @SelectProvider @InsertProvider @UpdateProvider @DeleteProvider 见名知意，这些高级注解主要用于动态 SQL，这里以 @SelectProvider 为例，主要包含两个注解属性，其中 type 表示工具类，method 表示工具类的某个方法，用于返回具体的 SQL。 @Mapper public interface UserMapper { @SelectProvider(type = UserSqlProvider.class, method = &quot;list222&quot;) List&lt;User&gt; list2(); } 工具类代码如下： public class UserSqlProvider { public String list222() { return &quot;select * from t_user ; } 四. 详细教程对上述注解有所了解之后，我们以具体项目案例来进一步巩固这些注解的实际使用。 具体步骤引入依赖为了方便演示，首选搭建 Web 环境，另外数据库选择 Mysql 5.5+。 &lt;dependencies&gt; &lt;dependency&gt; &lt;!--添加Web依赖 --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!--添加Mybatis依赖 --&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--添加MySQL驱动依赖 --&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--添加Test依赖 --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加配置这里主要是添加数据源，配置驼峰映射和开启 SQL 日志的控制台打印。在项目的资源目录中，添加 application.yml 配置如下： spring: datasource: #连接MySQL url: jdbc:mysql://localhost:3306/socks?useSSL=false username: root password: root driver-class-name: com.mysql.jdbc.Driver mybatis: configuration: #配置项：开启下划线到驼峰的自动转换. 作用：将数据库字段根据驼峰规则自动注入到对象属性。 map-underscore-to-camel-case: true logging: level: #打印SQL信息 com.hehe.mapper: debug 编写数据层代码这里以我们熟悉的用户信息为例，编写 UserMapper 接口和本案例使用的 UserSqlProvider。 UserMapper添加 UserMapper 接口用于数据查询： package com.hehe.mapper; @Mapper public interface UserMapper { /** * 方式1：使用注解编写SQL。 */ @Select(&quot;select * from t_user&quot;) List&lt;User&gt; list(); /** * 方式2：使用注解指定某个工具类的方法来动态编写SQL. */ @SelectProvider(type = UserSqlProvider.class, method = &quot;listByUsername&quot;) List&lt;User&gt; listByUsername(String username); /** * 延伸：上述两种方式都可以附加@Results注解来指定结果集的映射关系. * * PS：如果符合下划线转驼峰的匹配项可以直接省略不写。 */ @Results({ @Result(property = &quot;userId&quot;, column = &quot;USER_ID&quot;), @Result(property = &quot;username&quot;, column = &quot;USERNAME&quot;), @Result(property = &quot;password&quot;, column = &quot;PASSWORD&quot;), @Result(property = &quot;mobileNum&quot;, column = &quot;PHONE_NUM&quot;) }) @Select(&quot;select * from t_user&quot;) List&lt;User&gt; listSample(); /** * 延伸：无论什么方式,如果涉及多个参数,则必须加上@Param注解,否则无法使用EL表达式获取参数。 */ @Select(&quot;select * from t_user where username like #{username} and password like #{password}&quot;) User get(@Param(&quot;username&quot;) String username, @Param(&quot;password&quot;) String password); @SelectProvider(type = UserSqlProvider.class, method = &quot;getBadUser&quot;) User getBadUser(@Param(&quot;username&quot;) String username, @Param(&quot;password&quot;) String password); } UserSqlProvider添加 UserSqlProvider，用于生成 SQL 的工具类 。 package com.hehe.mapper; /** * 主要用途：根据复杂的业务需求来动态生成SQL. * &lt;p&gt; * 目标：使用Java工具类来替代传统的XML文件.(例如：UserSqlProvider.java &lt;-- UserMapper.xml) */ public class UserSqlProvider { /** * 方式1：在工具类的方法里,可以自己手工编写SQL。 */ public String listByUsername(String username) { return &quot;select * from t_user where username =#{username}&quot;; } /** * 方式2：也可以根据官方提供的API来编写动态SQL。 */ public String getBadUser(@Param(&quot;username&quot;) String username, @Param(&quot;password&quot;) String password) { return new SQL() {{ SELECT("*"); FROM("t_user"); if (username != null && password != null) { WHERE("username like #{username} and password like #{password}"); } else { WHERE("1=2"); } }}.toString(); } } 实体类 User添加实体类 User public class User { private String userId; private String username; private String password; private String mobileNum; //Getters &amp; Setters } 添加数据库记录打开 Navicat 查询窗口，然后只需下面这段脚本。 USE `SOCKS`; DROP TABLE IF EXISTS `t_user`; CREATE TABLE `t_user` ( `USER_ID` varchar(50) , `USERNAME` varchar(50) , `PASSWORD` varchar(50) , `PHONE_NUM` varchar(15) ) ; INSERT INTO `t_user` VALUES (&apos;1&apos;, &apos;admin&apos;, &apos;admin&apos;,&apos;15011791234&apos;); INSERT INTO `t_user` VALUES (&apos;2&apos;, &apos;roots&apos;, &apos;roots&apos;,&apos;18812342017&apos;); 编写控制层代码package com.hehe.controller; @RestController @RequestMapping(&quot;/user/*&quot;) public class UserController { @SuppressWarnings(&quot;all&quot;) @Autowired UserMapper userMapper; @GetMapping(&quot;list&quot;) public List&lt;User&gt; list() { return userMapper.list(); } @GetMapping(&quot;list/{username}&quot;) public List&lt;User&gt; listByUsername(@PathVariable(&quot;username&quot;) String username) { return userMapper.listByUsername(username); } @GetMapping(&quot;get/{username}/{password}&quot;) public User get(@PathVariable(&quot;username&quot;) String username, @PathVariable(&quot;password&quot;) String password) { return userMapper.get(username, password); } @GetMapping(&quot;get/bad/{username}/{password}&quot;) public User getBadUser(@PathVariable(&quot;username&quot;) String username, @PathVariable(&quot;password&quot;) String password) { return userMapper.getBadUser(username, password); } } 启动和测试启动工程后，访问 http://localhost:8080/user/list 可以查看用户列表如下： 访问 http://localhost:8080/user/list/admin 可以查询用户名为 admin 的信息： 五. 源码和文档专题地址：SpringBoot 布道系列 源码地址：SpringBoot-MyBatis-Annotation 官方文档：Mybatis3 - 中文手册]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何编写兼容各主流邮箱的HTML邮件]]></title>
    <url>%2Fpost%2FHow-to-Write-HTML-Mail%2F</url>
    <content type="text"><![CDATA[最近一个需求中遇到了发送邮件的功能，发现很多 css 在邮件里是有限制的，通过对以前的各位达人总结的学习，解决了这个问题，现转载如下。 几乎每个会员制网站都需要通过后台发送邮件来与会员进行沟通，如注册确认、营销推广。这些由站方发给会员的信件，往往纯文本格式已不能满足界面和交互的要 求，这时候我们就需要发送 HTML 页面。由于 HTML 邮件不是独立的 HOST 在本站的页面，是寄人篱下的。所以编写 HTML 邮件与编写 HTML 页面有很大 的不同。因为，各面向网民的主流邮箱都或多或少的会对它们接收到的 HTML 邮件在后台进行过滤。毫无疑问，JS 代码是被严格过滤掉的，包括所有的事件监听 属性，如 onclick、onmouseover，这是基于邮件安全性的考虑。不仅如此，CSS 代码也会被部分过滤。本人要讲的就是如何编写不被各大主流 邮箱过滤的，能正常显示的 HTML 邮件。 首先，我们先来看看邮箱是如何展现 HTML 邮件的。我本人没有做过邮件系统，况且各大邮箱后台的过滤算法也不是那么容易可以让外人知道的。所以，我们只能 通过前端展现，来推测哪些是被邮箱接受的写法，而哪些又是会被过滤掉的。通过对 gmail、hotmail、163、sohu、sina 几个邮箱的分析， 我把邮箱分为两类： 第一类，包括 gmail、hotmail、sohu，这类邮箱，邮件内容是被布局在整个邮箱页面中的某个 div 中。 第二类，包括 163、sina，这类邮箱，邮件内容被布局在独立的 iframe 中。 熟悉 HTML 的朋友都知道，iframe 内容是作为独立的 document，与父页面的元素和 CSS 是互不相干的，几乎可以作为一个独立的页面来对 待。而如果如果邮件内容是在 div 中，那么邮件内容是作为整个邮箱页面的一个组成部分。显然，以 iframe 作为展现方式的邮箱，对邮件内容就会宽容许 多，因为它给了你一个足够独立的表现空间。而 div 就不是那么客气了。试想一下，如果你在你的邮件里写上这么一句 CSS，是不是整个邮箱的展现页面上字体 都变成 20px 而因此乱了套： &lt;style type=”text/css”&gt; body {font-size:20px} &lt;/style&gt; 我们需要写兼容各邮箱的统一邮件模板，那么必然就要避开以上这种外联 CSS 写法，另外类似于 float、position 等成非正常内容流的 style 也会被过滤，假如你写了，很可能会影响到外部邮箱的表现。 下面我列出一些编写原则： 1、全局规则之一，不要写 &lt;style&gt; 标签、不要写 class，所有 CSS 都用 style 属性，什么元素需要什么样式就用 style 写内联的 CSS。 2、全局规则之二，少用图片，邮箱不会过滤你的 img 标签，但是系统往往会默认不载入陌生来信的图片，如果用了很多图片的邮件，在片没有载入的情况下，丑陋无比甚至看不清内容，没耐心的用户直接就删除了。图片上务必加上 alt。 3、不要在 style 里面写 float、position 这些 style，因为会被过滤。那么如何实现左右布局或者更复杂的布局呢？用 table。 4、style 内容里面 background 可以设置 color，但是 img 会被过滤，就是说不能通过 CSS 来设置背景图片了。但是有一个很有意思的元素 属性，也叫 background，里面可以定义一个图片路径，这是个不错的替代方案，虽然这样功能有限，比如无法定位背景图片了，有总比没有好。例如要给 一个单元格加一个背景，必须这样写： &lt;td background=”http://image1.koubei.com/images/common/logo_koubei.gif”&gt;&lt;/td&gt; 5、div 模式的邮箱不支持 flash，iframe 模式的有待验证。 最后提一句，sohu 的邮箱很怪异，会在每个文本段后面加一个空格，导致原本正常的排版一行放不下而换行，从而使某些布局错乱。所以，如果你要兼容 sohu 邮箱的话，遇到一些紧凑的布局就要格外小心了，尽量减少文本段的数量，留足宽度。 HTML 细节就目前来说，如果要做一个 email 页面，为了保证最大的兼容性，有以下几点需要注意： 对于纯文本邮件： 邮件标题不要超过 18 个字；每行不要超过 34 个字。对于 HTML 邮件： 邮件标题不要超过 18 个字；HTML 代码和图片尽量不要超过 50kb；页面宽度推荐 500px，最大不要超过 600px；避免使用边缘的、非主流的 HTML 技术；不使用 css 来布局，应该使用表格来布局；不使用外联的 css 样式，而使用 font 标签来定义样式，定义链接颜色时也是如此，写法如下： &lt;font&gt; ... &lt;/font&gt; 不使用 Flash、Java、Javascript、frames、i-frames、ActiveX 以及 DHTML ；body 和 meta 之类的标签是可以无视的，因为在很多邮箱系统里它会被过滤；如果整个邮件有用到背景色或背景图，建议用以下方式处理： &lt;table border=&quot;0&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt; &lt;tr&gt; &lt;td width=&quot;100%&quot; height=&quot;100%&quot; bgcolor=&quot;.....&quot;&gt; &lt;!--- 邮件内容 --&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 有背景图片的时候，我们要采用这种写法： &lt;table background=&quot;background.gif&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt; 图片屏蔽 由于图片可以用来侦测邮件的打开率和 email 地址的有效性。不少邮件客户端都会默认把邮件中的图片屏蔽，用户需要再点一下才能显示图片。 来源：EmailLabs, 2004 。国内用户常用的 Foxmail 似乎没有屏蔽邮件内图片的功能，我也找不到相关设置的地方。 一旦图片被屏蔽，整个邮件就会变得面目全非，这里有以下一些建议： 重要内容尽量避免使用图片，比如标题、链接等；制作一份和邮件内容一样的 web 页面，然后在邮件顶部写一句话，类似：“如果您无法查看邮件内容，请点击这里查看”；所有图片都要加上 alt 属性；所有的图片都要定义高和宽；通知收件人把你的发件地址加入白名单。Outlook 2007 的限制由于 outlook 2007 使用了 word 的渲染引擎来展现邮件内容，所以很多 HTML 属性没法得到支持了，比如： 背景图片 (这一点很重要！)css 浮动和定位 (这个没啥用)自定义列表项的图像 (这个也没啥用)Flash(反正不放)GIF 动画图片的 alt 属性 (值得注意)表单 (反正不放)这些细节还是应该注意一下。 附：Email 客户端的 CSS 支持情况本资料来自国外某邮件营销公司，所以缺乏国内邮件客户端的数据。 &lt;style&gt; 标签 标签 CSS 选择器 CSS 属性(*) 不被 Microsoft Outlook 2007 支持。 转载自： http://ued.koubei.com/?p=239 http://blog.csdn.net/liuyong0818/archive/2008/11/15/3305937.aspx]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
</search>
